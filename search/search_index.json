{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Soliplex Documentation","text":"<p>Welcome to the Soliplex ecosystem documentation. Soliplex provides AI-powered retrieval-augmented generation capabilities for intelligent document search and question answering.</p>"},{"location":"#components","title":"Components","text":""},{"location":"#core-platform","title":"Core Platform","text":"<p>The main Soliplex RAG system with FastAPI backend and Flutter frontend.</p> <p>Quick Links: - Prerequisites &amp; Installation - Server Setup - Docker Deployment - Configuration Guide</p>"},{"location":"#ingester","title":"Ingester","text":"<p>Robust document ingestion system for loading content into RAG databases.</p> <p>Quick Links: - Getting Started - Architecture - API Reference - CLI Reference</p>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#for-new-users","title":"For New Users","text":"<ol> <li>Prerequisites Guide - Complete installation checklist</li> <li>Getting Started with Core Platform - Set up the backend server</li> <li>Getting Started with Ingester - Document ingestion basics</li> </ol>"},{"location":"#for-developers","title":"For Developers","text":"<ol> <li>Core Platform Architecture - System design and components</li> <li>Ingester Architecture - Ingestion pipeline design</li> <li>API References - REST API documentation</li> </ol>"},{"location":"#for-operations","title":"For Operations","text":"<ol> <li>Docker Deployment - Containerized deployment guide</li> <li>Configuration Guide - Installation configuration</li> <li>Ingester CLI Reference - Command-line tool usage</li> </ol>"},{"location":"#what-is-soliplex","title":"What is Soliplex?","text":"<p>Soliplex combines the power of retrieval systems with generative AI to provide accurate, contextual responses based on your document collections. The system indexes your documents and uses them to enhance AI responses with relevant, up-to-date information.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>RAG-Powered Search: Semantic document retrieval using LanceDB vector database</li> <li>Multi-Room Architecture: Independent chat environments with separate configurations</li> <li>Multiple LLM Providers: OpenAI, Ollama, and compatible APIs</li> <li>Document Ingestion: Robust pipeline for loading and processing documents</li> <li>Real-time Communication: WebSocket-based conversation streams</li> <li>OIDC Authentication: Enterprise SSO with Keycloak integration</li> </ul>"},{"location":"#documentation-updates","title":"Documentation Updates","text":"<p>This documentation is automatically synchronized from multiple repositories:</p> <ul> <li>Core Platform: soliplex/soliplex</li> <li>Ingester: soliplex/ingester</li> </ul> <p>Documentation is updated automatically when changes are made to the source repositories.</p> <p>Last Updated: This site is automatically updated when documentation changes are pushed to the main branch of each repository.</p>"},{"location":"client/","title":"Client Setup","text":"<p>The Soliplex client is a Flutter web application that provides the user interface for interacting with the RAG system.</p>"},{"location":"client/#prerequisites","title":"Prerequisites","text":"<ul> <li>Dart SDK</li> <li>Flutter SDK</li> <li>Google Chrome (for web development)</li> </ul>"},{"location":"client/#installation","title":"Installation","text":"<ol> <li> <p>Clone the client repository:    <pre><code>git clone git@github.com:soliplex/soliplex.git\ncd soliplex/src/gen_ai_client\n</code></pre></p> </li> <li> <p>Install Flutter dependencies:    <pre><code>flutter pub get\n</code></pre></p> </li> </ol>"},{"location":"client/#running-the-client","title":"Running the Client","text":"<p>Start the Flutter web application:</p> <pre><code>flutter run -d chrome\n</code></pre> <p>This will launch the application in Chrome and provide a development server with hot reload capabilities.</p>"},{"location":"client/#development","title":"Development","text":"<p>The client uses: - Flutter 3.35+ with Material Design - Riverpod for state management - <code>go_router</code> for navigation - WebSocket connections for real-time chat</p>"},{"location":"overview/","title":"Soliplex Overview","text":"<p>Soliplex is an AI-powered Retrieval-Augmented Generation (RAG) system designed to provide intelligent document search and question-answering capabilities.</p>"},{"location":"overview/#architecture","title":"Architecture","text":"<p>The system consists of three main components:</p>"},{"location":"overview/#1-backend-server-soliplex","title":"1. Backend Server (<code>soliplex/</code>)","text":"<ul> <li>Technology: FastAPI with Python 3.13</li> <li>Purpose: Handles API requests, RAG processing, and AI model integration</li> <li>Features: </li> <li>OpenAI API integration</li> <li>Document indexing and retrieval</li> <li>Authentication and authorization</li> <li>Real-time WebSocket communication</li> </ul>"},{"location":"overview/#2-frontend-client-gen_ai_client","title":"2. Frontend Client (<code>gen_ai_client/</code>)","text":"<ul> <li>Technology: Flutter web application</li> <li>Purpose: Provides user interface for chat and document interaction</li> <li>Features:</li> <li>Material Design UI</li> <li>Real-time chat interface</li> <li>State management with Riverpod</li> <li>Responsive web design</li> </ul>"},{"location":"overview/#3-configuration-system","title":"3. Configuration System","text":"<ul> <li>OIDC Authentication: Keycloak integration for secure access</li> <li>Room Configuration: Chat environments and settings</li> <li>Model Configuration: LLM provider and model settings</li> </ul>"},{"location":"overview/#key-features","title":"Key Features","text":"<ul> <li>RAG Capabilities: Combines document retrieval with AI generation</li> <li>Multiple AI Models: Support for OpenAI and local models</li> <li>Secure Authentication: OIDC-based user management  </li> <li>Real-time Chat: WebSocket-powered interactive communication</li> <li>Document Management: Upload, index, and search through documents</li> </ul>"},{"location":"rag/","title":"Retrieval-Augmented Generation (RAG) Database","text":"<p>Soliplex depends on the <code>haiku-rag</code> library to manage its retrieval-augmented generation (RAG) searches.  That library stores its extracted documents / chunks / embeddings in LanceDB databases.</p> <p>The example installation of Soliplex uses the Soliplex documentation as its RAG corpus, and expects that database to be created at <code>db/rag/rag.lancedb</code>.</p>"},{"location":"rag/#note-on-haiku-rag-versions","title":"Note on <code>haiku-rag</code> Versions","text":"<p>The <code>soliplex</code> code itself requires only the <code>haiku-rag-slim</code> project (https://pypi.org/project/haiku.rag-slim/), which allows for queries aganst an existing LanceDB database.</p> <p>However, this dependency is not sufficient to perform the ingestion / indexing of documents.  For that purpose, either:</p> <ul> <li> <p>Install the main <code>haiku-rag</code> project   https://pypi.org/project/haiku.rag/   wihch will pull in all the dependencies required to ingest and index   documents.</p> </li> <li> <p>Pull the <code>docling-serve</code> Docker image, and run its server, with   your <code>haiku.rag.yaml</code> file configured to use it.</p> </li> </ul> <p>See the <code>haiku.rag</code> documentation to determine:</p> <ul> <li> <p>Which installation do you need?</p> </li> <li> <p>What are the tradeoffs of local vs. remote processing?</p> </li> <li> <p>How to configure <code>haiku-rag</code> to run in \"remote processing\" mode?</p> </li> </ul>"},{"location":"rag/#adding-a-single-document","title":"Adding a single document","text":"<pre><code>export OLLAMA_BASE_URL=&lt;your Ollama server / port&gt;\nhaiku-rag --config example/haiku.rag.yaml \\\n  add-src --db db/rag/rag.lancedb docs/index.md\n...\nDocument &lt;UUID&gt; added successfully.\n</code></pre>"},{"location":"rag/#adding-all-documents-in-a-directory","title":"Adding all documents in a directory","text":"<pre><code>export OLLAMA_BASE_URL=&lt;your Ollama server / port&gt;\nhaiku-rag --config example/haiku.rag.yaml \\\n  add-src --db db/rag/rag.lancedb docs/\n...\n17 documents added successfully.\n</code></pre>"},{"location":"rag/#configuration-of-haiku-rag-clients-within-soliplex","title":"Configuration of <code>haiku-rag</code> clients within Soliplex","text":"<p>Please see this page for notes on configuring the various <code>haiku-rag</code> clients used in a Soliplex installation.</p>"},{"location":"server/","title":"Server Setup","text":"<p>The Soliplex server is a FastAPI-based backend that forwards requests to OpenAI and provides RAG functionality.</p>"},{"location":"server/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Python 3.13+</p> </li> <li> <p>Access to LLM:</p> </li> <li> <p>OpenAI - an API key is required to use OpenAI</p> </li> <li> <p>Ollama  ([https://ollama.com/] https://ollama.com/)</p> </li> <li> <p>Logfire (optional):</p> </li> </ul> <p>A token from logfire (login here)   allows for visibility into the application. (see the   docs on FastAPI integration   for more information).</p>"},{"location":"server/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone git@github.com:soliplex/soliplex.git\ncd soliplex/\n</code></pre></p> </li> <li> <p>Set up a Python3 virtual environment:    <pre><code>python -m venv venv\nsource venv/bin/activate\npip install --upgrade setuptools pip\n</code></pre></p> </li> <li> <p>Install <code>soliplex</code> and its dependencies:    <pre><code>pip install -e .\n</code></pre></p> </li> <li> <p>Set up environment variables:</p> </li> </ol> <p>An environment file can be used to configure secrets.    For logfire, create a <code>.env</code> file with:    <pre><code>LOGFIRE_TOKEN=&lt;your_token_here&gt;\n</code></pre></p>"},{"location":"server/#running-the-example","title":"Running the example","text":"<p>The example configuration provides an overview of how a soliplex application is assembled.  It contains four top-level installation configurations:</p> <ul> <li> <p><code>example/minimal.yaml</code> is a minimal example using Ollama:  it requires   no secrets.</p> </li> <li> <p><code>example/installation.yaml</code> is a more fleshed-out example using Ollama:   it requires secrets for the exernal Model-Control Protocol (MCP) client   toosets for the room <code>mcptest</code>.</p> </li> <li> <p><code>example/minimal-openai.yaml</code> is a minimal example using OpenAI:    it requires no secrets beyond the <code>OPENAI_API_KEY</code>.</p> </li> <li> <p><code>example/installation.yaml</code> is a more fleshed-out example using OpenAI:   in addition tothe <code>OPENAI_API_KEY</code> secret, it requires secrets for the   exernal Model-Control Protocol (MCP) client toosets for the room <code>mcptest</code>.</p> </li> </ul> <p>Each installation configuration includes a number of rooms that </p> <ol> <li>Configure resources:</li> </ol> <p>The example needs access to a model server using either openapi    or ollama as well as access to example MCP services.</p> <p>The example uses https://smithery.ai/ but others    can be configured.</p> <p>a. OIDC configuration:    TODO</p> <ol> <li> <p>Configure the LLM (Ollama / OpenAI):</p> </li> <li> <p>For the Ollama veriants, export the URL of your model server as      <code>OLLAMA_BASE_URL</code>.  This url should not contain the <code>/v1</code> suffix.      E.g. if you are running Ollama on your own machine:</p> <pre><code>export OLLAMA_BASE_URL=http://localhost:11434\n</code></pre> </li> <li> <p>The example configuration uses the <code>gpt-oss</code> model.  If using either      Ollama variant, install that model via:      <pre><code>ollama pull gpt-oss:latest\n</code></pre></p> </li> <li> <p>Check for missing secrets / environment variables:</p> </li> </ol> <p>This command will check the server for any missing variables or    invalid configuration files.    <pre><code>soliplex-cli check-config example/&lt;installation config&gt;.yaml\n</code></pre></p> <p>The secrets used in the your chosen configuration should be exported as    environment variables, e.g.:    <pre><code>SMITHERY_AI_API_KEY=&lt;your key&gt;\nSMITHERY_AI_PROFILE=&lt;your profile&gt;\n</code></pre></p> <p>Note that the alternate installation configurations, <code>example/minimal.yaml</code>    and <code>example/minimal-openai.yaml</code>, requires no additional secrets    The <code>example/minimal.yaml</code> configuration still expects    the <code>OLLAMA_BASE_URL</code> environment variable to be set (or present in    an <code>.env</code> file):    <pre><code>soliplex-cli check-config example/minimal.yaml\n</code></pre></p> <ol> <li> <p>Configure any missing secrets, e.g. by sourcing a <code>.env</code> file, or    by exporting them directly.</p> </li> <li> <p>Configure any missing environment variables, e.g. by editing    the installation YAML file, adding them to a <code>.env</code> file in the    installation path, or exporting them directly.    <pre><code>export OLLAMA_BASE_URL=http://&lt;your-ollama-host&gt;:11434\nsoliplex-cli check-config example/\n</code></pre></p> </li> </ol>"},{"location":"server/#running-the-server","title":"Running the Server","text":"<p>Start the FastAPI server with auto-reload:</p> <pre><code>soliplex-cli serve example/installation.yaml -r both\n</code></pre> <p>The server will be available at <code>http://localhost:8000</code> by default.</p> <p>For testing purposes, the server can be run with authentication disabled. To run without authentication: <pre><code>soliplex-cli serve example/no_auth.yaml -r both\n</code></pre></p> <p>To confirm your room configuration: <pre><code>curl -X 'GET' \\\n  'http://127.0.0.1:8000/api/v1/rooms' \\\n  -H 'accept: application/json'\n</code></pre></p>"},{"location":"server/#api-endpoints","title":"API Endpoints","text":"<p>If the <code>soliplex-cli</code> server is running, you can browse the live OpenAPI documentation.</p>"},{"location":"usage/","title":"Using Soliplex","text":"<p>Once both the server and client are running, you can start using the Soliplex system.</p>"},{"location":"usage/#getting-started","title":"Getting Started","text":"<ol> <li>Open your web browser and navigate to the client application</li> <li>In the dropdown menu, select the localhost option</li> <li>Start typing your questions or prompts</li> </ol>"},{"location":"usage/#features","title":"Features","text":"<p>The Soliplex system provides: - Chat Interface: Interactive chat with AI models - Document Retrieval: RAG-powered document search and question answering - Multiple Models: Support for various AI models through OpenAI API - Real-time Responses: WebSocket-based real-time communication</p>"},{"location":"usage/#tips","title":"Tips","text":"<ul> <li>Use clear, specific questions for better RAG results</li> <li>The system can access and search through indexed documents</li> <li>Responses are generated using retrieval-augmented generation for   more accurate and contextual answers</li> </ul>"},{"location":"config/agents/","title":"Agent Configurations","text":"<p>The agent configuration mapping is used to configure the Pydantic AI agent used to make the calls to the LLM.</p> <pre><code>agent:\n    model_name: \"gpt-oss:20b\"\n    system_prompt: |\n      You are an expert AI assistant specializing in information retrieval.\n\n      Your answers should be clear, concise, and ready for production use.\n\n      Always provide code or examples in Markdown blocks.\n</code></pre>"},{"location":"config/agents/#required-agent-elements","title":"Required Agent Elements","text":"<ul> <li><code>model_name</code>: a string, should be the identifier of an LLM model for the   agent.</li> </ul> <p>NOTE: this value was previously optional, defaulting to the value             of the since-deprecated <code>DEFAULT_AGENT_MODEL</code> key in the             installation environment.</p> <ul> <li><code>system_prompt</code> is the \"instructions\" for the LLM serving the room.   If it starts with a <code>./</code>, it will be treated as a filename in the   same directory, whose contents will be read in its place.</li> </ul> <p>A minimal configuration, without an external prompt file:</p> <pre><code>agent:\n    model_name: \"gpt-oss:latest\"\n    system_prompt: |\n        You are a knowledgeable assistant that helps users find information from a document knowledge base.\n\n        Your process:\n        1. When a user asks a question, use the search_documents tool to find relevant information\n        ...\n</code></pre> <p>A minimal configuration, but with the prompt stored in external file:</p> <pre><code>agent:\n    model_name: \"gpt-oss:latest\"\n    system_prompt: \"./prompt.txt\"\n</code></pre>"},{"location":"config/agents/#optional-agent-elements","title":"Optional Agent Elements","text":"<ul> <li> <p><code>provider_type</code>: a string, must be one of <code>\"ollama\"</code> (the default) or   <code>\"openai\"</code>.</p> </li> <li> <p><code>provider_base_url</code>: a string, defaulting to the value configured in   the installation environment as <code>OLLAMA_BASE_URL</code> is the base API URL   for the agent's LLM provider. Must be specified without the <code>/v1</code>     suffix. E.g.:</p> </li> </ul> <pre><code>provider_base_url: \"https://provider.example.com/api\"\n</code></pre> <ul> <li><code>provider_key</code> (a string, default's to None) should be the   name of the secret holding the LLM provider's API key   (not the value of the API key), prefixed with <code>secret:</code></li> </ul> <pre><code>provider_key: \"secret:FOO_PROVIDER_API_KEY\"\n</code></pre> <p><code>provider_model_settings</code>: a mapping, whose keys are determined by   the <code>provider_type</code> above (see below).</p>"},{"location":"config/agents/#example-ollama-configuration","title":"Example Ollama Configuration","text":"<p>NOTE: the values below show types, but should not be used without           testing.</p> <pre><code>model_name: \"gpt-oss:latest\"\nprovider_type: \"ollama\"\nprovider_model_settings:\n  temperature: 0.90\n  top_k: 100\n  top_p: 0.75\n  min_p: 0.25\n  stop: \"STOP\"\n  num_ctx: 2048\n  num_predict: 2000\n</code></pre>"},{"location":"config/agents/#example-openai-configuration","title":"Example OpenAI Configuration","text":"<p>NOTE: the values below show types, but should not be used without           testing.</p> <pre><code>model_name: \"mistral:7b\"\nprovider_type: \"openai\"\nprovider_model_settings:\n  temperature: 0.90\n  top_p: 0.70\n  frequency_penalty: 0.25\n  presence_penalty: 0.50\n  parallel_tool_calls: false\n  truncation: \"disabled\"\n  max_tokens: 2048\n  verbosity: \"high\"\n</code></pre>"},{"location":"config/completions/","title":"Completion Configuration Filesystem Layout","text":"<p>A completion is configured via a directory, whose name is the completion ID.</p> <p>NOTE: directories whose names start with '.' are ignored.</p> <p>Within that directory should be one or two files:</p> <ul> <li> <p><code>completion_config.yaml</code> holds metadata about the completion (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the room.</p> </li> </ul> <p>Example layout without external prompt: <pre><code>simple/\n    room_config.yaml\n</code></pre></p> <p>Example layout with external prompt: <pre><code>chat/\n    prompt.txt\n    room_config.yaml\n</code></pre></p>"},{"location":"config/completions/#completions-endpoint-configuration-file-schema","title":"Completions Endpoint Configuration File Schema","text":""},{"location":"config/completions/#required-endpoint-elements","title":"Required endpoint elements","text":"<p>The <code>completion_config.yaml</code>  file should be a mapping, with at least the following required elements:</p> <ul> <li> <p><code>id</code> (a string) should match the name of the endpoint's directory.</p> </li> <li> <p><code>agent</code> (a mapping)</p> </li> </ul> <p>A minimal completion endpoint configuration must include the above elements, e.g.:</p> <pre><code>id: \"chat\"\nagent:\n  system_prompt: |\n      You are an..... #\n</code></pre> <p>Please see this page which documents the <code>agent</code> element schema.</p>"},{"location":"config/environment/","title":"Installation Environment","text":"<p>The <code>environment</code> section configures non-secret values used by various portions of the Soliplex application.  Application code should use the <code>Installation.get_environment</code> API to fetch configured values, rather than using <code>os.environ</code>.</p>"},{"location":"config/environment/#environment-entries","title":"Environment Entries","text":"<p>The section consists of a list of mappings, each with keys <code>name</code> and <code>value</code>.</p> <pre><code>environment:\n  - name: \"ENV_VAR_NAME\"\n    value: \"ENV_VAR_VALUE\"\n</code></pre>"},{"location":"config/environment/#unconfigured-environment-entries","title":"Unconfigured Environment Entries","text":"<p>If the <code>value</code> key is missing, the Soliplex application will attempt to resolve it using <code>os.environ</code> during startup.</p>"},{"location":"config/environment/#bare-string-environment-entries","title":"Bare-String Environment Entries","text":"<p>As an alternative, an item in the list can be a bare string:  such an entry corresponds exactly to a mapping with <code>name: \"&lt;bare string</code> and no <code>value</code>.</p> <p>This configuration: <pre><code>environment:\n  - \"ENV_VAR_NAME\"\n</code></pre> is exactly equivalent to this one: <pre><code>environment:\n  - name: \"ENV_VAR_NAME\"\n</code></pre></p>"},{"location":"config/environment/#checking-configured-environment-values","title":"Checking Configured Environment Values","text":"<p>The <code>soliplex-cli</code> application has a sub-command, <code>list-environment</code>. It loads the configuration, attempts to resolve any values not found, and reports them:</p> <pre><code>$ soliplex-cli list-environment example/installation.yaml \n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Configured environment variables \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n- OLLAMA_BASE_URL          : MISSING\n- INSTALLATION_PATH        : file:.\n- RAG_LANCE_DB_PATH        : file:../db/rag\n- LOGFIRE_ENVIRONMENT      : container\n- LOGFIRE_SERVICE_NAME     : soliplex\n</code></pre>"},{"location":"config/filesystem_layout/","title":"Installation Filesystem Layout","text":"<p>An \"installation\" is a set of filesystem-based configuration files, organized as a directory tree.</p> <p>At the root of an installation directory is a file, <code>installation.yaml</code>, which is used to configure environment variables and secrets used by the installation.  There may be alternative configurations available, e.g. to configure how the installation runs inside a container.</p> <p>See this page for documentation on the schema of one of these configurations.</p> <p>An installation directory typically contains subdirectories, each holding configurations for a given type of entity.</p> <p>Example layout:</p> <pre><code>/\n  installation.yaml\n  completions/\n    chat-bot/\n      completion_config.yaml\n      prompt.txt\n    ...\n  oidc/\n    cacert.pem\n    config.yaml\n  quizzes/\n    quiz_name.json\n    ...\n  rooms/\n    quiztest/\n      prompt.txt\n      room_config.yaml\n    ...\n</code></pre>"},{"location":"config/filesystem_layout/#room-configuration","title":"Room Configuration","text":"<p>Within a \"rooms\" directory, each room is represented by a subdirectory, whose name is the room ID.</p> <p>Within that subdirectory should be one or two files:</p> <ul> <li> <p><code>room_config.yaml</code> holds metadata about the room (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the room.</p> </li> <li> <p>A logo image file (optional)</p> </li> </ul> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"config/filesystem_layout/#completions-endpoint-configuration","title":"Completions Endpoint Configuration","text":"<p>Within a \"completions\" directory, each endpoint is represented by a subdirectory, whose name is the endpoint ID.</p> <p>Within that subdirectory should be one or two files:</p> <ul> <li> <p><code>completion_config.yaml</code> holds metadata about the endpoint (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the endpoint.</p> </li> </ul> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"config/filesystem_layout/#quiz-configuration","title":"Quiz Configuration","text":"<p>This directory contains question sets as individual JSON files, derived from the evaluation dataset entries.</p> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"config/filesystem_layout/#oidc-provider-configuration","title":"OIDC Provider Configuration","text":"<p>This directory contains configuration files defining the OIDC identity providers configured for use in this installation.</p> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"config/installation/","title":"Installation Configuration","text":""},{"location":"config/installation/#installation-id","title":"Installation ID","text":"<p>A required field, to allow quick disambiguation between alternative configurations.</p> <pre><code>id: \"soliplex-example\"\n</code></pre>"},{"location":"config/installation/#installation-metaconfiguration","title":"Installation Metaconfiguration","text":"<p>The <code>meta</code> section allows you to register custom \"kinds\" of entities (tool configurations, MCP client toolset configurations, etc.), such that you can use them within your own configurations (e.g., to register a configuration class for use with a custom tool in a given room).</p> <pre><code>meta:\n</code></pre> <p>See this page for documentation on the meta-configuration schema.</p>"},{"location":"config/installation/#secrets","title":"Secrets","text":"<pre><code>secrets:\n</code></pre> <p>Secrets are values used to authenticate access to different resources or APIs.</p> <p>The may be kept in an external store, such as:</p> <ul> <li>ASW secret store</li> <li>GitHub secrets</li> <li>Docker Compose secrets files</li> <li>The user keyring</li> </ul> <p>See this page for documentation on configuring installation secrets.</p>"},{"location":"config/installation/#environment","title":"Environment","text":"<p>The <code>environment</code> section configures non-secret values used by various portions of the Soliplex application.  Application code should use the <code>Installation.get_environment</code> API to fetch configured values, rather than using <code>os.environ</code>.</p> <pre><code>environment:\n</code></pre> <p>See this page for documentation on configuring the installation environment.</p>"},{"location":"config/installation/#haikurag-configuration-file","title":"<code>haiku.rag</code> Configuration File","text":"<p>The <code>haiku_rag_config_file</code> entry points to a YAML file containing configuration values for the <code>haiku.rag</code> client</p> <p>If not configured explicitly, the installation configuration expects to find this file in the same directory, with the default name <code>haiku.rag.yaml</code>.</p> <p>Pleas see the <code>haiku.rag</code> configuration docs for details on how to configure the <code>haiku.rag</code> client used by Soliplex.</p>"},{"location":"config/installation/#agent-configurations","title":"Agent Configurations","text":"<p>An installation can declare agent configurations (which are normally bound to rooms / completions) at the top-level, such that they can be looked up by ID from Python code using <code>the_installation.get_agent_by_id</code>.</p> <p><pre><code>agent_configs:\n\n  - id: \"ollama_gpt_oss\"\n    model_name: \"gpt-oss:20b\"\n    system_prompt: |\n      You are an expert AI assistant specializing in information retrieval.\n      ...\n</code></pre> Please see this page for details on configuring agents. In addition to the values described there, note that the <code>id</code> element is required here.</p>"},{"location":"config/installation/#thread-persistence-dburi","title":"Thread Persistence DBURI","text":"<p>An installation can define two DBURIs for the database used to store AG-UI threads, runs, events, etc.</p>"},{"location":"config/installation/#synchronous-dburi","title":"Synchronous DBURI","text":"<p>One DBURI is for sync usage, e.g.  within console scripts.  Examples:</p> <ul> <li><code>sqlite://</code></li> <li><code>postgresql+psycopg2://user:&lt;password&gt;@dbhost/dbname</code></li> </ul>"},{"location":"config/installation/#asynchronous-dburi","title":"Asynchronous DBURI","text":"<p>The other DBURI is for async usage, e.g. within the Soliplex server process.  Examples:</p> <ul> <li><code>sqlite+aiosqlite://</code></li> <li><code>postgresql+asyncpg://user:&lt;password&gt;@dbhost/dbname</code></li> </ul> <p>This DBURI must be compatible with SQLAlchemy's asyncio extension. Dialects known to work include:</p> <ul> <li><code>aiosqlite</code></li> <li><code>asyncpg</code></li> </ul>"},{"location":"config/installation/#default-configuration","title":"Default configuration","text":"<p>By default, Soliplex configures thread persistence using in-memory DBURIS:</p> <ul> <li>For sync use, <code>sqlite</code> (DBURI <code>sqlite://</code>)</li> <li>For async use, <code>aiosqlite</code> (DBURI <code>sqlite+aiosqlite://</code>)</li> </ul> <p>The default configuration is equivalent to this explicit YAML:</p> <pre><code>thread_persistence_dburi:\n  sync: \"sqlite://\"\n  async: \"sqlite+aiosqlite://\"\n</code></pre>"},{"location":"config/installation/#database-passwords-as-secrets","title":"Database passwords as secrets","text":"<p>For DBURIs requiring authentication, we would rather not expose the password in plain-text configuration.  In this case, we can define a Soliplex secret (read here), and use that secret in the DBURI.</p> <pre><code>secrets:\n    - secret_name: MY_DBURI_SECRET\n      # Configure sources here\n...\n\nthread_persistence_dburi:\n  sync: \"postgresql+psycopg2://user:secret:MY_DBURI_SECRET@dbhost/dbname\"\n  async: \"postgresql+asyncpg://user:secret:MY_DBURI_SECRET@dbhost/dbname\"\n</code></pre>"},{"location":"config/installation/#oidc-auth-provider-paths","title":"OIDC Auth Provider Paths","text":"<p>The <code>oidc_paths</code> element specifies one or more filesystem paths to be searched for OIDC provider configs.</p> <p>Please see this page for details on how to configure these providers.</p> <pre><code>oidc_paths:\n  - \"/path/to/oidc/config/dir\"\n</code></pre> <p>Non-absolute paths will be evaluated relative to the installation directory.</p> <p>By default, Soliplex loads provider configurations found under the path './oicd', just as though we had configured:</p> <pre><code>oidc_paths:\n  - \"./oidc\"\n</code></pre> <p>To disable authentication, list a single, \"null\" path, e.g.: <pre><code>oidc_paths:\n  -\n</code></pre> Or else run 'soliplex-cli serve --no-auth-mode'</p>"},{"location":"config/installation/#room-configuration-paths","title":"Room Configuration Paths","text":"<p>The <code>room_paths</code> element specify one or more filesystem paths to search for room configs.</p> <p>Please see this page for details on how to configure these providers.</p> <p>Each path can be either:</p> <ul> <li> <p>a directory containing its own <code>room_config.yaml</code> file:  this directory   will be mapped as a single room.</p> </li> <li> <p>a directory whose immediate subdirectories will be treated as rooms   IFF they contain a <code>room_config.yaml</code> file.</p> </li> </ul> <p>Non-absolute paths are evaluated relative to the installation directory.</p> <p>The order of <code>room_paths</code> in this list controls which room configuration is used for any conflict on room ID:  rooms found earlier in the list \"win\" over later ones with the same ID.</p> <p>By default, Soliplex loads room configurations found under the path './rooms', just as though we had configured:</p> <p><pre><code>room_paths:\n  - \"./rooms\"\n</code></pre> To disable all rooms, list a single, \"null\" path, e.g.:</p> <pre><code>room_paths:\n   -\n</code></pre>"},{"location":"config/installation/#completion-configuration-paths","title":"Completion Configuration Paths","text":"<p>The <code>completion_paths</code> entry specifies one or more filesystem paths to search for completion configs.</p> <p>Please see this page for details on how to configure these providers.</p> <p>Each path can be either:</p> <ul> <li> <p>a directory containing its own <code>completion_config.yaml</code> file:  this   directory will be mapped as a single completion.</p> </li> <li> <p>a directory whose immediate subdirectories will be treated as rooms   IFF they contain a <code>room_config.yaml</code> file.</p> </li> </ul> <p>Non-absolute paths will be evaluated relative to the installation directory.</p> <p>The order of entries in the <code>completion_paths</code> list controls which completion configuration is used for any conflict on completion ID:  completions found earlier in the list \"win\" over later ones with the same ID.</p> <p>By default, Soliplex loads completion configurations found under the path './completions', just as though we had configured:</p> <pre><code>completion_paths:\n  - \"./completions\"\n</code></pre> <p>To disable all completions, list a single, \"null\" path, e.g.: <pre><code>completion_paths:\n  -\n</code></pre></p>"},{"location":"config/meta/","title":"Installation Metaconfiguration","text":"<p>The <code>meta</code> section of an installation configuration enables registration of custom \"kinds\" of entities (tool configurations, MCP client toolset configurations, etc.), so that they can be used within the rest of the installation.</p> <p>E.g., registering a new tool configuration class in the <code>meta.tool_configs</code> section allows use of that class when configuring a custom tool in a given room.</p>"},{"location":"config/meta/#registering-ag-ui-feature-classes","title":"Registering AG-UI Feature Classes","text":"<p>The <code>meta.agui_features</code> section registers AG-UI feature types so that they can be referenced by their <code>name</code>.  Each feature is a contract between the client application and the server, defining the schema for a named field in the AG-UI state, and which parties are expected to write to that field.</p> <p>The section contains a list of mappings, each of which include:</p> <ul> <li> <p><code>name</code>, a string identifying the field in the AG-UI state.</p> </li> <li> <p><code>model_klass</code>, a Python \"dotted name\" which can be used to import the    model class which defines the field's schema.</p> </li> <li> <p><code>source</code> (optional), a  key indicating which party is allowed to set   the feature's field in the AG-UI state. Allowed values are \"client\",   \"server\", and \"either\";  the default is \"either\".</p> </li> </ul> <p>By default, Soliplex registers its own AG-UI feature classes, just as though we configured explicitly:</p> <pre><code>meta:\n  agui_features:\n\n  - name: \"filter_documents\"\n    model_klass: \"soliplex.agui.features.FilterDocuments\"\n    source: \"client\"\n\n  - name: \"ask_history\"\n    model_klass: \"soliplex.agui.features.AskedAndAnswered\"\n    source: \"server\"\n</code></pre>"},{"location":"config/meta/#registering-tool-configuration-classes","title":"Registering Tool Configuration Classes","text":"<p>The <code>meta.tool_configs</code> section enumerates tool configuration types so that they can be referenced by their <code>tool_name</code>.</p> <p>The section contains a list of Python \"dotted names\", i.e. strings which can be used to import the configuration class.</p> <p>By default, Soliplex registers its own tool config classes, just as though we configured explicitly:</p> <pre><code>meta:\n  tool_configs:\n  - \"soliplex.config.SearchDocumentsToolConfig\"\n</code></pre>"},{"location":"config/meta/#registering-mcp-client-toolset-configuration-classes","title":"Registering MCP Client Toolset Configuration Classes","text":"<p>The <code>meta.mcp_toolset_configs</code> section enumerates MCP client toolset configuration types so that they can be referenced by their 'kind'.</p> <p>The section contains a list of Python \"dotted names\", i.e. strings which can be used to import the configuration class.</p> <p>By default, Soliplex registers its own tool config classes, just as though we configured explicitly:</p> <pre><code>meta:\n  mcp_toolset_configs:\n  - \"soliplex.config.Stdio_MCP_ClientToolsetConfig\"\n  - \"soliplex.config.HTTP_MCP_ClientToolsetConfig\"\n</code></pre>"},{"location":"config/meta/#registering-mcp-server-tool-wrapper-types","title":"Registering MCP Server Tool Wrapper Types","text":"<p>The <code>meta.mcp_server_tool_wrappers</code> section maps tool configuration classes to the equivalent wrapper class, used then offering the tool to external MCP clients.</p> <p>The section contains a list of mappings with keys <code>config_klass</code> and <code>wrapper_klass</code>.  Values for both keys Python \"dotted names\", i.e. strings which can be used to import the corresponding class.</p> <p>By default, Soliplex configures its 'soliplex.config.WithQueryMCPWrapper' as the wrapper for 'soliplex.config.SearchDocumentsToolConfig', just as if we configured here:</p> <pre><code>meta:\n  mcp_server_tool_wrappers:\n  - config_klass: \"soliplex.config.SearchDocumentsToolConfig\"\n    wrapper_klass: \"soliplex.config.WithQueryMCPWrapper\"\n</code></pre>"},{"location":"config/meta/#registering-agent-configuration-classes","title":"Registering Agent Configuration Classes","text":"<p>The <code>meta.agent_configs</code> section enumerates agent configuration types so that they can be referenced by their <code>kind</code>.</p> <p>The section contains a list of Python \"dotted names\", i.e. strings which can be used to import the configuration class.</p> <p>By default, Soliplex registers its own agent config class, just as though we configured explicitly:</p> <pre><code>meta:\n  tool_configs:\n  - \"soliplex.config.AgentConfig\"\n</code></pre>"},{"location":"config/meta/#registering-secret-source-configurations","title":"Registering Secret Source Configurations","text":"<p>Each installation secret can be configured with multiple \"sources\" of different kinds. Each source configuration kind corresponds to a Python function which is used to retrieve the secret value.</p> <p>The <code>meta.secret_sources</code> section allows configuring new secret source configurations and their corresponding functions.</p> <p>By default, these classes are configured to use the corresponding functions in 'soliplex.secrets', just as if we configured here:</p> <pre><code>meta:\n  secret_sources:\n  - config_klass: \"soliplex.config.EnvVarSecretSource\"\n    registered_func: \"soliplex.secrets.get_env_var_secret\"\n  - config_klass: \"soliplex.config.FilePathSecretSource\"\n    registered_func: \"soliplex.secrets.get_file_path_secret\"\n  - config_klass: \"soliplex.config.SubprocessSecretSource\"\n    registered_func: \"soliplex.secrets.get_subprocess_secret\"\n  - config_klass: \"soliplex.config.RandomCharsSecretSource\"\n    registered_func: \"soliplex.secrets.get_random_chars_secret\"\n</code></pre>"},{"location":"config/oidc_providers/","title":"OIDC Provider Configuration","text":"<p>The <code>config.yaml</code> file in an OIDC provider configuration directory specifies one or more authentication systems, sharing a common CA certificate store:</p> <pre><code>oidc_client_pem_path: \"./cacert.pem\"\n\nauth_systems:\n\n  - id: \"myprovder\"\n    title: \"Authenticate with MyProovider\"\n    server_url: \"https://oidc.excample.com/\"\n    client_id: \"myprovider-token-service\"\n    client_secret: \"\"  # \"secret:{MYPROVIDER_CLIENT_SECRET}\"\n    scope: \"openid email profile\"\n    token_validation_pem: |\n        -----BEGIN PUBLIC KEY-----\n        MII..AQAB\n        -----END PUBLIC KEY-----\n</code></pre>"},{"location":"config/oidc_providers/#required-configuration-elements","title":"Required Configuration Elements","text":"<ul> <li><code>authsystems</code> is a list of one or more OIDC provider configurations   (see below).</li> </ul>"},{"location":"config/oidc_providers/#optional-configuration-elements","title":"Optional Configuration Elements","text":"<ul> <li><code>oidc_client_pem_path</code> points to a file on the filesystem containing   the shared CA certificate store.  If not configured, the Soliplex   application will use systemwide default CA certificates.</li> </ul>"},{"location":"config/oidc_providers/#required-oidc-provider-elements","title":"Required OIDC Provider Elements","text":"<ul> <li> <p><code>id</code>: a string, should be unique across all configured providers</p> </li> <li> <p><code>title</code>: a string, might be displayed by a client</p> </li> <li> <p><code>server_url</code>: URL for initiating the token auth flow.</p> </li> <li> <p><code>token_validation_pem</code>: a string, the public key used to verify    the providers tokens.</p> </li> <li> <p><code>client_id</code>: a string identifying the client to the provider.</p> </li> </ul>"},{"location":"config/oidc_providers/#optional-oidc-provider-elements","title":"Optional OIDC Provider Elements","text":"<ul> <li> <p><code>client_secret</code>: a string;  if not empty, should be in the form   <code>\"secret:MYPROVIDER_CLIENT_SECRET\"</code>, where the name following the   <code>secret:</code> prefix is the name of a configured installation secret   (see this page for details).</p> </li> <li> <p><code>scope</code>: string, an OAuth scope specifier.</p> </li> </ul>"},{"location":"config/quizzes/","title":"Quiz Datasets","text":"<p>Quizzes use the evaluation dataset entries (see the schema).</p>"},{"location":"config/quizzes/#room-configuration","title":"Room Configuration","text":"<ul> <li>Room configurations get a new key, <code>quizzes</code>, with a value which   is a mapping defining quizzes which can be run in the room   (see <code>rooms/README.md</code>).</li> </ul>"},{"location":"config/quizzes/#api","title":"API","text":""},{"location":"config/quizzes/#get-apiv1rooms","title":"<code>GET /api/v1/rooms</code>","text":"<p>Room config entries in the response include the value of <code>quizzes</code> (a list of mappings).</p>"},{"location":"config/quizzes/#get-apiv1roomsroom_id","title":"<code>GET /api/v1/rooms/{room_id}</code>","text":"<p>Response includes  the value of <code>quizzes</code> (a list of mappings).</p>"},{"location":"config/quizzes/#get-apiv1roomsroom_idquizquiz_id","title":"<code>GET /api/v1/rooms/{room_id}/quiz/{quiz_id}</code>","text":"<p>Fetch the quiz.  Returns a mapping for the quiz with a list of questions:</p> <pre><code>{\n    \"id\": \"&lt;quiz_id&gt;\",\n    \"questions\": [\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"What color is the sky? (QA)\",\n            \"metadata\": {\n                \"type\": \"qa\"\n            }\n        },\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"The color of the sky is _____\",\n            \"metadata\": {\n                \"type\": \"fill-blank\"\n            }\n        },\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"Is the sky blue?\",\n            \"metadata\": {\n                \"type\": \"multiple-choice\",\n                \"options\": {\n                    \"true\",\n                    \"false\"\n                }\n            }\n        },\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"What color is the sky? (MC)\",\n            \"metadata\": {\n                \"type\": \"multiple-choice\",\n                \"options\": {\n                    \"red\",\n                    \"green\",\n                    \"blue\"\n                }\n            }\n        },\n    ...\n    ]\n}\n</code></pre> <ul> <li> <p><code>question-type</code> is one of <code>\"qa\"</code>, <code>\"fill-blank\"</code>, or <code>\"multiple-choice\"</code></p> </li> <li> <p>Questions of type <code>\"multiple-choice\"</code> contain an additional entry,   <code>\"options\"</code> in their metadata, whose value is a list of strings.</p> </li> </ul>"},{"location":"config/quizzes/#post-apiv1roomsroom_idquizquiz_idquestion_uuid","title":"<code>POST /api/v1/rooms/{room_id}/quiz/{quiz_id}/{question_uuid}</code>","text":"<p>Check an answer.  Client should send the answer entered / selected by the user as a <code>text/plain</code> body.  For a correct answer, returns:</p> <pre><code>{\n    \"correct\": \"true\"\n}\n</code></pre> <p>For an incorrect answer, returns: <pre><code>{\n    \"correct\": \"false\"\n    \"expected_output\": \"&lt;expected_output&gt;\"\n}\n</code></pre></p> <p>(Later, this response might include more information, such as a citation).</p>"},{"location":"config/rag/","title":"<code>haiku-rag</code> Client Configuration","text":"<p>In order to use its RAG database(s) (see this page for how to create them), Soliplex installation uses <code>haiku.rag</code> as a library, creating instances of <code>haiku.rag.client.HaikuRag</code> client class as needed.</p> <p>NOTE:  the <code>embeddings</code> configuration used to create the RAG database            must match the client configuration used to read the database.</p> <p>The configuration used to create these client instances can be defined in two places:</p>"},{"location":"config/rag/#global-configuration","title":"Global Configuration","text":"<p>The default <code>haiku-rag</code> configuration for an installation lives in a seprate file, <code>haiku.rag.yaml</code>, which is located by default in the installation directory (next to the main installation config file).</p> <p>See the <code>haiku-rag</code> docs for the format and semantics of this file.</p>"},{"location":"config/rag/#room-level-and-completion-level-configuration","title":"Room-level and Completion-level Configuration","text":"<p>Rooms and completions which use the <code>soliplex.tools.search_documents</code> tool can also define a <code>haiku.rag.yaml</code> file, next to their own config files.  Soliplex overlays any configuration defined in such files on top of the global configuration when using the tool.</p> <p>E.g., to override only the reranking used by <code>haiku-rag</code> in a given room:</p> <pre><code>reranking:\n  model:\n    name: \"gpt-oss:20b\"\n    provider: \"ollama\"\n</code></pre>"},{"location":"config/rooms/","title":"Room Configuration Filesystem Layout","text":"<p>A room is configured via a directory, whose name is the room ID.</p> <p>NOTE: directories whose names start with '.' are ignored.</p> <p>Within that directory should be one or two files:</p> <ul> <li> <p><code>room_config.yaml</code> holds metadata about the room (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the room.</p> </li> </ul> <p>Example layout without external prompt file: <pre><code>simple/\n    room_config.yaml\n</code></pre></p> <pre><code>chat/\n    prompt.txt\n    room_config.yaml\n</code></pre>"},{"location":"config/rooms/#room-configuration-file-schema","title":"Room Configuration File Schema","text":""},{"location":"config/rooms/#required-room-elements","title":"Required room elements","text":"<p>The <code>room_config.yaml</code>  file should be a mapping, with at least the following required elements:</p> <ul> <li> <p><code>id</code> (a string) should match the name of the room's directory.</p> </li> <li> <p><code>name</code> (a string) is the \"title\" of the room, as would be shown in a list.</p> </li> <li> <p><code>description</code> (a string) tells the purpose of the room:  it might show up   as the \"lede\" graph (below the <code>name</code>) in a list of rooms.</p> </li> <li> <p><code>agent</code> (a mapping, see next section)</p> </li> </ul> <p>A minimal room configuration must include the above elements, e.g.:</p> <pre><code>id: \"chat\"\nname: \"Chatting Darkly\"\ndescription: \"Scanning for conversations\"\nagent:\n  system_prompt: |\n      You are an..... #\n</code></pre>"},{"location":"config/rooms/#optional-room-elements-ui-related","title":"Optional room elements (UI-related):","text":"<ul> <li><code>welcome_message</code> (a string), for the UI to display when the user   enters a room.  E.g.:</li> </ul> <pre><code>welcome_message: &gt;\n    Welcome to the room.  We hope you find it useful\n\n    Please review the suggestions below for ideas on the kinds\n    of questions for which this room is intended.\n</code></pre> <ul> <li><code>suggestions</code> (a list of strings) contains possible \"starter questions\"   for the room, which the UI might display as shortcuts when the user   enters the room.  E.g.:</li> </ul> <pre><code>suggestions:\n  - \"How high is up?\"\n  - \"Why is the sky blue?\"\n</code></pre> <ul> <li><code>enable_attachments</code> (a boolean, default <code>False</code>), which, if true,    tells the UI to allow the user to attach files to a prompt. E.g.:</li> </ul> <pre><code>enable_attachments: true\n</code></pre>"},{"location":"config/rooms/#agent-configuration","title":"Agent configuration","text":"<p>The <code>agent</code> mapping is used to configure the Pydantic AI agent used to make the room's calls to the LLM.</p> <pre><code>agent:\n    model_name: \"gpt-oss:latest\"\n    system_prompt: \"./prompt.txt\"\n</code></pre> <p>Please see this page for a full description of the options for configuring an agent.</p>"},{"location":"config/rooms/#tool-configurations","title":"Tool Configurations","text":"<ul> <li><code>tools</code> should be a list of mappings, with at least the key   <code>tool_name</code>, whose value is a dotted name identifying a Python function    (or callable) which can serve as a \"tool\" for the LLM.  E.g.:</li> </ul> <p><pre><code>tools:\n    - tool_name: \"soliplex.tools.get_current_datetime\"\n    - tool_name: \"soliplex.tools.get_current_user\"\n</code></pre>   Each tool mapping can contain additional elements, which are used to    configure the tool's behavior.</p>"},{"location":"config/rooms/#rag-search-related","title":"RAG / search-related","text":"<p>The <code>soliplex.tools.search_documents</code> tool takes a number of configuration values.  Exactly one of the following two elements is required:</p> <ul> <li><code>rag_lancedb_stem</code> is a string:  it should be the \"base name\" (without   path or <code>.lancedb</code> suffix) of the LanceDB file containing the RAG document   data for the tool. This file must exist in the \"standard\" location   (typically under the <code>db/rag/</code> directory;  see below).</li> </ul> <pre><code>rag_lancedb_stem: \"&lt;room_id&gt;\"\n</code></pre> <ul> <li><code>rag_lancedb_override_path</code> is a string:  it should be a fully-qualified   pathname, including the suffix, of the LanceDB directory containing the RAG   document data for the tool. </li> </ul> <pre><code>rag_lancedb_override_path: \"/&lt;path-to-rag-databases&gt;/&lt;room_id&gt;.&lt;extension&gt;\"\n</code></pre> <p>Other, optional elements for the <code>search_documents</code> tool:</p> <ul> <li><code>search_documents_limit</code> is a positive integer (default <code>5</code>), used to   control the number of results returned by the <code>search_documents</code> tool. E.g.:</li> </ul> <pre><code>search_documents_limit: 8\n</code></pre> <p>Minimal <code>search_documents</code> configuration, with RAG database file found in the standard location:</p> <pre><code>agent:\n  tools:\n    - tool_name: \"soliplex.tools.search_documents\"\n      rag_lancedb_stem: \"chat\"\n</code></pre> <p>Minimal <code>search_documents</code> configuration, with RAG database file found in an overridden location:</p> <pre><code>agent:\n  tools:\n    - tool_name: \"soliplex.tools.search_documents\"\n      rag_lancedb_override_path: \"/path/to/rag/db/filename.lancedb\"\n</code></pre> <p>Maximal <code>search_documents</code> configuration</p> <pre><code>agent:\n  tools:\n    - tool_name: \"soliplex.tools.search_documents\"\n      rag_lancedb_stem: \"chat\"\n      search_documents_limit: 8\n</code></pre>"},{"location":"config/rooms/#quiz-related-elements","title":"Quiz-related elements","text":"<ul> <li><code>quizzes</code> is a list of mappings (default <code>()</code>):  each mapping defines a   quiz which can be run in the room (see this page for   details of the quiz dataset).</li> </ul> <pre><code>quizzes:\n  - id: \"test_quiz\"\n    title: \"Test Quiz\"\n    question_file: \"/path/to/questions.json\"\n    randomize: false\n    max_questions: 100\n</code></pre>"},{"location":"config/rooms/#location-of-rag-database-files","title":"Location of RAG database files","text":"<p>Rooms using the <code>search_documents</code> tool need to be able to find the LanceDB database containing the chunks and embeddings extracted by Haiku-RAG.  At present, there should be a single database per room, named by convention <code>&lt;stem&gt;.lancedb</code>, and stored in the <code>db/rag/</code> subdirectory of the project root.</p>"},{"location":"config/secrets/","title":"Configuring Installation Secrets","text":"<p>The <code>secrets</code> section of an installation configuration contains a list of secret names, and optionally their configured sources.</p> <p>The default configuration knows of four types of sources:</p> <ul> <li>Environment variables</li> <li>File paths</li> <li>Subprocess commands</li> <li>Randomly-generated strings</li> </ul>"},{"location":"config/secrets/#secret-source-environment-variable","title":"Secret Source: Environment Variable","text":"<p>A secret source which uses an environment variable can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"env_var\"\n       env_var_name: \"MY_SECRET_ENV_VAR_NAME\"\n</code></pre>"},{"location":"config/secrets/#secret-source-filesystem-path","title":"Secret Source: Filesystem Path","text":"<p>A secret source which uses a file system path can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"file_path\"\n       file_path: \"/run/secret/my_secret\"\n</code></pre>"},{"location":"config/secrets/#secret-source-subprocess-command","title":"Secret Source: Subprocess Command","text":"<p>A secret source which uses a subprocess command can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"subprocess\"\n       command: \"/usr/bin/fetch_secret\"\n       args:\n       - \"--secret-name=MY_SECRET\"\n</code></pre>"},{"location":"config/secrets/#secret-source-randomly-generated-string","title":"Secret Source: Randomly-Generated String","text":"<p>A secret source which uses generates a random string at process startup can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"random_chars\"\n       n_chars: 32\n</code></pre>"},{"location":"config/secrets/#layering-secret-sources","title":"Layering Secret Sources","text":"<p>Sources are resolved in the order they are listed, with the first one returning a value winning.  This example layers an environment variable source with a random string source:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"env_var\"\n       env_var_name: \"MY_SECRET_ENV_VAR_NAME\"\n     - kind: \"random_chars\"\n       n_chars: 32\n</code></pre>"},{"location":"config/secrets/#secrets-without-sources","title":"Secrets without Sources","text":"<p>Secrets which list no sources are treated as though they were configured using an environment variable source with the same name.</p> <p>This configuration:</p> <pre><code>secrets:\n    - secret_name: MY_SECRET\n</code></pre> <p>is equivalent to:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"env_var\"\n       env_var_name: \"MY_SECRET\"\n</code></pre>"},{"location":"config/secrets/#secrets-as-bare-strings","title":"Secrets as Bare Strings","text":"<p>An even shorter way to spell the previous configuration:</p> <pre><code>secrets:\n   - \"MY_SECRET\"\n</code></pre>"},{"location":"config/secrets/#checking-configured-secrets","title":"Checking Configured Secrets","text":"<p>The <code>soliplex-cli</code> application has a sub-command, <code>list-secrets</code>. It loads the configuration, attempts to resolve all the secrets, and reports those not found.  E.g.:</p> <pre><code>$ soliplex-cli list-secrets example/installation.yaml \n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Configured secrets \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n- LOGFIRE_TOKEN             MISSING\n- SMITHERY_AI_API_KEY       MISSING\n- SMITHERY_AI_PROFILE       MISSING\n- URL_SAFE_TOKEN_SECRET     OK\n</code></pre>"},{"location":"ingester/API/","title":"Soliplex Ingester API Reference","text":""},{"location":"ingester/API/#base-url","title":"Base URL","text":"<p>All API endpoints are prefixed with <code>/api/v1/</code> unless otherwise noted.</p>"},{"location":"ingester/API/#authentication","title":"Authentication","text":"<p>Currently, the API does not implement authentication. This should be added for production deployments.</p>"},{"location":"ingester/API/#document-endpoints","title":"Document Endpoints","text":""},{"location":"ingester/API/#get-apiv1document","title":"GET /api/v1/document/","text":"<p>Get documents by source or batch ID.</p> <p>Query Parameters: - <code>source</code> (string, optional) - Source identifier to filter documents - <code>batch_id</code> (integer, optional) - Batch ID to filter documents</p> <p>Response: - <code>200 OK</code> - Array of DocumentURI objects - <code>400 Bad Request</code> - Neither source nor batch_id provided</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/document/?batch_id=1\"\n</code></pre></p>"},{"location":"ingester/API/#post-apiv1documentingest-document","title":"POST /api/v1/document/ingest-document","text":"<p>Ingest a new document into the system.</p> <p>Content-Type: <code>multipart/form-data</code></p> <p>Form Parameters: - <code>file</code> (file, optional) - Document file to upload - <code>input_uri</code> (string, optional) - URI to fetch document from - <code>mime_type</code> (string, optional) - MIME type of the document - <code>source_uri</code> (string, required) - Source URI/path identifier - <code>source</code> (string, required) - Source system identifier - <code>batch_id</code> (integer, required) - Batch ID to assign document - <code>doc_meta</code> (string, optional) - JSON string of metadata (default: <code>{}</code>) - <code>priority</code> (integer, optional) - Processing priority (default: 0)</p> <p>Response: - <code>201 Created</code> - Document ingested successfully - <code>400 Bad Request</code> - Invalid parameters or metadata - <code>500 Internal Server Error</code> - Processing error</p> <p>Success Response Body: <pre><code>{\n  \"batch_id\": 1,\n  \"document_uri\": \"/path/to/doc.pdf\",\n  \"document_hash\": \"sha256-abc123...\",\n  \"source\": \"filesystem\",\n  \"uri_id\": 42\n}\n</code></pre></p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/api/v1/document/ingest-document\" \\\n  -F \"file=@document.pdf\" \\\n  -F \"source_uri=/documents/report.pdf\" \\\n  -F \"source=filesystem\" \\\n  -F \"batch_id=1\" \\\n  -F \"doc_meta={\\\"author\\\":\\\"John Doe\\\"}\"\n</code></pre></p>"},{"location":"ingester/API/#batch-endpoints","title":"Batch Endpoints","text":""},{"location":"ingester/API/#get-apiv1batch","title":"GET /api/v1/batch/","text":"<p>List all document batches.</p> <p>Response: - <code>200 OK</code> - Array of DocumentBatch objects</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/batch/\"\n</code></pre></p>"},{"location":"ingester/API/#post-apiv1batch","title":"POST /api/v1/batch/","text":"<p>Create a new document batch.</p> <p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Form Parameters: - <code>source</code> (string, required) - Source system identifier - <code>name</code> (string, required) - Human-readable batch name</p> <p>Response: - <code>201 Created</code> - Batch created successfully</p> <p>Response Body: <pre><code>{\n  \"batch_id\": 1\n}\n</code></pre></p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/api/v1/batch/\" \\\n  -d \"source=filesystem\" \\\n  -d \"name=Q4 Reports\"\n</code></pre></p>"},{"location":"ingester/API/#post-apiv1batchstart-workflows","title":"POST /api/v1/batch/start-workflows","text":"<p>Start workflow processing for all documents in a batch.</p> <p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Form Parameters: - <code>batch_id</code> (integer, required) - Batch ID to process - <code>workflow_definition_id</code> (string, optional) - Workflow to use (default: from config) - <code>priority</code> (integer, optional) - Processing priority (default: 0) - <code>param_id</code> (string, optional) - Parameter set ID (default: \"default\")</p> <p>Response: - <code>201 Created</code> - Workflows started successfully - <code>404 Not Found</code> - Batch not found - <code>500 Internal Server Error</code> - Processing error</p> <p>Response Body: <pre><code>{\n  \"message\": \"Workflows started\",\n  \"workflows\": 10,\n  \"run_group\": 5\n}\n</code></pre></p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/api/v1/batch/start-workflows\" \\\n  -d \"batch_id=1\" \\\n  -d \"workflow_definition_id=batch\" \\\n  -d \"param_id=default\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1batchstatus","title":"GET /api/v1/batch/status","text":"<p>Get detailed status for a batch.</p> <p>Query Parameters: - <code>batch_id</code> (integer, required) - Batch ID</p> <p>Response: - <code>200 OK</code> - Batch status details - <code>404 Not Found</code> - Batch not found</p> <p>Response Body: <pre><code>{\n  \"batch\": {\n    \"id\": 1,\n    \"name\": \"Q4 Reports\",\n    \"source\": \"filesystem\",\n    \"start_date\": \"2025-01-15T10:00:00\",\n    \"completed_date\": null\n  },\n  \"document_count\": 10,\n  \"workflow_count\": {\n    \"COMPLETED\": 7,\n    \"RUNNING\": 2,\n    \"PENDING\": 1\n  },\n  \"workflows\": [...],\n  \"parsed\": 7,\n  \"remaining\": 3\n}\n</code></pre></p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/batch/status?batch_id=1\"\n</code></pre></p>"},{"location":"ingester/API/#workflow-endpoints","title":"Workflow Endpoints","text":""},{"location":"ingester/API/#get-apiv1workflow","title":"GET /api/v1/workflow/","text":"<p>Get workflow runs, optionally filtered by batch ID.</p> <p>Query Parameters: - <code>batch_id</code> (integer, optional) - Filter by batch ID</p> <p>Response: - <code>200 OK</code> - Array of WorkflowRun objects</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/?batch_id=1\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowby-status","title":"GET /api/v1/workflow/by-status","text":"<p>Get workflow runs filtered by status.</p> <p>Query Parameters: - <code>status</code> (enum, required) - One of: PENDING, RUNNING, COMPLETED, ERROR, FAILED - <code>batch_id</code> (integer, optional) - Filter by batch ID</p> <p>Response: - <code>200 OK</code> - Array of WorkflowRun objects</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/by-status?status=FAILED\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowdefinitions","title":"GET /api/v1/workflow/definitions","text":"<p>List all available workflow definitions.</p> <p>Response: - <code>200 OK</code> - Array of workflow definition summaries</p> <p>Response Body: <pre><code>[\n  {\n    \"id\": \"batch\",\n    \"name\": \"Batch Workflow\"\n  },\n  {\n    \"id\": \"interactive\",\n    \"name\": \"Interactive Workflow\"\n  }\n]\n</code></pre></p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/definitions\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowdefinitionsworkflow_id","title":"GET /api/v1/workflow/definitions/{workflow_id}","text":"<p>Get detailed workflow definition by ID.</p> <p>Path Parameters: - <code>workflow_id</code> (string, required) - Workflow definition ID</p> <p>Response: - <code>200 OK</code> - Complete WorkflowDefinition object - <code>404 Not Found</code> - Workflow definition not found</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/definitions/batch\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowparam-sets","title":"GET /api/v1/workflow/param-sets","text":"<p>List all available parameter sets.</p> <p>Response: - <code>200 OK</code> - Array of parameter set summaries</p> <p>Response Body: <pre><code>[\n  {\n    \"id\": \"default\",\n    \"name\": \"Default Parameters\"\n  },\n  {\n    \"id\": \"high_quality\",\n    \"name\": \"High Quality Processing\"\n  }\n]\n</code></pre></p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/param-sets\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowparam-setsset_id","title":"GET /api/v1/workflow/param-sets/{set_id}","text":"<p>Get parameter set by ID.</p> <p>Path Parameters: - <code>set_id</code> (string, required) - Parameter set ID</p> <p>Response: - <code>200 OK</code> - Complete WorkflowParams object - <code>404 Not Found</code> - Parameter set not found</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/param-sets/default\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowparam-setstargettarget","title":"GET /api/v1/workflow/param-sets/target/{target}","text":"<p>Get parameter sets that target a specific LanceDB directory.</p> <p>Path Parameters: - <code>target</code> (string, required) - LanceDB data directory path</p> <p>Response: - <code>200 OK</code> - Array of matching WorkflowParams objects</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/param-sets/target/lancedb\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowsteps","title":"GET /api/v1/workflow/steps","text":"<p>Get workflow steps filtered by status.</p> <p>Query Parameters: - <code>status</code> (enum, required) - One of: PENDING, RUNNING, COMPLETED, ERROR, FAILED</p> <p>Response: - <code>200 OK</code> - Array of RunStep objects</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/steps?status=RUNNING\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowrun-groups","title":"GET /api/v1/workflow/run-groups","text":"<p>Get workflow run groups, optionally filtered by batch ID.</p> <p>Query Parameters: - <code>batch_id</code> (integer, optional) - Filter by batch ID</p> <p>Response: - <code>200 OK</code> - Array of RunGroup objects - <code>500 Internal Server Error</code> - Processing error</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/run-groups?batch_id=1\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowrun-groupsrun_group_id","title":"GET /api/v1/workflow/run-groups/{run_group_id}","text":"<p>Get specific run group by ID.</p> <p>Path Parameters: - <code>run_group_id</code> (integer, required) - Run group ID</p> <p>Response: - <code>200 OK</code> - RunGroup object - <code>500 Internal Server Error</code> - Processing error</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/run-groups/5\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowrun-groupsrun_group_idstats","title":"GET /api/v1/workflow/run-groups/{run_group_id}/stats","text":"<p>Get statistics for a run group.</p> <p>Path Parameters: - <code>run_group_id</code> (integer, required) - Run group ID</p> <p>Response: - <code>200 OK</code> - Statistics object with status counts and durations - <code>500 Internal Server Error</code> - Processing error</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/run-groups/5/stats\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowruns","title":"GET /api/v1/workflow/runs","text":"<p>Get workflow runs for a batch.</p> <p>Query Parameters: - <code>batch_id</code> (integer, required) - Batch ID</p> <p>Response: - <code>200 OK</code> - Array of WorkflowRun objects</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/runs?batch_id=1\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowrunsworkflow_id","title":"GET /api/v1/workflow/runs/{workflow_id}","text":"<p>Get specific workflow run by ID, including steps.</p> <p>Path Parameters: - <code>workflow_id</code> (integer, required) - Workflow run ID</p> <p>Response: - <code>200 OK</code> - WorkflowRun object with steps array</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/runs/42\"\n</code></pre></p>"},{"location":"ingester/API/#get-apiv1workflowrunsworkflow_idlifecycle","title":"GET /api/v1/workflow/runs/{workflow_id}/lifecycle","text":"<p>Get lifecycle history events for a specific workflow run.</p> <p>Path Parameters: - <code>workflow_id</code> (integer, required) - Workflow run ID</p> <p>Response: - <code>200 OK</code> - Array of LifecycleHistory objects ordered by start_date - <code>400 Bad Request</code> - Invalid workflow ID - <code>500 Internal Server Error</code> - Processing error</p> <p>Response Body: <pre><code>[\n  {\n    \"id\": 1,\n    \"event\": \"item_start\",\n    \"run_group_id\": 5,\n    \"workflow_run_id\": 42,\n    \"step_id\": null,\n    \"start_date\": \"2025-01-15T10:00:00\",\n    \"completed_date\": \"2025-01-15T10:01:30\",\n    \"status\": \"COMPLETED\",\n    \"status_date\": \"2025-01-15T10:01:30\",\n    \"status_message\": \"Item processing completed successfully\",\n    \"status_meta\": {}\n  }\n]\n</code></pre></p> <p>Event Types: - <code>group_start</code> / <code>group_end</code> - Run group lifecycle - <code>item_start</code> / <code>item_end</code> / <code>item_failed</code> - Item processing lifecycle - <code>step_start</code> / <code>step_end</code> / <code>step_failed</code> - Individual step lifecycle</p> <p>Example: <pre><code>curl \"http://localhost:8000/api/v1/workflow/runs/42/lifecycle\"\n</code></pre></p>"},{"location":"ingester/API/#post-apiv1workflow","title":"POST /api/v1/workflow/","text":"<p>Start a new workflow run for a single document.</p> <p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Form Parameters: - <code>doc_id</code> (string, required) - Document hash to process - <code>workflow_definition_id</code> (string, optional) - Workflow to use - <code>param_id</code> (string, optional) - Parameter set ID - <code>priority</code> (integer, optional) - Processing priority (default: 0)</p> <p>Response: - <code>201 Created</code> - Workflow run created - <code>500 Internal Server Error</code> - Processing error</p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/api/v1/workflow/\" \\\n  -d \"doc_id=sha256-abc123...\" \\\n  -d \"workflow_definition_id=batch\" \\\n  -d \"priority=10\"\n</code></pre></p>"},{"location":"ingester/API/#post-apiv1workflowretry","title":"POST /api/v1/workflow/retry","text":"<p>Retry failed workflow steps for a run group.</p> <p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Form Parameters: - <code>run_group_id</code> (integer, required) - Run group ID to retry</p> <p>Response: - <code>201 Created</code> - Failed steps reset successfully - <code>500 Internal Server Error</code> - Processing error</p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/api/v1/workflow/retry\" \\\n  -d \"run_group_id=5\"\n</code></pre></p>"},{"location":"ingester/API/#source-status-endpoint","title":"Source Status Endpoint","text":""},{"location":"ingester/API/#post-apiv1source-status","title":"POST /api/v1/source-status","text":"<p>Check document status for a source system.</p> <p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Form Parameters: - <code>source</code> (string, required) - Source system identifier - <code>hashes</code> (string, required) - JSON object mapping URIs to hashes</p> <p>Response: - <code>200 OK</code> - Status object indicating new/changed/deleted documents</p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/api/v1/source-status\" \\\n  -d \"source=filesystem\" \\\n  -d 'hashes={\"file1.pdf\":\"sha256-abc\",\"file2.pdf\":\"sha256-def\"}'\n</code></pre></p>"},{"location":"ingester/API/#data-models","title":"Data Models","text":""},{"location":"ingester/API/#documentbatch","title":"DocumentBatch","text":"<pre><code>{\n  \"id\": 1,\n  \"name\": \"Q4 Reports\",\n  \"source\": \"filesystem\",\n  \"start_date\": \"2025-01-15T10:00:00\",\n  \"completed_date\": null,\n  \"batch_params\": {},\n  \"duration\": null\n}\n</code></pre>"},{"location":"ingester/API/#document","title":"Document","text":"<pre><code>{\n  \"hash\": \"sha256-abc123...\",\n  \"mime_type\": \"application/pdf\",\n  \"file_size\": 1024000,\n  \"doc_meta\": {\"author\": \"John Doe\"},\n\n}\n</code></pre>"},{"location":"ingester/API/#documenturi","title":"DocumentURI","text":"<pre><code>{\n  \"id\": 42,\n  \"doc_hash\": \"sha256-abc123...\",\n  \"uri\": \"/documents/report.pdf\",\n  \"source\": \"filesystem\",\n  \"version\": 1,\n  \"batch_id\": 1\n}\n</code></pre>"},{"location":"ingester/API/#workflowrun","title":"WorkflowRun","text":"<pre><code>{\n  \"id\": 100,\n  \"workflow_definition_id\": \"batch\",\n  \"run_group_id\": 5,\n  \"batch_id\": 1,\n  \"doc_id\": \"sha256-abc123...\",\n  \"priority\": 0,\n  \"created_date\": \"2025-01-15T10:00:00\",\n  \"start_date\": \"2025-01-15T10:01:00\",\n  \"completed_date\": null,\n  \"status\": \"RUNNING\",\n  \"status_date\": \"2025-01-15T10:05:00\",\n  \"status_message\": null,\n  \"status_meta\": {},\n  \"run_params\": {},\n  \"duration\": null\n}\n</code></pre>"},{"location":"ingester/API/#runstep","title":"RunStep","text":"<pre><code>{\n  \"id\": 500,\n  \"workflow_run_id\": 100,\n  \"workflow_step_number\": 2,\n  \"workflow_step_name\": \"parse\",\n  \"step_config_id\": 10,\n  \"step_type\": \"parse\",\n  \"is_last_step\": false,\n  \"created_date\": \"2025-01-15T10:01:00\",\n  \"priority\": 0,\n  \"start_date\": \"2025-01-15T10:02:00\",\n  \"status_date\": \"2025-01-15T10:05:00\",\n  \"completed_date\": null,\n  \"retry\": 0,\n  \"retries\": 3,\n  \"status\": \"RUNNING\",\n  \"status_message\": null,\n  \"status_meta\": {},\n  \"worker_id\": \"worker-abc-123\",\n  \"duration\": null\n}\n</code></pre>"},{"location":"ingester/API/#runstatus-enum","title":"RunStatus Enum","text":"<ul> <li><code>PENDING</code> - Not yet started</li> <li><code>RUNNING</code> - Currently executing</li> <li><code>COMPLETED</code> - Finished successfully</li> <li><code>ERROR</code> - Failed but will retry</li> <li><code>FAILED</code> - Permanently failed after all retries</li> </ul>"},{"location":"ingester/API/#workflowsteptype-enum","title":"WorkflowStepType Enum","text":"<ul> <li><code>ingest</code> - Load document</li> <li><code>validate</code> - Validate document</li> <li><code>parse</code> - Extract text/structure</li> <li><code>chunk</code> - Split into chunks</li> <li><code>embed</code> - Generate embeddings</li> <li><code>store</code> - Save to RAG system</li> <li><code>enrich</code> - Add metadata</li> <li><code>route</code> - Conditional routing</li> </ul>"},{"location":"ingester/API/#error-responses","title":"Error Responses","text":"<p>All error responses follow this format:</p> <pre><code>{\n  \"error\": \"Error message describing what went wrong\",\n  \"status_code\": 400\n}\n</code></pre> <p>Common HTTP status codes: - <code>400 Bad Request</code> - Invalid parameters - <code>404 Not Found</code> - Resource not found - <code>500 Internal Server Error</code> - Server-side error</p>"},{"location":"ingester/API/#rate-limiting","title":"Rate Limiting","text":"<p>Currently, no rate limiting is implemented. For production deployments, consider adding rate limiting middleware.</p>"},{"location":"ingester/API/#openapiswagger-documentation","title":"OpenAPI/Swagger Documentation","text":"<p>Interactive API documentation is available at: - Swagger UI: <code>http://localhost:8000/docs</code> - ReDoc: <code>http://localhost:8000/redoc</code></p>"},{"location":"ingester/ARCHITECTURE/","title":"Soliplex Ingester Architecture","text":""},{"location":"ingester/ARCHITECTURE/#overview","title":"Overview","text":"<p>Soliplex Ingester is a document processing and RAG (Retrieval-Augmented Generation) ingestion system designed to handle large-scale document workflows. It provides a FastAPI-based REST API, workflow orchestration, and integration with document parsing and embedding services.</p>"},{"location":"ingester/ARCHITECTURE/#system-components","title":"System Components","text":""},{"location":"ingester/ARCHITECTURE/#1-fastapi-server","title":"1. FastAPI Server","text":"<p>The server provides REST API endpoints for document and workflow management:</p> <ul> <li>Document Routes (<code>/api/v1/document/*</code>) - Document upload, retrieval, and management</li> <li>Batch Routes (<code>/api/v1/batch/*</code>) - Batch processing operations</li> <li>Workflow Routes (<code>/api/v1/workflow/*</code>) - Workflow execution and monitoring</li> <li>Stats Routes (<code>/api/v1/stats/*</code>) - System statistics and metrics</li> </ul> <p>Server entry point: <code>src/soliplex_ingester/server/__init__.py:30</code></p>"},{"location":"ingester/ARCHITECTURE/#2-workflow-system","title":"2. Workflow System","text":"<p>The workflow system orchestrates multi-step document processing pipelines:</p> <pre><code>Document \u2192 Validate \u2192 Parse \u2192 Chunk \u2192 Embed \u2192 Store\n</code></pre> <p>Workflow Components:</p> <ul> <li>WorkflowDefinition - Defines the steps and lifecycle events for a workflow</li> <li>WorkflowRun - Represents a single execution instance for one document</li> <li>RunGroup - Groups multiple workflow runs together</li> <li>RunStep - Individual step execution within a workflow run</li> </ul> <p>Step Types: - <code>INGEST</code> - Load document into system - <code>VALIDATE</code> - Validate document format and content - <code>PARSE</code> - Extract text and structure from document - <code>CHUNK</code> - Split document into semantic chunks - <code>EMBED</code> - Generate vector embeddings - <code>STORE</code> - Save to RAG system (LanceDB + HaikuRAG) - <code>ENRICH</code> - Add metadata or additional processing - <code>ROUTE</code> - Conditional routing logic</p> <p>Implementation: <code>src/soliplex_ingester/lib/wf/</code></p>"},{"location":"ingester/ARCHITECTURE/#3-worker-system","title":"3. Worker System","text":"<p>Async workers process workflow steps concurrently:</p> <ul> <li>Workers poll for pending workflow steps</li> <li>Configurable concurrency levels for different operations</li> <li>Automatic retry logic with configurable retry counts</li> <li>Health check/heartbeat system via <code>WorkerCheckin</code></li> </ul> <p>Worker implementation: <code>src/soliplex_ingester/lib/wf/runner.py</code></p>"},{"location":"ingester/ARCHITECTURE/#4-storage-layer","title":"4. Storage Layer","text":"<p>Database: - SQLModel + SQLAlchemy with async support - Supports SQLite (dev) and PostgreSQL (production) - Alembic for migrations</p> <p>File Storage: - Configurable backends (filesystem, S3-compatible via OpenDAL) - Separate storage locations for different artifact types:   - Raw documents   - Parsed markdown   - Parsed JSON   - Chunks   - Embeddings</p> <p>Vector Storage: - LanceDB for vector embeddings - HaikuRAG client for retrieval operations</p>"},{"location":"ingester/ARCHITECTURE/#5-document-processing-pipeline","title":"5. Document Processing Pipeline","text":"<pre><code>graph LR\n    A[Upload Document] --&gt; B[Create DocumentURI]\n    B --&gt; C[Hash &amp; Store as Document]\n    C --&gt; D[Queue Workflow Run]\n    D --&gt; E[Validate Step]\n    E --&gt; F[Parse with Docling]\n    F --&gt; G[Chunk Text]\n    G --&gt; H[Generate Embeddings]\n    H --&gt; I[Store in LanceDB]\n    I --&gt; J[Update RAG Index]\n</code></pre>"},{"location":"ingester/ARCHITECTURE/#6-external-services","title":"6. External Services","text":"<p>Docling Server: - Document parsing service - Extracts text, structure, and metadata - Configurable via <code>DOCLING_SERVER_URL</code></p> <p>HaikuRAG: - RAG backend for document retrieval - Vector search and document management - Optional (controlled by <code>DO_RAG</code> setting)</p>"},{"location":"ingester/ARCHITECTURE/#data-flow","title":"Data Flow","text":""},{"location":"ingester/ARCHITECTURE/#document-ingestion-flow","title":"Document Ingestion Flow","text":"<ol> <li>Upload - Client uploads document via <code>/api/v1/document/upload</code></li> <li>Hash &amp; Dedupe - System computes SHA256 hash, checks for duplicates</li> <li>Create URI - Maps source URI to document hash</li> <li>Batch Assignment - Associates document with processing batch</li> <li>Workflow Creation - Creates WorkflowRun and RunSteps</li> <li>Worker Processing - Workers pick up and execute steps</li> <li>Status Updates - Database tracks step and run status</li> <li>Completion - Document marked complete when all steps succeed</li> </ol>"},{"location":"ingester/ARCHITECTURE/#workflow-execution-flow","title":"Workflow Execution Flow","text":"<ol> <li>Worker Startup - Worker registers and starts polling</li> <li>Step Selection - Worker queries for PENDING steps with <code>FOR UPDATE</code> lock</li> <li>Status Transition - PENDING \u2192 RUNNING \u2192 COMPLETED/ERROR/FAILED</li> <li>Step Execution - Calls registered handler method</li> <li>Artifact Storage - Saves intermediate results</li> <li>Retry Logic - Automatic retry on ERROR status</li> <li>Run Completion - Aggregates step status to run status</li> <li>Group Completion - Aggregates run status to group status</li> </ol>"},{"location":"ingester/ARCHITECTURE/#configuration","title":"Configuration","text":"<p>Configuration via environment variables with <code>pydantic-settings</code>:</p> <ul> <li>Database connection</li> <li>File storage paths</li> <li>Worker concurrency settings</li> <li>External service URLs</li> <li>Workflow and parameter directories</li> </ul> <p>See <code>src/soliplex_ingester/lib/config.py:15</code> for full configuration schema.</p>"},{"location":"ingester/ARCHITECTURE/#scalability","title":"Scalability","text":"<p>Horizontal Scaling: - Multiple workers can run concurrently - Database row-level locking prevents duplicate processing - Stateless API servers can be load balanced</p> <p>Vertical Scaling: - Configurable concurrency per worker - Batch size controls for embedding operations - Connection pooling for database access</p> <p>Workflow Parallelism: - Multiple workflows can process simultaneously - Steps within a workflow run sequentially - Different documents process independently</p>"},{"location":"ingester/ARCHITECTURE/#technology-stack","title":"Technology Stack","text":"<ul> <li>Web Framework: FastAPI 0.120+</li> <li>Database ORM: SQLModel 0.0.27+</li> <li>Async Runtime: asyncio</li> <li>CLI: Typer</li> <li>Document Parsing: Docling</li> <li>Vector DB: LanceDB 0.25+</li> <li>RAG: HaikuRAG</li> <li>Storage: OpenDAL (multi-backend support)</li> </ul>"},{"location":"ingester/ARCHITECTURE/#extension-points","title":"Extension Points","text":"<p>Custom Workflow Steps: Define custom step handlers by: 1. Creating a new async function matching the EventHandler signature 2. Registering in workflow YAML configuration 3. Implementing retry logic and error handling</p> <p>Custom Storage Backends: Configure via <code>FILE_STORE_TARGET</code> environment variable and OpenDAL configuration.</p> <p>Custom Lifecycle Events: Add event handlers in workflow configuration to respond to: - <code>GROUP_START</code> / <code>GROUP_END</code> - <code>ITEM_START</code> / <code>ITEM_END</code> - <code>STEP_START</code> / <code>STEP_END</code> - <code>ITEM_FAILED</code> / <code>STEP_FAILED</code></p>"},{"location":"ingester/ARCHITECTURE/#monitoring","title":"Monitoring","text":"<p>Database Tables: - <code>workflowrun</code> - Track run status and duration - <code>runstep</code> - Monitor individual step execution - <code>workcheckin</code> - Worker health and activity - <code>lifecyclehistory</code> - Audit trail of events</p> <p>Metrics Available: - Document processing throughput - Step success/failure rates - Worker utilization - Processing durations - Batch completion times</p> <p>Access via <code>/api/v1/stats/*</code> endpoints.</p>"},{"location":"ingester/CLI/","title":"CLI Reference","text":""},{"location":"ingester/CLI/#overview","title":"Overview","text":"<p>Soliplex Ingester provides a command-line interface (CLI) built with Typer. The CLI binary is named <code>si-cli</code>.</p> <p>Installation: After installing the package, the <code>si-cli</code> command is available: <pre><code>pip install -e .\nsi-cli --help\n</code></pre></p> <p>Entry Point: <code>src/soliplex_ingester/cli.py:35</code></p>"},{"location":"ingester/CLI/#global-options","title":"Global Options","text":"<p>All commands support these options:</p> <pre><code>si-cli --help           # Show help for all commands\nsi-cli COMMAND --help   # Show help for specific command\n</code></pre> <p>Initialization: Before running any command, the CLI automatically: 1. Validates settings 2. Sets up logging based on <code>LOG_LEVEL</code></p>"},{"location":"ingester/CLI/#commands","title":"Commands","text":""},{"location":"ingester/CLI/#validate-settings","title":"validate-settings","text":"<p>Validate and display application settings.</p> <p>Usage: <pre><code>si-cli validate-settings\n</code></pre></p> <p>Description: - Validates all environment variables - Displays current configuration - Exits with error code if validation fails</p> <p>Example Output: <pre><code>doc_db_url='sqlite+aiosqlite:///./db/documents.db'\ndocling_server_url='http://localhost:5001/v1'\ndocling_http_timeout=600\nlog_level='INFO'\nfile_store_target='fs'\nfile_store_dir='file_store'\n...\n</code></pre></p> <p>Error Output: <pre><code>invalid settings\n{'type': 'missing', 'loc': ('doc_db_url',), 'msg': 'Field required'}\n</code></pre></p> <p>Exit Codes: - <code>0</code> - Settings valid - <code>1</code> - Validation failed</p> <p>Implementation: <code>src/soliplex_ingester/cli.py:38</code></p>"},{"location":"ingester/CLI/#db-init","title":"db-init","text":"<p>Initialize database tables and run migrations.</p> <p>Usage: <pre><code>si-cli db-init\n</code></pre></p> <p>Description: - Creates all database tables using SQLModel metadata - Runs Alembic migrations to latest version - Idempotent (safe to run multiple times)</p> <p>Prerequisites: - <code>DOC_DB_URL</code> environment variable must be set - Database server must be accessible - User must have CREATE TABLE permissions</p> <p>Example: <pre><code>export DOC_DB_URL=\"sqlite+aiosqlite:///./db/documents.db\"\nsi-cli db-init\n</code></pre></p> <p>Notes: - For SQLite, creates database file if it doesn't exist - For PostgreSQL, database must already exist - Uses synchronous SQLAlchemy engine (not async)</p> <p>Implementation: <code>src/soliplex_ingester/cli.py:68</code></p>"},{"location":"ingester/CLI/#serve","title":"serve","text":"<p>Start the FastAPI web server.</p> <p>Usage: <pre><code>si-cli serve [OPTIONS]\n</code></pre></p> <p>Options:</p> Option Short Type Default Description <code>--host</code> <code>-h</code> str <code>127.0.0.1</code> Bind address <code>--port</code> <code>-p</code> int <code>8000</code> Port number <code>--uds</code> - str None Unix domain socket path <code>--fd</code> - int None File descriptor to bind <code>--reload</code> <code>-r</code> bool False Auto-reload on file changes <code>--workers</code> - int None Number of worker processes <code>--access-log</code> - bool None Enable/disable access log <code>--proxy-headers</code> - bool None Trust proxy headers <code>--forwarded-allow-ips</code> - str None IPs to trust for proxy headers <p>Examples:</p> <p>Basic server: <pre><code>si-cli serve\n</code></pre></p> <p>Custom host and port: <pre><code>si-cli serve --host 0.0.0.0 --port 9000\n</code></pre></p> <p>Development mode with auto-reload: <pre><code>si-cli serve --reload\n</code></pre></p> <p>Production with multiple workers: <pre><code>si-cli serve --workers 4 --host 0.0.0.0\n</code></pre></p> <p>Unix socket: <pre><code>si-cli serve --uds /tmp/soliplex.sock\n</code></pre></p> <p>Behind proxy: <pre><code>si-cli serve --proxy-headers --forwarded-allow-ips \"10.0.0.0/8\"\n</code></pre></p> <p>Reload Configuration: When <code>--reload</code> is enabled: - Watches Python files in <code>soliplex_ingester</code> package - Watches <code>*.yaml</code>, <code>*.yml</code>, <code>*.txt</code> files - Automatically restarts on changes</p> <p>Worker Note: The server automatically starts a background worker on startup. The worker processes workflow steps concurrently with serving API requests.</p> <p>Environment Variables: - <code>WEB_CONCURRENCY</code> - Default number of workers if not specified</p> <p>Implementation: <code>src/soliplex_ingester/cli.py:207</code></p>"},{"location":"ingester/CLI/#worker","title":"worker","text":"<p>Run a standalone workflow processing worker.</p> <p>Usage: <pre><code>si-cli worker\n</code></pre></p> <p>Description: - Starts a worker that polls for pending workflow steps - Executes steps according to workflow definitions - Runs indefinitely until interrupted (Ctrl+C)</p> <p>Behavior: - Registers worker with unique ID in database - Sends heartbeat every <code>WORKER_CHECKIN_INTERVAL</code> seconds - Processes steps based on priority and availability - Handles retries according to step configuration</p> <p>Example: <pre><code>si-cli worker\n</code></pre></p> <p>Multiple Workers: Run multiple instances for increased throughput: <pre><code># Terminal 1\nsi-cli worker\n\n# Terminal 2\nsi-cli worker\n\n# Terminal 3\nsi-cli worker\n</code></pre></p> <p>Graceful Shutdown: - Press <code>Ctrl+C</code> to stop worker - Worker will finish current step before exiting - Pending steps remain in database for other workers</p> <p>Monitoring: Check worker status via API: <pre><code>curl http://localhost:8000/api/v1/workflow/steps?status=RUNNING\n</code></pre></p> <p>Implementation: <code>src/soliplex_ingester/cli.py:148</code></p>"},{"location":"ingester/CLI/#validate-haiku","title":"validate-haiku","text":"<p>Validate HaikuRAG integration for a batch.</p> <p>Usage: <pre><code>si-cli validate-haiku BATCH_ID [OPTIONS]\n</code></pre></p> <p>Arguments: - <code>BATCH_ID</code> (int, required) - Batch ID to validate</p> <p>Options: - <code>--detail</code> (bool) - Show detailed output (not yet implemented)</p> <p>Description: - Checks all documents in batch - Verifies parsed markdown exists - Confirms documents are indexed in HaikuRAG - Reports any errors or missing documents</p> <p>Example: <pre><code>si-cli validate-haiku 1\n</code></pre></p> <p>Output: <pre><code>-----------results--------------\n found 10 results\n-----------fails--------------\n[\n  {\n    \"doc\": \"sha256-abc123...\",\n    \"haiku\": null,\n    \"message\": \"Document not found in HaikuRAG\",\n    \"status\": \"haiku error\"\n  }\n]\n</code></pre></p> <p>Status Values: - <code>success</code> - Document indexed correctly - <code>no_id</code> - Document has no <code>rag_id</code> (not yet stored) - <code>md error</code> - Parsed markdown not found - <code>haiku error</code> - Error fetching from HaikuRAG</p> <p>Implementation: <code>src/soliplex_ingester/cli.py:133</code></p>"},{"location":"ingester/CLI/#list-workflows","title":"list-workflows","text":"<p>List all available workflow definitions.</p> <p>Usage: <pre><code>si-cli list-workflows\n</code></pre></p> <p>Description: - Scans <code>WORKFLOW_DIR</code> for YAML files - Displays workflow IDs</p> <p>Example: <pre><code>si-cli list-workflows\n</code></pre></p> <p>Output: <pre><code>batch\nbatch_split\ninteractive\n</code></pre></p> <p>Implementation: <code>src/soliplex_ingester/cli.py:189</code></p>"},{"location":"ingester/CLI/#dump-workflow","title":"dump-workflow","text":"<p>Display complete workflow definition.</p> <p>Usage: <pre><code>si-cli dump-workflow WORKFLOW_ID\n</code></pre></p> <p>Arguments: - <code>WORKFLOW_ID</code> (str, required) - Workflow definition ID</p> <p>Description: - Loads workflow from YAML - Displays as formatted JSON</p> <p>Example: <pre><code>si-cli dump-workflow batch\n</code></pre></p> <p>Output: <pre><code>{\n  \"id\": \"batch\",\n  \"name\": \"Batch Workflow\",\n  \"meta\": {},\n  \"item_steps\": {\n    \"validate\": {\n      \"name\": \"docling validate\",\n      \"retries\": 3,\n      \"method\": \"soliplex_ingester.lib.workflow.validate_document\",\n      \"parameters\": {}\n    },\n    ...\n  },\n  \"lifecycle_events\": null\n}\n</code></pre></p> <p>Implementation: <code>src/soliplex_ingester/cli.py:162</code></p>"},{"location":"ingester/CLI/#list-param-sets","title":"list-param-sets","text":"<p>List all available parameter sets.</p> <p>Usage: <pre><code>si-cli list-param-sets\n</code></pre></p> <p>Description: - Scans <code>PARAM_DIR</code> for YAML files - Displays parameter set IDs</p> <p>Example: <pre><code>si-cli list-param-sets\n</code></pre></p> <p>Output: <pre><code>default\nhigh_quality\nfast_processing\n</code></pre></p> <p>Implementation: <code>src/soliplex_ingester/cli.py:201</code></p>"},{"location":"ingester/CLI/#dump-param-set","title":"dump-param-set","text":"<p>Display complete parameter set configuration.</p> <p>Usage: <pre><code>si-cli dump-param-set [PARAM_ID]\n</code></pre></p> <p>Arguments: - <code>PARAM_ID</code> (str, optional) - Parameter set ID (default: \"default\")</p> <p>Description: - Loads parameter set from YAML - Displays as formatted JSON</p> <p>Example: <pre><code>si-cli dump-param-set default\n</code></pre></p> <p>Output: <pre><code>{\n  \"id\": \"default\",\n  \"name\": \"Default Parameters\",\n  \"meta\": {},\n  \"config\": {\n    \"parse\": {\n      \"format\": \"markdown\",\n      \"ocr_enabled\": true\n    },\n    \"chunk\": {\n      \"chunk_size\": 512,\n      \"chunk_overlap\": 50\n    },\n    ...\n  }\n}\n</code></pre></p> <p>Implementation: <code>src/soliplex_ingester/cli.py:175</code></p>"},{"location":"ingester/CLI/#usage-patterns","title":"Usage Patterns","text":""},{"location":"ingester/CLI/#development-workflow","title":"Development Workflow","text":"<p>1. Validate configuration: <pre><code>si-cli validate-settings\n</code></pre></p> <p>2. Initialize database: <pre><code>si-cli db-init\n</code></pre></p> <p>3. Start server with reload: <pre><code>si-cli serve --reload\n</code></pre></p> <p>4. (Optional) Start additional workers: <pre><code>si-cli worker\n</code></pre></p>"},{"location":"ingester/CLI/#production-deployment","title":"Production Deployment","text":"<p>1. Validate configuration: <pre><code>si-cli validate-settings\n</code></pre></p> <p>2. Run migrations: <pre><code>si-cli db-init\n</code></pre></p> <p>3. Start server with multiple workers: <pre><code>si-cli serve --host 0.0.0.0 --port 8000 --workers 4\n</code></pre></p> <p>4. Start dedicated worker processes: <pre><code># In separate terminals/services\nsi-cli worker  # Process 1\nsi-cli worker  # Process 2\nsi-cli worker  # Process 3\n</code></pre></p>"},{"location":"ingester/CLI/#batch-processing","title":"Batch Processing","text":"<p>1. Create batch and ingest documents: <pre><code># Use API or client library\ncurl -X POST http://localhost:8000/api/v1/batch/ \\\n  -d \"source=filesystem\" \\\n  -d \"name=Test Batch\"\n</code></pre></p> <p>2. Start workflows: <pre><code>curl -X POST http://localhost:8000/api/v1/batch/start-workflows \\\n  -d \"batch_id=1\" \\\n  -d \"workflow_definition_id=batch\"\n</code></pre></p> <p>3. Start workers to process: <pre><code>si-cli worker\n</code></pre></p> <p>4. Monitor progress: <pre><code>curl http://localhost:8000/api/v1/batch/status?batch_id=1\n</code></pre></p> <p>5. Validate results: <pre><code>si-cli validate-haiku 1\n</code></pre></p>"},{"location":"ingester/CLI/#configuration-management","title":"Configuration Management","text":"<p>List available workflows: <pre><code>si-cli list-workflows\n</code></pre></p> <p>Inspect workflow: <pre><code>si-cli dump-workflow batch\n</code></pre></p> <p>List parameter sets: <pre><code>si-cli list-param-sets\n</code></pre></p> <p>Inspect parameters: <pre><code>si-cli dump-param-set default\n</code></pre></p>"},{"location":"ingester/CLI/#troubleshooting","title":"Troubleshooting","text":"<p>Check configuration: <pre><code>si-cli validate-settings\n</code></pre></p> <p>Verify database connection: <pre><code>si-cli db-init\n</code></pre></p> <p>Test server startup: <pre><code>si-cli serve --host localhost --port 8000\n# Press Ctrl+C to stop\n</code></pre></p> <p>Check worker connectivity: <pre><code>si-cli worker\n# Should start without errors\n# Press Ctrl+C to stop\n</code></pre></p> <p>Validate batch processing: <pre><code>si-cli validate-haiku BATCH_ID\n</code></pre></p>"},{"location":"ingester/CLI/#exit-codes","title":"Exit Codes","text":"Code Meaning <code>0</code> Success <code>1</code> Configuration error / validation failed <code>130</code> Interrupted by user (Ctrl+C)"},{"location":"ingester/CLI/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects all configuration environment variables. Key ones for CLI usage:</p> <ul> <li><code>DOC_DB_URL</code> - Database connection (required)</li> <li><code>LOG_LEVEL</code> - Logging verbosity (DEBUG, INFO, WARNING, ERROR)</li> <li><code>WORKFLOW_DIR</code> - Workflow definitions directory</li> <li><code>PARAM_DIR</code> - Parameter sets directory</li> <li><code>DOCLING_SERVER_URL</code> - Docling service endpoint</li> </ul> <p>See CONFIGURATION.md for complete list.</p>"},{"location":"ingester/CLI/#logging","title":"Logging","text":""},{"location":"ingester/CLI/#log-levels","title":"Log Levels","text":"<p>Set via <code>LOG_LEVEL</code> environment variable:</p> <pre><code>LOG_LEVEL=DEBUG si-cli serve\n</code></pre> <p>Levels: - <code>DEBUG</code> - Detailed diagnostic information - <code>INFO</code> - General informational messages (default) - <code>WARNING</code> - Warning messages - <code>ERROR</code> - Error messages - <code>CRITICAL</code> - Critical error messages</p>"},{"location":"ingester/CLI/#log-output","title":"Log Output","text":"<p>Logs are written to stderr. Redirect as needed:</p> <pre><code>si-cli worker 2&gt;&amp;1 | tee worker.log\n</code></pre>"},{"location":"ingester/CLI/#log-format","title":"Log Format","text":"<p>Default format includes: - Timestamp - Log level - Logger name - Message</p> <p>Example: <pre><code>2025-01-15 10:00:00,123 INFO soliplex_ingester.cli Starting server\n2025-01-15 10:00:01,456 INFO soliplex_ingester.server Starting worker\n</code></pre></p>"},{"location":"ingester/CLI/#signal-handling","title":"Signal Handling","text":""},{"location":"ingester/CLI/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>The CLI handles signals for graceful shutdown:</p> <p>Signals: - <code>SIGINT</code> (Ctrl+C) - Graceful shutdown - <code>SIGTERM</code> - Graceful shutdown</p> <p>Behavior: 1. Stop accepting new work 2. Complete current operations 3. Clean up resources 4. Exit with code 0</p> <p>Example: <pre><code>si-cli worker\n# Press Ctrl+C\n# Worker completes current step and exits\n</code></pre></p>"},{"location":"ingester/CLI/#platform-notes","title":"Platform Notes","text":""},{"location":"ingester/CLI/#windows","title":"Windows","text":"<p>On Windows, the CLI automatically sets the event loop policy for compatibility:</p> <pre><code>if platform.system() == \"Windows\":\n    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n</code></pre> <p>This is handled automatically; no user action required.</p>"},{"location":"ingester/CLI/#unixlinux","title":"Unix/Linux","text":"<p>No special configuration needed.</p>"},{"location":"ingester/CLI/#running-with-python","title":"Running with Python","text":"<p>If <code>si-cli</code> is not in PATH, run directly:</p> <pre><code>python -m soliplex_ingester.cli --help\n</code></pre>"},{"location":"ingester/CLI/#docker-usage","title":"Docker Usage","text":"<p>Dockerfile CMD examples:</p> <p>Server: <pre><code>CMD [\"si-cli\", \"serve\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre></p> <p>Worker: <pre><code>CMD [\"si-cli\", \"worker\"]\n</code></pre></p> <p>Init container: <pre><code>CMD [\"si-cli\", \"db-init\"]\n</code></pre></p>"},{"location":"ingester/CLI/#systemd-service","title":"Systemd Service","text":"<p>Example service file:</p> <p>/etc/systemd/system/soliplex-ingester.service: <pre><code>[Unit]\nDescription=Soliplex Ingester API Server\nAfter=network.target postgresql.service\n\n[Service]\nType=simple\nUser=soliplex\nGroup=soliplex\nWorkingDirectory=/opt/soliplex-ingester\nEnvironmentFile=/etc/soliplex/config.env\nExecStart=/opt/soliplex-ingester/.venv/bin/si-cli serve --host 0.0.0.0 --port 8000\nRestart=on-failure\nRestartSec=5s\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <p>/etc/systemd/system/soliplex-worker@.service: <pre><code>[Unit]\nDescription=Soliplex Ingester Worker %i\nAfter=network.target postgresql.service\n\n[Service]\nType=simple\nUser=soliplex\nGroup=soliplex\nWorkingDirectory=/opt/soliplex-ingester\nEnvironmentFile=/etc/soliplex/config.env\nEnvironment=\"WORKER_ID=worker-%i\"\nExecStart=/opt/soliplex-ingester/.venv/bin/si-cli worker\nRestart=on-failure\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <p>Start services: <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable soliplex-ingester\nsudo systemctl start soliplex-ingester\nsudo systemctl enable soliplex-worker@{1..3}\nsudo systemctl start soliplex-worker@{1..3}\n</code></pre></p>"},{"location":"ingester/CLI/#future-commands","title":"Future Commands","text":"<p>Commands planned for future releases:</p> <ul> <li><code>si-cli batch create</code> - Create batch via CLI</li> <li><code>si-cli batch ingest</code> - Ingest documents from directory</li> <li><code>si-cli batch status</code> - Check batch status</li> <li><code>si-cli workflow retry</code> - Retry failed workflows</li> <li><code>si-cli stats</code> - Display system statistics</li> <li><code>si-cli clean</code> - Clean up old data</li> </ul>"},{"location":"ingester/CLI/#getting-help","title":"Getting Help","text":"<p>Command help: <pre><code>si-cli --help\nsi-cli serve --help\nsi-cli worker --help\n</code></pre></p> <p>Report issues: - GitHub: https://github.com/your-repo/soliplex-ingester/issues - Include <code>si-cli validate-settings</code> output - Include relevant logs with <code>LOG_LEVEL=DEBUG</code></p>"},{"location":"ingester/CONFIGURATION/","title":"Configuration Guide","text":""},{"location":"ingester/CONFIGURATION/#overview","title":"Overview","text":"<p>Soliplex Ingester is configured via environment variables using Pydantic Settings. All configuration is defined in <code>src/soliplex/ingester/lib/config.py:15</code>.</p>"},{"location":"ingester/CONFIGURATION/#environment-variables","title":"Environment Variables","text":""},{"location":"ingester/CONFIGURATION/#database-configuration","title":"Database Configuration","text":""},{"location":"ingester/CONFIGURATION/#doc_db_url-required","title":"DOC_DB_URL (required)","text":"<p>Database connection URL.</p> <p>SQLite Example: <pre><code>DOC_DB_URL=\"sqlite+aiosqlite:///./db/documents.db\"\n</code></pre></p> <p>PostgreSQL Example: <pre><code>DOC_DB_URL=\"postgresql+psycopg://username:password@localhost:5432/soliplex\"\n</code></pre></p> <p>Notes: - Must use async drivers (<code>aiosqlite</code> for SQLite or <code>psycopg</code> for PostgreSQL) - SQLite uses relative or absolute file paths - PostgreSQL requires credentials and network access</p>"},{"location":"ingester/CONFIGURATION/#external-services","title":"External Services","text":""},{"location":"ingester/CONFIGURATION/#docling_server_url","title":"DOCLING_SERVER_URL","text":"<p>Docling document parsing service endpoint.</p> <p>Default: <code>http://localhost:5001/v1</code></p> <p>Example: <pre><code>DOCLING_SERVER_URL=\"http://docling.internal.company.com/v1\"\n</code></pre></p> <p>Notes: - Used for document parsing (PDF, DOCX, etc.) - Must be accessible from worker nodes - Health check: <code>GET {url}/health</code></p>"},{"location":"ingester/CONFIGURATION/#docling_http_timeout","title":"DOCLING_HTTP_TIMEOUT","text":"<p>HTTP timeout for Docling requests in seconds.</p> <p>Default: <code>600</code> (10 minutes)</p> <p>Example: <pre><code>DOCLING_HTTP_TIMEOUT=300\n</code></pre></p> <p>Notes: - Large documents may require longer timeouts - Adjust based on document size and complexity</p>"},{"location":"ingester/CONFIGURATION/#logging","title":"Logging","text":""},{"location":"ingester/CONFIGURATION/#log_level","title":"LOG_LEVEL","text":"<p>Python logging level.</p> <p>Default: <code>INFO</code></p> <p>Options: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code></p> <p>Example: <pre><code>LOG_LEVEL=DEBUG\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#file-storage","title":"File Storage","text":""},{"location":"ingester/CONFIGURATION/#file_store_target","title":"FILE_STORE_TARGET","text":"<p>Storage backend type.</p> <p>Default: <code>fs</code> (filesystem)</p> <p>Options: - <code>fs</code> - Local filesystem - <code>s3</code> - S3-compatible storage (requires OpenDAL config)</p> <p>Example: <pre><code>FILE_STORE_TARGET=s3\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#file_store_dir","title":"FILE_STORE_DIR","text":"<p>Base directory for file storage.</p> <p>Default: <code>file_store</code></p> <p>Example: <pre><code>FILE_STORE_DIR=/var/lib/soliplex/files\n</code></pre></p> <p>Notes: - Used when <code>FILE_STORE_TARGET=fs</code> - Must be writable by the application user - Consider disk space requirements</p>"},{"location":"ingester/CONFIGURATION/#document_store_dir","title":"DOCUMENT_STORE_DIR","text":"<p>Subdirectory for raw documents.</p> <p>Default: <code>raw</code></p> <p>Full Path: <code>{FILE_STORE_DIR}/{DOCUMENT_STORE_DIR}</code></p>"},{"location":"ingester/CONFIGURATION/#parsed_markdown_store_dir","title":"PARSED_MARKDOWN_STORE_DIR","text":"<p>Subdirectory for parsed markdown.</p> <p>Default: <code>markdown</code></p>"},{"location":"ingester/CONFIGURATION/#parsed_json_store_dir","title":"PARSED_JSON_STORE_DIR","text":"<p>Subdirectory for parsed JSON.</p> <p>Default: <code>json</code></p>"},{"location":"ingester/CONFIGURATION/#chunks_store_dir","title":"CHUNKS_STORE_DIR","text":"<p>Subdirectory for text chunks.</p> <p>Default: <code>chunks</code></p>"},{"location":"ingester/CONFIGURATION/#embeddings_store_dir","title":"EMBEDDINGS_STORE_DIR","text":"<p>Subdirectory for embedding vectors.</p> <p>Default: <code>embeddings</code></p>"},{"location":"ingester/CONFIGURATION/#vector-database","title":"Vector Database","text":""},{"location":"ingester/CONFIGURATION/#lancedb_dir","title":"LANCEDB_DIR","text":"<p>Directory for LanceDB vector storage.</p> <p>Default: <code>lancedb</code></p> <p>Filesystem Example: <pre><code>LANCEDB_DIR=/var/lib/soliplex/lancedb\n</code></pre></p> <p>S3 Example: <pre><code>LANCEDB_DIR=s3://my-bucket/lancedb\n</code></pre></p> <p>Notes: - Local filesystem paths or S3 URIs are supported - When using S3, LanceDB requires standard AWS environment variables (see below) - Stores vector embeddings for RAG retrieval - Requires sufficient disk space (filesystem) or S3 bucket access - Periodically compact for performance</p> <p>Required AWS Environment Variables for S3: <pre><code>AWS_ACCESS_KEY_ID=your_access_key_id\nAWS_SECRET_ACCESS_KEY=your_secret_key\nAWS_REGION=us-east-1\n</code></pre></p> <p>Optional AWS Environment Variables: <pre><code># For S3-compatible providers (MinIO, SeaweedFS, etc.)\nAWS_ENDPOINT=http://127.0.0.1:8333\n\n# Required when using HTTP to connect to endpoint\nAWS_ALLOW_HTTP=1\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#worker-configuration","title":"Worker Configuration","text":""},{"location":"ingester/CONFIGURATION/#ingest_queue_concurrency","title":"INGEST_QUEUE_CONCURRENCY","text":"<p>Maximum concurrent queue operations.</p> <p>Default: <code>20</code></p> <p>Example: <pre><code>INGEST_QUEUE_CONCURRENCY=50\n</code></pre></p> <p>Notes: - Controls internal queue processing - Higher values increase throughput but use more memory</p>"},{"location":"ingester/CONFIGURATION/#ingest_worker_concurrency","title":"INGEST_WORKER_CONCURRENCY","text":"<p>Maximum concurrent workflow steps per worker.</p> <p>Default: <code>10</code></p> <p>Example: <pre><code>INGEST_WORKER_CONCURRENCY=20\n</code></pre></p> <p>Notes: - Primary throughput control - Balance against CPU and external service limits - Monitor resource usage when tuning</p>"},{"location":"ingester/CONFIGURATION/#docling_concurrency","title":"DOCLING_CONCURRENCY","text":"<p>Maximum concurrent Docling requests.</p> <p>Default: <code>3</code></p> <p>Example: <pre><code>DOCLING_CONCURRENCY=5\n</code></pre></p> <p>Notes: - Prevents overwhelming Docling service - Coordinate with Docling server capacity - Increase if Docling can handle load</p>"},{"location":"ingester/CONFIGURATION/#worker_task_count","title":"WORKER_TASK_COUNT","text":"<p>Number of workflow steps to fetch per query.</p> <p>Default: <code>5</code></p> <p>Example: <pre><code>WORKER_TASK_COUNT=10\n</code></pre></p> <p>Notes: - Batch size for step queries - Higher values reduce database round-trips - Lower values improve fairness across workers</p>"},{"location":"ingester/CONFIGURATION/#worker_checkin_interval","title":"WORKER_CHECKIN_INTERVAL","text":"<p>Worker heartbeat interval in seconds.</p> <p>Default: <code>120</code> (2 minutes)</p> <p>Example: <pre><code>WORKER_CHECKIN_INTERVAL=60\n</code></pre></p> <p>Notes: - How often workers update health status - Lower values increase database load slightly - Used for monitoring worker liveness</p>"},{"location":"ingester/CONFIGURATION/#worker_checkin_timeout","title":"WORKER_CHECKIN_TIMEOUT","text":"<p>Worker timeout threshold in seconds.</p> <p>Default: <code>600</code> (10 minutes)</p> <p>Example: <pre><code>WORKER_CHECKIN_TIMEOUT=300\n</code></pre></p> <p>Notes: - When to consider a worker stale - Should be significantly larger than <code>WORKER_CHECKIN_INTERVAL</code> - Used for detecting crashed workers</p>"},{"location":"ingester/CONFIGURATION/#embed_batch_size","title":"EMBED_BATCH_SIZE","text":"<p>Batch size for embedding operations.</p> <p>Default: <code>1000</code></p> <p>Example: <pre><code>EMBED_BATCH_SIZE=500\n</code></pre></p> <p>Notes: - Number of chunks to embed at once - Higher values improve throughput - Limited by embedding service capacity and memory</p>"},{"location":"ingester/CONFIGURATION/#workflow-configuration","title":"Workflow Configuration","text":""},{"location":"ingester/CONFIGURATION/#workflow_dir","title":"WORKFLOW_DIR","text":"<p>Directory containing workflow YAML definitions.</p> <p>Default: <code>config/workflows</code></p> <p>Example: <pre><code>WORKFLOW_DIR=/etc/soliplex/workflows\n</code></pre></p> <p>Notes: - Scanned for <code>*.yaml</code> files at startup - Hot-reload if <code>--reload</code> flag is used</p>"},{"location":"ingester/CONFIGURATION/#default_workflow_id","title":"DEFAULT_WORKFLOW_ID","text":"<p>Default workflow to use when not specified.</p> <p>Default: <code>batch_split</code></p> <p>Example: <pre><code>DEFAULT_WORKFLOW_ID=batch\n</code></pre></p> <p>Notes: - Must match an <code>id</code> in workflow YAML files - Used when API requests omit <code>workflow_definition_id</code></p>"},{"location":"ingester/CONFIGURATION/#param_dir","title":"PARAM_DIR","text":"<p>Directory containing parameter set YAML files.</p> <p>Default: <code>config/params</code></p> <p>Example: <pre><code>PARAM_DIR=/etc/soliplex/params\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#default_param_id","title":"DEFAULT_PARAM_ID","text":"<p>Default parameter set to use when not specified.</p> <p>Default: <code>default</code></p> <p>Example: <pre><code>DEFAULT_PARAM_ID=high_quality\n</code></pre></p> <p>Notes: - Must match an <code>id</code> in parameter YAML files</p>"},{"location":"ingester/CONFIGURATION/#feature-flags","title":"Feature Flags","text":""},{"location":"ingester/CONFIGURATION/#do_rag","title":"DO_RAG","text":"<p>Enable/disable HaikuRAG integration.</p> <p>Default: <code>True</code></p> <p>Example: <pre><code>DO_RAG=false\n</code></pre></p> <p>Notes: - Set to <code>false</code> for testing without RAG backend - When disabled, <code>store</code> step becomes a no-op - Useful for CI/CD testing</p>"},{"location":"ingester/CONFIGURATION/#configuration-file","title":"Configuration File","text":"<p>While the system uses environment variables, you can organize them in a <code>.env</code> file:</p> <p>.env Example: <pre><code># Database\nDOC_DB_URL=sqlite+aiosqlite:///./db/documents.db\n\n# External Services\nDOCLING_SERVER_URL=http://localhost:5001/v1\nDOCLING_HTTP_TIMEOUT=600\n\n# Logging\nLOG_LEVEL=INFO\n\n# Storage\nFILE_STORE_TARGET=fs\nFILE_STORE_DIR=file_store\nLANCEDB_DIR=lancedb\n\n# Worker Settings\nINGEST_WORKER_CONCURRENCY=10\nDOCLING_CONCURRENCY=3\nWORKER_TASK_COUNT=5\nWORKER_CHECKIN_INTERVAL=120\nWORKER_CHECKIN_TIMEOUT=600\nEMBED_BATCH_SIZE=1000\n\n# Workflow Configuration\nWORKFLOW_DIR=config/workflows\nDEFAULT_WORKFLOW_ID=batch\nPARAM_DIR=config/params\nDEFAULT_PARAM_ID=default\n\n# Features\nDO_RAG=true\n</code></pre></p> <p>Load with: <pre><code>export $(cat .env | xargs)\nsi-cli serve\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#s3-configuration-overview","title":"S3 Configuration Overview","text":"<p>This project supports S3 storage in two different contexts with different configuration methods:</p>"},{"location":"ingester/CONFIGURATION/#1-lancedb-vector-storage-lancedb_dir","title":"1. LanceDB Vector Storage (<code>LANCEDB_DIR</code>)","text":"<p>Purpose: Stores vector embeddings for RAG retrieval Configuration Method: Standard AWS environment variables Example: <pre><code>LANCEDB_DIR=s3://my-vector-bucket/lancedb\nAWS_ACCESS_KEY_ID=your_key_id\nAWS_SECRET_ACCESS_KEY=your_secret_key\nAWS_REGION=us-east-1\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#2-artifact-storage-file_store_targets3","title":"2. Artifact Storage (<code>FILE_STORE_TARGET=s3</code>)","text":"<p>Purpose: Stores intermediate processing artifacts (documents, markdown, chunks, embeddings) Configuration Method: Nested Pydantic settings with <code>__</code> delimiter Example: <pre><code>FILE_STORE_TARGET=s3\nARTIFACT_S3__BUCKET=my-artifact-bucket\nARTIFACT_S3__ACCESS_KEY_ID=your_key_id\nARTIFACT_S3__ACCESS_SECRET=your_secret_key\nARTIFACT_S3__REGION=us-east-1\nARTIFACT_S3__ENDPOINT_URL=http://127.0.0.1:8333\n</code></pre></p> <p>Important Notes: - These are independent systems and can use different S3 buckets or providers - LanceDB uses standard AWS SDK naming (<code>AWS_SECRET_ACCESS_KEY</code>) - Artifact/Input S3 uses Pydantic nested naming (<code>ARTIFACT_S3__ACCESS_SECRET</code>) - The field name difference is intentional to support Pydantic's nested configuration</p>"},{"location":"ingester/CONFIGURATION/#nested-configuration-advanced","title":"Nested Configuration (Advanced)","text":"<p>Pydantic Settings supports nested configuration using <code>__</code> delimiter for structured settings.</p> <p>Artifact S3 Configuration: <pre><code>ARTIFACT_S3__BUCKET=soliplex-artifacts\nARTIFACT_S3__ACCESS_KEY_ID=soliplex\nARTIFACT_S3__ACCESS_SECRET=soliplex\nARTIFACT_S3__REGION=xx\nARTIFACT_S3__ENDPOINT_URL=http://127.0.0.1:8333\n</code></pre></p> <p>Input S3 Configuration: <pre><code>INPUT_S3__BUCKET=soliplex-inputs\nINPUT_S3__ACCESS_KEY_ID=soliplex\nINPUT_S3__ACCESS_SECRET=soliplex\nINPUT_S3__REGION=xx\nINPUT_S3__ENDPOINT_URL=http://127.0.0.1:8333\n</code></pre></p> <p>Notes: - <code>ACCESS_SECRET</code> (not <code>SECRET_ACCESS_KEY</code>) is used for nested config fields - Nested delimiter is <code>__</code> (double underscore) - Both <code>INPUT_S3</code> and <code>ARTIFACT_S3</code> can point to different buckets/providers</p> <p>See <code>src/soliplex/ingester/lib/config.py:7-16</code> for nested model definitions.</p>"},{"location":"ingester/CONFIGURATION/#configuration-validation","title":"Configuration Validation","text":""},{"location":"ingester/CONFIGURATION/#validate-settings","title":"Validate Settings","text":"<p>Check configuration without starting services:</p> <pre><code>si-cli validate-settings\n</code></pre> <p>Output: <pre><code>doc_db_url='sqlite+aiosqlite:///./db/documents.db'\ndocling_server_url='http://localhost:5001/v1'\nlog_level='INFO'\n...\n</code></pre></p> <p>Validation Errors: <pre><code>invalid settings\n{'type': 'missing', 'loc': ('doc_db_url',), 'msg': 'Field required'}\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"ingester/CONFIGURATION/#development","title":"Development","text":"<p>dev.env: <pre><code>DOC_DB_URL=sqlite+aiosqlite:///./db/dev.db\nLOG_LEVEL=DEBUG\nINGEST_WORKER_CONCURRENCY=5\nDO_RAG=false\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#staging","title":"Staging","text":"<p>staging.env: <pre><code>DOC_DB_URL=postgresql+psycopg://user:pass@staging-db:5432/soliplex\nLOG_LEVEL=INFO\nINGEST_WORKER_CONCURRENCY=10\nDOCLING_SERVER_URL=http://docling-staging:5001/v1\nDO_RAG=true\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#production","title":"Production","text":"<p>production.env: <pre><code>DOC_DB_URL=postgresql+psycopg://user:pass@prod-db:5432/soliplex\nLOG_LEVEL=WARNING\nINGEST_WORKER_CONCURRENCY=20\nDOCLING_CONCURRENCY=5\nDOCLING_SERVER_URL=http://docling-prod:5001/v1\nFILE_STORE_TARGET=s3\nDO_RAG=true\nWORKER_CHECKIN_INTERVAL=60\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#docker-configuration","title":"Docker Configuration","text":""},{"location":"ingester/CONFIGURATION/#docker-compose-example","title":"Docker Compose Example","text":"<p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  ingester:\n    image: soliplex-ingester:latest\n    environment:\n      DOC_DB_URL: postgresql+psycopg://postgres:password@db:5432/soliplex\n      DOCLING_SERVER_URL: http://docling:5001/v1\n      LOG_LEVEL: INFO\n      FILE_STORE_DIR: /data/files\n      LANCEDB_DIR: /data/lancedb\n      INGEST_WORKER_CONCURRENCY: 15\n    volumes:\n      - ./config/workflows:/app/config/workflows\n      - ./config/params:/app/config/params\n      - data-volume:/data\n    depends_on:\n      - db\n      - docling\n\n  db:\n    image: postgres:16\n    environment:\n      POSTGRES_DB: soliplex\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: password\n    volumes:\n      - db-volume:/var/lib/postgresql/data\n\n  docling:\n    image: docling-server:latest\n    ports:\n      - \"5001:5001\"\n\nvolumes:\n  db-volume:\n  data-volume:\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#kubernetes-configmap","title":"Kubernetes ConfigMap","text":"<p>configmap.yaml: <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: soliplex-config\ndata:\n  DOC_DB_URL: \"postgresql+psycopg://user:pass@postgres-service:5432/soliplex\"\n  DOCLING_SERVER_URL: \"http://docling-service:5001/v1\"\n  LOG_LEVEL: \"INFO\"\n  INGEST_WORKER_CONCURRENCY: \"20\"\n  WORKFLOW_DIR: \"/config/workflows\"\n  PARAM_DIR: \"/config/params\"\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#performance-tuning","title":"Performance Tuning","text":""},{"location":"ingester/CONFIGURATION/#high-throughput","title":"High Throughput","text":"<pre><code>INGEST_WORKER_CONCURRENCY=50\nDOCLING_CONCURRENCY=10\nWORKER_TASK_COUNT=20\nEMBED_BATCH_SIZE=2000\n</code></pre> <p>Notes: - Requires powerful hardware - Monitor CPU, memory, and I/O - Coordinate with external service capacity</p>"},{"location":"ingester/CONFIGURATION/#resource-constrained","title":"Resource Constrained","text":"<pre><code>INGEST_WORKER_CONCURRENCY=5\nDOCLING_CONCURRENCY=2\nWORKER_TASK_COUNT=3\nEMBED_BATCH_SIZE=500\n</code></pre> <p>Notes: - Reduces memory and CPU usage - Lower throughput but more stable - Good for shared environments</p>"},{"location":"ingester/CONFIGURATION/#batch-processing","title":"Batch Processing","text":"<pre><code>INGEST_WORKER_CONCURRENCY=30\nDOCLING_CONCURRENCY=8\nWORKER_TASK_COUNT=10\nWORKER_CHECKIN_INTERVAL=300\n</code></pre> <p>Notes: - Optimized for processing large batches - Reduces monitoring overhead - Assumes long-running workers</p>"},{"location":"ingester/CONFIGURATION/#secrets-management","title":"Secrets Management","text":""},{"location":"ingester/CONFIGURATION/#using-environment-files","title":"Using Environment Files","text":"<p>Keep secrets out of version control:</p> <pre><code># .env.secrets (add to .gitignore)\nDOC_DB_URL=postgresql+psycopg://user:$(cat /run/secrets/db_password)@db/soliplex\n</code></pre>"},{"location":"ingester/CONFIGURATION/#using-secret-management-tools","title":"Using Secret Management Tools","text":"<p>AWS Secrets Manager: <pre><code>export DOC_DB_URL=$(aws secretsmanager get-secret-value --secret-id db-url --query SecretString --output text)\n</code></pre></p> <p>HashiCorp Vault: <pre><code>export DOC_DB_URL=$(vault kv get -field=url secret/soliplex/db)\n</code></pre></p> <p>Kubernetes Secrets: <pre><code>env:\n  - name: DOC_DB_URL\n    valueFrom:\n      secretKeyRef:\n        name: db-credentials\n        key: url\n</code></pre></p>"},{"location":"ingester/CONFIGURATION/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ingester/CONFIGURATION/#configuration-not-loading","title":"Configuration Not Loading","text":"<p>Symptom: Application uses default values</p> <p>Solutions: 1. Verify environment variables are set: <code>env | grep DOC_</code> 2. Check for typos in variable names 3. Ensure <code>.env</code> file is in correct directory 4. Verify <code>.env</code> file is being loaded</p>"},{"location":"ingester/CONFIGURATION/#validation-errors","title":"Validation Errors","text":"<p>Symptom: Application fails to start with validation error</p> <p>Solutions: 1. Run <code>si-cli validate-settings</code> to see errors 2. Check required fields are set 3. Verify value types (e.g., integers for ports) 4. Check URL formats</p>"},{"location":"ingester/CONFIGURATION/#connection-errors","title":"Connection Errors","text":"<p>Symptom: Cannot connect to database or Docling</p> <p>Solutions: 1. Verify URLs are correct 2. Test connectivity: <code>curl http://docling-url/health</code> 3. Check network policies/firewall 4. Verify credentials</p>"},{"location":"ingester/CONFIGURATION/#file-permissions","title":"File Permissions","text":"<p>Symptom: Cannot write to storage directories</p> <p>Solutions: 1. Check directory exists and is writable 2. Verify application user permissions 3. Create directories if needed: <code>mkdir -p file_store lancedb</code> 4. Set ownership: <code>chown -R app-user file_store lancedb</code></p>"},{"location":"ingester/CONFIGURATION/#configuration-reference","title":"Configuration Reference","text":"Variable Type Required Default Description <code>DOC_DB_URL</code> str Yes - Database connection URL <code>DOCLING_SERVER_URL</code> str No <code>http://localhost:5001/v1</code> Docling service URL <code>DOCLING_HTTP_TIMEOUT</code> int No <code>600</code> Docling timeout (seconds) <code>LOG_LEVEL</code> str No <code>INFO</code> Logging level <code>FILE_STORE_TARGET</code> str No <code>fs</code> Storage backend type <code>FILE_STORE_DIR</code> str No <code>file_store</code> Base storage directory <code>LANCEDB_DIR</code> str No <code>lancedb</code> LanceDB directory (supports S3 URIs) <code>DOCUMENT_STORE_DIR</code> str No <code>raw</code> Raw documents subdir <code>PARSED_MARKDOWN_STORE_DIR</code> str No <code>markdown</code> Markdown subdir <code>PARSED_JSON_STORE_DIR</code> str No <code>json</code> JSON subdir <code>CHUNKS_STORE_DIR</code> str No <code>chunks</code> Chunks subdir <code>EMBEDDINGS_STORE_DIR</code> str No <code>embeddings</code> Embeddings subdir <code>INGEST_QUEUE_CONCURRENCY</code> int No <code>20</code> Queue concurrency <code>INGEST_WORKER_CONCURRENCY</code> int No <code>10</code> Worker concurrency <code>DOCLING_CONCURRENCY</code> int No <code>3</code> Docling concurrency <code>WORKER_TASK_COUNT</code> int No <code>5</code> Steps per query <code>WORKER_CHECKIN_INTERVAL</code> int No <code>120</code> Heartbeat interval (sec) <code>WORKER_CHECKIN_TIMEOUT</code> int No <code>600</code> Worker timeout (sec) <code>EMBED_BATCH_SIZE</code> int No <code>1000</code> Embedding batch size <code>WORKFLOW_DIR</code> str No <code>config/workflows</code> Workflow definitions dir <code>DEFAULT_WORKFLOW_ID</code> str No <code>batch_split</code> Default workflow <code>PARAM_DIR</code> str No <code>config/params</code> Parameter sets dir <code>DEFAULT_PARAM_ID</code> str No <code>default</code> Default parameter set <code>AWS_ACCESS_KEY_ID</code> str Conditional - AWS access key (required for S3 LanceDB) <code>AWS_SECRET_ACCESS_KEY</code> str Conditional - AWS secret key (required for S3 LanceDB) <code>AWS_REGION</code> str Conditional - AWS region (required for S3 LanceDB) <code>AWS_ENDPOINT</code> str No - S3 endpoint (for non-AWS providers) <code>AWS_ALLOW_HTTP</code> int No - Allow HTTP for S3 (set to 1 for HTTP) <code>ARTIFACT_S3__*</code> nested Conditional - Artifact S3 config (BUCKET, ACCESS_SECRET, etc.) <code>INPUT_S3__*</code> nested Conditional - Input S3 config (BUCKET, ACCESS_SECRET, etc.) <code>DO_RAG</code> bool No <code>True</code> Enable RAG integration"},{"location":"ingester/DATABASE/","title":"Database Models and Schema","text":""},{"location":"ingester/DATABASE/#overview","title":"Overview","text":"<p>Soliplex Ingester uses SQLModel (built on SQLAlchemy) for database modeling with async support. The system supports both SQLite (development) and PostgreSQL (production).</p> <p>Database models defined in: <code>src/soliplex_ingester/lib/models.py</code></p>"},{"location":"ingester/DATABASE/#database-connection","title":"Database Connection","text":""},{"location":"ingester/DATABASE/#configuration","title":"Configuration","text":"<p>Set via environment variable: <pre><code>DOC_DB_URL=\"sqlite+aiosqlite:///./db/documents.db\"\n# or\nDOC_DB_URL=\"postgresql+asyncpg://user:pass@localhost/soliplex\"\n</code></pre></p>"},{"location":"ingester/DATABASE/#async-engine","title":"Async Engine","text":"<p>The system uses async SQLAlchemy with connection pooling:</p> <pre><code>from soliplex_ingester.lib.models import get_session\n\nasync with get_session() as session:\n    # Your database operations\n    result = await session.exec(select(Document))\n</code></pre>"},{"location":"ingester/DATABASE/#core-models","title":"Core Models","text":""},{"location":"ingester/DATABASE/#documentbatch","title":"DocumentBatch","text":"<p>Represents a batch of documents ingested together.</p> <p>Table: <code>documentbatch</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment batch ID - <code>name</code> (str) - Human-readable batch name - <code>source</code> (str) - Source system identifier - <code>start_date</code> (datetime) - When batch processing started - <code>completed_date</code> (datetime, nullable) - When batch completed - <code>batch_params</code> (dict[str, str]) - JSON metadata</p> <p>Computed Fields: - <code>duration</code> (float) - Processing time in seconds</p> <p>Example: <pre><code>{\n  \"id\": 1,\n  \"name\": \"Q4 Financial Reports\",\n  \"source\": \"sharepoint\",\n  \"start_date\": \"2025-01-15T10:00:00\",\n  \"completed_date\": \"2025-01-15T12:30:00\",\n  \"batch_params\": {\"department\": \"finance\"},\n  \"duration\": 9000.0\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#document","title":"Document","text":"<p>Represents a unique document identified by content hash.</p> <p>Table: <code>document</code></p> <p>Fields: - <code>hash</code> (str, primary key) - SHA256 content hash (format: \"sha256-...\") - <code>mime_type</code> (str) - Document MIME type - <code>file_size</code> (int, nullable) - Size in bytes - <code>doc_meta</code> (dict[str, str]) - JSON metadata</p> <p>Relationships: - Multiple <code>DocumentURI</code> records can reference the same document</p> <p>Deduplication: Documents are deduplicated by hash. If the same file is ingested multiple times, only one Document record exists.</p> <p>Example: <pre><code>{\n  \"hash\": \"sha256-a1b2c3d4e5f6...\",\n  \"mime_type\": \"application/pdf\",\n  \"file_size\": 1024000,\n  \"doc_meta\": {\n    \"author\": \"John Doe\",\n    \"title\": \"Q4 Report\"\n  },\n  \"rag_id\": \"doc_xyz123\",\n  \"batch_id\": 1\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#documenturi","title":"DocumentURI","text":"<p>Maps source URIs to document hashes, allowing multiple URIs to reference the same document.</p> <p>Table: <code>documenturi</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>doc_hash</code> (str, foreign key) - References <code>document.hash</code> - <code>uri</code> (str) - Source system path/identifier - <code>source</code> (str) - Source system name - <code>version</code> (int) - Version number (increments on changes) - <code>batch_id</code> (int, foreign key, nullable) - Associated batch</p> <p>Constraints: - Unique constraint on <code>(uri, source)</code> - One active URI per source</p> <p>Use Cases: - Track document locations across source systems - Detect when a document at a URI has changed (hash mismatch) - Support document versioning</p> <p>Example: <pre><code>{\n  \"id\": 42,\n  \"doc_hash\": \"sha256-a1b2c3d4e5f6...\",\n  \"uri\": \"/sharepoint/finance/q4-report.pdf\",\n  \"source\": \"sharepoint\",\n  \"version\": 2,\n  \"batch_id\": 1\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#documenturihistory","title":"DocumentURIHistory","text":"<p>Tracks historical versions of documents at specific URIs.</p> <p>Table: <code>documenturihistory</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>doc_uri_id</code> (int, foreign key) - References <code>documenturi.id</code> - <code>version</code> (int) - Version number - <code>hash</code> (str) - Document hash at this version - <code>process_date</code> (datetime) - When this version was processed - <code>action</code> (str) - Action taken (\"created\", \"updated\", \"deleted\") - <code>batch_id</code> (int, foreign key, nullable) - Associated batch - <code>histmeta</code> (dict[str, str]) - JSON metadata</p> <p>Use Cases: - Audit trail of document changes - Rollback to previous versions - Compliance and record-keeping</p> <p>Example: <pre><code>{\n  \"id\": 100,\n  \"doc_uri_id\": 42,\n  \"version\": 1,\n  \"hash\": \"sha256-old-hash...\",\n  \"process_date\": \"2025-01-10T10:00:00\",\n  \"action\": \"created\",\n  \"batch_id\": 1,\n  \"histmeta\": {\"user\": \"importer\"}\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#documentbytes","title":"DocumentBytes","text":"<p>Stores raw file bytes and artifacts in the database.</p> <p>Table: <code>documentbytes</code></p> <p>Fields: - <code>hash</code> (str, primary key) - Document hash - <code>artifact_type</code> (str, primary key) - Type of artifact - <code>storage_root</code> (str, primary key) - Storage location identifier - <code>file_size</code> (int, nullable) - Size in bytes (auto-computed) - <code>file_bytes</code> (bytes) - Raw binary data</p> <p>Artifact Types: - <code>document</code> - Raw document - <code>parsed_markdown</code> - Extracted markdown - <code>parsed_json</code> - Structured JSON - <code>chunks</code> - Text chunks - <code>embeddings</code> - Vector embeddings - <code>rag</code> - RAG metadata</p> <p>Note: For production, consider using file storage instead of database storage for large binaries.</p> <p>Example: <pre><code>{\n  \"hash\": \"sha256-a1b2c3d4e5f6...\",\n  \"artifact_type\": \"parsed_markdown\",\n  \"storage_root\": \"db\",\n  \"file_size\": 50000,\n  \"file_bytes\": b\"# Document Title\\n\\n...\"\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#workflow-models","title":"Workflow Models","text":""},{"location":"ingester/DATABASE/#rungroup","title":"RunGroup","text":"<p>Groups related workflow runs together.</p> <p>Table: <code>rungroup</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>name</code> (str, nullable) - Optional group name - <code>workflow_definition_id</code> (str) - Workflow used - <code>param_definition_id</code> (str) - Parameter set used - <code>batch_id</code> (int, foreign key, nullable) - Associated batch - <code>created_date</code> (datetime) - When group was created - <code>start_date</code> (datetime) - When first run started - <code>completed_date</code> (datetime, nullable) - When all runs completed - <code>status</code> (RunStatus) - Overall group status - <code>status_date</code> (datetime, nullable) - When status last changed - <code>status_message</code> (str, nullable) - Status description - <code>status_meta</code> (dict[str, str]) - JSON metadata</p> <p>Relationships: - Has many <code>WorkflowRun</code> records - Has many <code>LifecycleHistory</code> records</p> <p>Example: <pre><code>{\n  \"id\": 5,\n  \"name\": \"Batch 1 Processing\",\n  \"workflow_definition_id\": \"batch\",\n  \"param_definition_id\": \"default\",\n  \"batch_id\": 1,\n  \"created_date\": \"2025-01-15T10:00:00\",\n  \"start_date\": \"2025-01-15T10:01:00\",\n  \"completed_date\": null,\n  \"status\": \"RUNNING\",\n  \"status_date\": \"2025-01-15T10:30:00\",\n  \"status_message\": \"Processing documents\",\n  \"status_meta\": {}\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#workflowrun","title":"WorkflowRun","text":"<p>Represents a single workflow execution for one document.</p> <p>Table: <code>workflowrun</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>workflow_definition_id</code> (str) - Workflow definition ID - <code>run_group_id</code> (int, foreign key) - Parent group - <code>batch_id</code> (int, foreign key) - Associated batch - <code>doc_id</code> (str) - Document hash being processed - <code>priority</code> (int) - Processing priority (higher = more urgent) - <code>created_date</code> (datetime) - When run was created - <code>start_date</code> (datetime) - When first step started - <code>completed_date</code> (datetime, nullable) - When all steps completed - <code>status</code> (RunStatus) - Current status - <code>status_date</code> (datetime, nullable) - When status last changed - <code>status_message</code> (str, nullable) - Status description - <code>status_meta</code> (dict[str, str]) - JSON metadata - <code>run_params</code> (dict[str, str|int|bool]) - Runtime parameters</p> <p>Computed Fields: - <code>duration</code> (float) - Processing time in seconds</p> <p>Relationships: - Has many <code>RunStep</code> records - Belongs to <code>RunGroup</code> - References <code>Document</code> via <code>doc_id</code></p> <p>Example: <pre><code>{\n  \"id\": 100,\n  \"workflow_definition_id\": \"batch\",\n  \"run_group_id\": 5,\n  \"batch_id\": 1,\n  \"doc_id\": \"sha256-a1b2c3d4e5f6...\",\n  \"priority\": 0,\n  \"created_date\": \"2025-01-15T10:00:00\",\n  \"start_date\": \"2025-01-15T10:01:00\",\n  \"completed_date\": null,\n  \"status\": \"RUNNING\",\n  \"status_date\": \"2025-01-15T10:05:00\",\n  \"status_message\": \"Processing step 3 of 5\",\n  \"status_meta\": {},\n  \"run_params\": {},\n  \"duration\": null\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#runstep","title":"RunStep","text":"<p>Represents one step within a workflow run.</p> <p>Table: <code>runstep</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>workflow_run_id</code> (int, foreign key) - Parent workflow run - <code>workflow_step_number</code> (int) - Step sequence number - <code>workflow_step_name</code> (str) - Step name/identifier - <code>step_config_id</code> (int, foreign key) - Configuration used - <code>step_type</code> (WorkflowStepType) - Type of step - <code>is_last_step</code> (bool) - Whether this is the final step - <code>created_date</code> (datetime) - When step was created - <code>priority</code> (int) - Processing priority - <code>start_date</code> (datetime, nullable) - When step started executing - <code>status_date</code> (datetime, nullable) - When status last changed - <code>completed_date</code> (datetime, nullable) - When step completed - <code>retry</code> (int) - Current retry attempt (0-indexed) - <code>retries</code> (int) - Maximum retry attempts - <code>status</code> (RunStatus) - Current status - <code>status_message</code> (str, nullable) - Status description - <code>status_meta</code> (dict[str, str]) - JSON metadata - <code>worker_id</code> (str, nullable) - Worker processing this step</p> <p>Computed Fields: - <code>duration</code> (float) - Execution time in seconds</p> <p>Relationships: - Belongs to <code>WorkflowRun</code> - References <code>StepConfig</code></p> <p>Example: <pre><code>{\n  \"id\": 500,\n  \"workflow_run_id\": 100,\n  \"workflow_step_number\": 2,\n  \"workflow_step_name\": \"parse\",\n  \"step_config_id\": 10,\n  \"step_type\": \"parse\",\n  \"is_last_step\": false,\n  \"created_date\": \"2025-01-15T10:01:00\",\n  \"priority\": 0,\n  \"start_date\": \"2025-01-15T10:02:00\",\n  \"status_date\": \"2025-01-15T10:05:00\",\n  \"completed_date\": null,\n  \"retry\": 0,\n  \"retries\": 3,\n  \"status\": \"RUNNING\",\n  \"status_message\": \"Parsing with Docling\",\n  \"status_meta\": {},\n  \"worker_id\": \"worker-abc-123\",\n  \"duration\": null\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#stepconfig","title":"StepConfig","text":"<p>Stores step configuration for reuse and tracking.</p> <p>Table: <code>stepconfig</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>created_date</code> (datetime, nullable) - When config was created - <code>step_type</code> (WorkflowStepType) - Type of step - <code>config_json</code> (dict[str, str|int|bool], nullable) - Step parameters - <code>cuml_config_json</code> (str, nullable) - Cumulative config from previous steps</p> <p>Use Cases: - Deduplicate identical configurations - Track which configuration was used for each run - Audit changes to processing parameters</p> <p>Example: <pre><code>{\n  \"id\": 10,\n  \"created_date\": \"2025-01-15T09:00:00\",\n  \"step_type\": \"parse\",\n  \"config_json\": {\n    \"format\": \"markdown\",\n    \"ocr_enabled\": true\n  },\n  \"cuml_config_json\": \"{\\\"validate\\\":{...},\\\"parse\\\":{...}}\"\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#configset","title":"ConfigSet","text":"<p>Represents a complete parameter set configuration.</p> <p>Table: <code>configset</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>yaml_id</code> (str) - Parameter set ID from YAML - <code>yaml_contents</code> (str) - Full YAML contents - <code>created_date</code> (datetime, nullable) - When loaded</p> <p>Relationships: - Has many <code>ConfigSetItem</code> records (junction table) - Links to multiple <code>StepConfig</code> records</p> <p>Use Cases: - Track which parameter sets were used - Reproduce exact configurations - Version control for processing parameters</p>"},{"location":"ingester/DATABASE/#configsetitem","title":"ConfigSetItem","text":"<p>Junction table linking config sets to step configs.</p> <p>Table: <code>configsetitem</code></p> <p>Fields: - <code>config_set_id</code> (int, primary key, foreign key) - References <code>configset.id</code> - <code>config_id</code> (int, primary key, foreign key) - References <code>stepconfig.id</code></p>"},{"location":"ingester/DATABASE/#lifecyclehistory","title":"LifecycleHistory","text":"<p>Tracks lifecycle events during workflow execution.</p> <p>Table: <code>lifecyclehistory</code></p> <p>Fields: - <code>id</code> (int, primary key) - Auto-increment ID - <code>event</code> (LifeCycleEvent) - Type of event - <code>run_group_id</code> (int, foreign key) - Associated run group - <code>workflow_run_id</code> (int, foreign key) - Associated workflow run - <code>step_id</code> (int, nullable) - Associated step (if applicable) - <code>start_date</code> (datetime) - When event started - <code>completed_date</code> (datetime, nullable) - When event completed - <code>status</code> (RunStatus) - Event status - <code>status_date</code> (datetime, nullable) - When status changed - <code>status_message</code> (str, nullable) - Status description - <code>status_meta</code> (dict[str, str]) - JSON metadata</p> <p>Event Types: - <code>GROUP_START</code> / <code>GROUP_END</code> - <code>ITEM_START</code> / <code>ITEM_END</code> / <code>ITEM_FAILED</code> - <code>STEP_START</code> / <code>STEP_END</code> / <code>STEP_FAILED</code></p> <p>Use Cases: - Audit trail of workflow execution - Performance monitoring - Debugging workflow issues</p>"},{"location":"ingester/DATABASE/#workercheckin","title":"WorkerCheckin","text":"<p>Tracks worker health and activity.</p> <p>Table: <code>workercheckin</code></p> <p>Fields: - <code>id</code> (str, primary key) - Worker identifier - <code>first_checkin</code> (datetime) - When worker first registered - <code>last_checkin</code> (datetime) - Most recent heartbeat</p> <p>Constraints: - Unique constraint on <code>id</code></p> <p>Use Cases: - Monitor active workers - Detect stale/crashed workers - Worker load balancing</p> <p>Example: <pre><code>{\n  \"id\": \"worker-abc-123\",\n  \"first_checkin\": \"2025-01-15T10:00:00\",\n  \"last_checkin\": \"2025-01-15T10:30:00\"\n}\n</code></pre></p>"},{"location":"ingester/DATABASE/#enums","title":"Enums","text":""},{"location":"ingester/DATABASE/#runstatus","title":"RunStatus","text":"<p>Workflow and step status values.</p> <pre><code>class RunStatus(str, Enum):\n    PENDING = \"PENDING\"      # Not yet started\n    RUNNING = \"RUNNING\"      # Currently executing\n    COMPLETED = \"COMPLETED\"  # Finished successfully\n    ERROR = \"ERROR\"          # Failed but will retry\n    FAILED = \"FAILED\"        # Permanently failed\n</code></pre>"},{"location":"ingester/DATABASE/#workflowsteptype","title":"WorkflowStepType","text":"<p>Types of workflow steps.</p> <pre><code>class WorkflowStepType(str, Enum):\n    INGEST = \"ingest\"\n    VALIDATE = \"validate\"\n    PARSE = \"parse\"\n    CHUNK = \"chunk\"\n    EMBED = \"embed\"\n    STORE = \"store\"\n    ENRICH = \"enrich\"\n    ROUTE = \"route\"\n</code></pre>"},{"location":"ingester/DATABASE/#artifacttype","title":"ArtifactType","text":"<p>Types of stored artifacts.</p> <pre><code>class ArtifactType(Enum):\n    DOC = \"document\"\n    PARSED_MD = \"parsed_markdown\"\n    PARSED_JSON = \"parsed_json\"\n    CHUNKS = \"chunks\"\n    EMBEDDINGS = \"embeddings\"\n    RAG = \"rag\"\n</code></pre>"},{"location":"ingester/DATABASE/#lifecycleevent","title":"LifeCycleEvent","text":"<p>Workflow lifecycle events.</p> <pre><code>class LifeCycleEvent(str, Enum):\n    GROUP_START = \"group_start\"\n    GROUP_END = \"group_end\"\n    ITEM_START = \"item_start\"\n    ITEM_END = \"item_end\"\n    ITEM_FAILED = \"item_failed\"\n    STEP_START = \"step_start\"\n    STEP_END = \"step_end\"\n    STEP_FAILED = \"step_failed\"\n</code></pre>"},{"location":"ingester/DATABASE/#relationships-diagram","title":"Relationships Diagram","text":"<pre><code>DocumentBatch\n    \u2193 (1:N)\nDocumentURI \u2500\u2500\u2192 Document (N:1)\n    \u2193\nDocumentURIHistory\n\nDocumentBatch\n    \u2193 (1:N)\nRunGroup\n    \u2193 (1:N)\nWorkflowRun \u2500\u2500\u2192 Document (N:1)\n    \u2193 (1:N)\nRunStep \u2500\u2500\u2192 StepConfig (N:1)\n\nConfigSet\n    \u2193 (N:M via ConfigSetItem)\nStepConfig\n\nRunGroup \u2500\u2500\u2192 LifecycleHistory (1:N)\nWorkflowRun \u2500\u2500\u2192 LifecycleHistory (1:N)\n</code></pre>"},{"location":"ingester/DATABASE/#database-initialization","title":"Database Initialization","text":""},{"location":"ingester/DATABASE/#using-cli","title":"Using CLI","text":"<pre><code>si-cli db-init\n</code></pre> <p>This creates tables and runs migrations.</p>"},{"location":"ingester/DATABASE/#using-alembic-directly","title":"Using Alembic Directly","text":"<pre><code>alembic upgrade head\n</code></pre>"},{"location":"ingester/DATABASE/#programmatic","title":"Programmatic","text":"<pre><code>from sqlalchemy import create_engine\nfrom sqlmodel import SQLModel\nfrom soliplex_ingester.lib.config import get_settings\n\nsettings = get_settings()\nengine = create_engine(settings.doc_db_url)\nSQLModel.metadata.create_all(engine)\n</code></pre>"},{"location":"ingester/DATABASE/#migrations","title":"Migrations","text":""},{"location":"ingester/DATABASE/#location","title":"Location","text":"<p><code>src/soliplex_ingester/migrations/</code></p>"},{"location":"ingester/DATABASE/#configuration_1","title":"Configuration","text":"<p><code>alembic.ini</code> (project root)</p>"},{"location":"ingester/DATABASE/#create-migration","title":"Create Migration","text":"<pre><code>alembic revision --autogenerate -m \"description\"\n</code></pre>"},{"location":"ingester/DATABASE/#apply-migration","title":"Apply Migration","text":"<pre><code>alembic upgrade head\n</code></pre>"},{"location":"ingester/DATABASE/#rollback","title":"Rollback","text":"<pre><code>alembic downgrade -1\n</code></pre>"},{"location":"ingester/DATABASE/#indexes","title":"Indexes","text":"<p>Consider adding these indexes for production:</p> <pre><code>-- Workflow processing queries\nCREATE INDEX idx_runstep_status ON runstep(status, priority DESC);\nCREATE INDEX idx_workflowrun_status ON workflowrun(status, batch_id);\nCREATE INDEX idx_rungroup_batch ON rungroup(batch_id);\n\n-- Document lookups\nCREATE INDEX idx_documenturi_source ON documenturi(source);\nCREATE INDEX idx_document_batch ON document(batch_id);\n\n-- Worker monitoring\nCREATE INDEX idx_runstep_worker ON runstep(worker_id);\nCREATE INDEX idx_workercheckin_last ON workercheckin(last_checkin);\n</code></pre>"},{"location":"ingester/DATABASE/#backup-and-maintenance","title":"Backup and Maintenance","text":""},{"location":"ingester/DATABASE/#sqlite-backup","title":"SQLite Backup","text":"<pre><code>sqlite3 db/documents.db \".backup backup.db\"\n</code></pre>"},{"location":"ingester/DATABASE/#postgresql-backup","title":"PostgreSQL Backup","text":"<pre><code>pg_dump -h localhost -U user soliplex &gt; backup.sql\n</code></pre>"},{"location":"ingester/DATABASE/#vacuum-sqlite","title":"Vacuum (SQLite)","text":"<pre><code>sqlite3 db/documents.db \"VACUUM;\"\n</code></pre>"},{"location":"ingester/DATABASE/#analyze-postgresql","title":"Analyze (PostgreSQL)","text":"<pre><code>psql -h localhost -U user -d soliplex -c \"ANALYZE;\"\n</code></pre>"},{"location":"ingester/DATABASE/#query-examples","title":"Query Examples","text":""},{"location":"ingester/DATABASE/#find-failed-workflows","title":"Find Failed Workflows","text":"<pre><code>from soliplex_ingester.lib.models import WorkflowRun, RunStatus, get_session\nfrom sqlmodel import select\n\nasync with get_session() as session:\n    query = select(WorkflowRun).where(WorkflowRun.status == RunStatus.FAILED)\n    results = await session.exec(query)\n    failed_runs = results.all()\n</code></pre>"},{"location":"ingester/DATABASE/#get-batch-statistics","title":"Get Batch Statistics","text":"<pre><code>from sqlmodel import func, select\n\nasync with get_session() as session:\n    query = select(\n        func.count(WorkflowRun.id).label(\"total\"),\n        WorkflowRun.status\n    ).where(\n        WorkflowRun.batch_id == batch_id\n    ).group_by(WorkflowRun.status)\n\n    results = await session.exec(query)\n    stats = {row.status: row.total for row in results}\n</code></pre>"},{"location":"ingester/DATABASE/#find-stale-workers","title":"Find Stale Workers","text":"<pre><code>from datetime import datetime, timedelta\n\ncutoff = datetime.now() - timedelta(seconds=600)\nquery = select(WorkerCheckin).where(WorkerCheckin.last_checkin &lt; cutoff)\nstale_workers = await session.exec(query)\n</code></pre>"},{"location":"ingester/GETTING_STARTED/","title":"Getting Started with Soliplex Ingester","text":""},{"location":"ingester/GETTING_STARTED/#quick-start","title":"Quick Start","text":"<p>This guide will help you get Soliplex Ingester up and running in minutes.</p>"},{"location":"ingester/GETTING_STARTED/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12 or higher</li> <li>pip or uv package manager</li> <li>SQLite (included with Python) or PostgreSQL</li> <li>Docling server for document parsing (optional)</li> <li>S3 backend (optional)</li> </ul>"},{"location":"ingester/GETTING_STARTED/#docker-services","title":"Docker Services","text":"<p>A sample docker compose file is provided to show how to configure services used by the ingester.</p>"},{"location":"ingester/GETTING_STARTED/#postgres","title":"postgres","text":"<p>The postgres configuration includes references to startup scripts to create sample users and permissions, but for a production deployment, a more sophisticated secrets configuration should be used. Data is stored in a docker volume which may also need to be changed for a production setup.</p>"},{"location":"ingester/GETTING_STARTED/#docling-serve","title":"docling-serve","text":"<p>Docling-serve is used to convert pdf documents into markdown and docling JSON documents for use in the pipelline. In order to allow for higher concurrency, the example file shows how to use multiple instances of docling that are load balanced using cookies. The docling client in the ingester handles the cookies to ensure the full request cycle stays on the same server.</p> <p>The configuration also shows how to provision GPUs for use in parsing.  Depending on server hardware, the device ids may have to be changed. Multiple instances can share a single GPU but testing is required to determine the optimal configuration.</p> <p>Docling serve is prone to leak memory so constraining its memory allocation is necessary to prevent overloading server resources.  The restart settings along with load balancing and retry logic in the client will ensure that the ingester is able to continue uninterrupted.</p>"},{"location":"ingester/GETTING_STARTED/#seaweedfs","title":"seaweedfs","text":"<p>SeaweedFS is provided as a simple S3 compatible storage if desired for either the intermediate artifacts or the final LanceDB databases. An initialization script is provided to create the necessary bucket and authentication information. A production configuration should use a more robust secrets confugration.  Cloud providers can also be used for storage if desired.</p>"},{"location":"ingester/GETTING_STARTED/#_1","title":"Getting Started","text":""},{"location":"ingester/GETTING_STARTED/#1-install-package","title":"1. Install Package","text":""},{"location":"ingester/GETTING_STARTED/#installation-from-source","title":"Installation from source","text":"<p>Using pip: <pre><code>cd soliplex-ingester\npip install -e .\n</code></pre></p> <p>Using uv: <pre><code>cd soliplex-ingester\nuv pip install -e .\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#running-your-own-install","title":"Running your own Install","text":"<p>You can integrate soliplex ingester into another python project by installing it like any other package.  This will allow you to use custom methods for any part of the workflow if desired.</p> <pre><code>uv init --lib &lt;my project name&gt;\nuv add https://github.com/soliplex/ingester.git\nuv run si-cli bootstrap\n</code></pre> <p>This installs the package and makes the <code>si-cli</code> command available.</p>"},{"location":"ingester/GETTING_STARTED/#2-verify-installation","title":"2. Verify Installation","text":"<pre><code>si-cli --help\n</code></pre> <p>You should see the CLI help menu.</p>"},{"location":"ingester/GETTING_STARTED/#configuration","title":"Configuration","text":""},{"location":"ingester/GETTING_STARTED/#3-set-environment-variables","title":"3. Set Environment Variables","text":"<p>Automatically configure: <pre><code>uv run init-env\n</code></pre></p> <p>Manually create a <code>.env</code> file in the project root:</p> <pre><code># Minimum required configuration\nDOC_DB_URL=sqlite+aiosqlite:///./db/documents.db\n\n# Optional: Docling service (for document parsing)\nDOCLING_SERVER_URL=http://localhost:5001/v1\n\n# Optional: Adjust logging\nLOG_LEVEL=INFO\n</code></pre> <p>Load the environment: <pre><code>export $(cat .env | xargs)\n</code></pre></p> <p>Or on Windows: <pre><code>Get-Content .env | ForEach-Object { $var = $_.Split('='); [Environment]::SetEnvironmentVariable($var[0], $var[1]) }\n</code></pre> Alternatively, si-cli can be run via uv to initialize the environment file <pre><code>uv run --env-file=.env si-cli\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#4-validate-configuration","title":"4. Validate Configuration","text":"<pre><code>si-cli validate-settings\n</code></pre> <p>This should display your configuration without errors.</p>"},{"location":"ingester/GETTING_STARTED/#database-setup","title":"Database Setup","text":""},{"location":"ingester/GETTING_STARTED/#5-initialize-database","title":"5. Initialize Database","text":"<pre><code>si-cli db-init\n</code></pre> <p>This creates: - SQLite database file at <code>db/documents.db</code> - All necessary tables - Runs migrations</p>"},{"location":"ingester/GETTING_STARTED/#start-the-server","title":"Start the Server","text":""},{"location":"ingester/GETTING_STARTED/#6-run-the-development-server","title":"6. Run the Development Server","text":"<pre><code>si-cli serve --reload\n</code></pre> <p>The server starts on <code>http://127.0.0.1:8000</code> with: - Auto-reload on code changes - Integrated worker for processing - OpenAPI docs at <code>/docs</code></p> <p>Test the server: <pre><code>curl http://localhost:8000/docs\n</code></pre></p> <p>You should see the Swagger UI.</p>"},{"location":"ingester/GETTING_STARTED/#your-first-batch","title":"Your First Batch","text":""},{"location":"ingester/GETTING_STARTED/#7-create-a-batch","title":"7. Create a Batch","text":"<pre><code>curl -X POST \"http://localhost:8000/api/v1/batch/\" \\\n  -d \"source=test\" \\\n  -d \"name=My First Batch\"\n</code></pre> <p>Response: <pre><code>{\n  \"batch_id\": 1\n}\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#8-ingest-a-document","title":"8. Ingest a Document","text":"<p>Option A: Upload a file <pre><code>curl -X POST \"http://localhost:8000/api/v1/document/ingest-document\" \\\n  -F \"file=@sample.pdf\" \\\n  -F \"source_uri=/documents/sample.pdf\" \\\n  -F \"source=test\" \\\n  -F \"batch_id=1\"\n</code></pre></p> <p>Option B: Provide a URI (requires Docling server) <pre><code>curl -X POST \"http://localhost:8000/api/v1/document/ingest-document\" \\\n  -F \"input_uri=https://example.com/document.pdf\" \\\n  -F \"source_uri=/remote/document.pdf\" \\\n  -F \"source=test\" \\\n  -F \"batch_id=1\"\n</code></pre></p> <p>Response: <pre><code>{\n  \"batch_id\": 1,\n  \"document_uri\": \"/documents/sample.pdf\",\n  \"document_hash\": \"sha256-abc123...\",\n  \"source\": \"test\",\n  \"uri_id\": 1\n}\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#9-start-workflow-processing","title":"9. Start Workflow Processing","text":"<pre><code>curl -X POST \"http://localhost:8000/api/v1/batch/start-workflows\" \\\n  -d \"batch_id=1\" \\\n  -d \"workflow_definition_id=batch\"\n</code></pre> <p>Response: <pre><code>{\n  \"message\": \"Workflows started\",\n  \"workflows\": 1,\n  \"run_group\": 1\n}\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#10-monitor-progress","title":"10. Monitor Progress","text":"<p>Check batch status: <pre><code>curl \"http://localhost:8000/api/v1/batch/status?batch_id=1\"\n</code></pre></p> <p>Response: <pre><code>{\n  \"batch\": { ... },\n  \"document_count\": 1,\n  \"workflow_count\": {\n    \"COMPLETED\": 0,\n    \"RUNNING\": 1,\n    \"PENDING\": 0\n  },\n  \"workflows\": [ ... ],\n  \"parsed\": 0,\n  \"remaining\": 1\n}\n</code></pre></p> <p>Watch workflow runs: <pre><code>watch -n 5 'curl -s \"http://localhost:8000/api/v1/workflow/?batch_id=1\"'\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#11-view-results","title":"11. View Results","text":"<p>Once processing completes, check the document:</p> <pre><code>curl \"http://localhost:8000/api/v1/document/?batch_id=1\"\n</code></pre>"},{"location":"ingester/GETTING_STARTED/#next-steps","title":"Next Steps","text":""},{"location":"ingester/GETTING_STARTED/#explore-workflows","title":"Explore Workflows","text":"<p>List available workflows: <pre><code>si-cli list-workflows\n</code></pre></p> <p>Inspect a workflow: <pre><code>si-cli dump-workflow batch\n</code></pre></p> <p>View workflow runs: <pre><code>curl \"http://localhost:8000/api/v1/workflow/?batch_id=1\"\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#configure-parameters","title":"Configure Parameters","text":"<p>List parameter sets: <pre><code>si-cli list-param-sets\n</code></pre></p> <p>View parameters: <pre><code>si-cli dump-param-set default\n</code></pre></p> <p>Create custom parameters: 1. Copy <code>config/params/default.yaml</code> to <code>config/params/custom.yaml</code> 2. Modify settings as needed 3. Use in API: <code>-d \"param_id=custom\"</code></p>"},{"location":"ingester/GETTING_STARTED/#scale-workers","title":"Scale Workers","text":"<p>Run additional workers: <pre><code># Terminal 1\nsi-cli worker\n\n# Terminal 2\nsi-cli worker\n\n# Terminal 3\nsi-cli worker\n</code></pre></p> <p>Each worker processes steps independently, increasing throughput.</p>"},{"location":"ingester/GETTING_STARTED/#monitor-system","title":"Monitor System","text":"<p>API Documentation: Browse to <code>http://localhost:8000/docs</code> for interactive API docs.</p> <p>Database Inspection: <pre><code>sqlite3 db/documents.db\nsqlite&gt; .tables\nsqlite&gt; SELECT * FROM documentbatch;\nsqlite&gt; SELECT * FROM workflowrun WHERE batch_id = 1;\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ingester/GETTING_STARTED/#server-wont-start","title":"Server Won't Start","text":"<p>Problem: Configuration validation fails</p> <p>Solution: <pre><code>si-cli validate-settings\n</code></pre></p> <p>Fix any reported errors in your <code>.env</code> file.</p> <p>Problem: Port already in use</p> <p>Solution: <pre><code>si-cli serve --port 8001\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#workflows-stuck","title":"Workflows Stuck","text":"<p>Problem: Workflows remain in PENDING status</p> <p>Solution: Ensure a worker is running: <pre><code>si-cli worker\n</code></pre></p> <p>Check worker logs for errors.</p>"},{"location":"ingester/GETTING_STARTED/#document-parsing-fails","title":"Document Parsing Fails","text":"<p>Problem: Parse step fails with connection error</p> <p>Solution: 1. Verify Docling server is running 2. Check <code>DOCLING_SERVER_URL</code> is correct 3. Test connectivity:    <pre><code>curl http://localhost:5001/v1/health\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#database-errors","title":"Database Errors","text":"<p>Problem: Database connection fails</p> <p>Solution: 1. Check <code>DOC_DB_URL</code> format 2. Ensure directory exists: <code>mkdir -p db</code> 3. Check permissions: <code>chmod 755 db</code> 4. Reinitialize: <code>si-cli db-init</code></p>"},{"location":"ingester/GETTING_STARTED/#development-mode","title":"Development Mode","text":"<p>For active development:</p> <p>1. Enable auto-reload: <pre><code>si-cli serve --reload\n</code></pre></p> <p>2. Set debug logging: <pre><code>export LOG_LEVEL=DEBUG\nsi-cli serve --reload\n</code></pre></p> <p>3. Watch logs: <pre><code>si-cli serve --reload 2&gt;&amp;1 | tee server.log\n</code></pre></p> <p>4. Monitor database: <pre><code>watch -n 2 'sqlite3 db/documents.db \"SELECT status, COUNT(*) FROM workflowrun GROUP BY status\"'\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#production-deployment","title":"Production Deployment","text":""},{"location":"ingester/GETTING_STARTED/#configuration_1","title":"Configuration","text":"<p>Create production <code>.env</code>:</p> <pre><code># Database\nDOC_DB_URL=postgresql+asyncpg://user:password@db-host:5432/soliplex\n\n# Services\nDOCLING_SERVER_URL=http://docling-prod:5001/v1\n\n# Logging\nLOG_LEVEL=WARNING\n\n# Performance\nINGEST_WORKER_CONCURRENCY=20\nDOCLING_CONCURRENCY=5\nWORKER_TASK_COUNT=10\n\n# Storage\nFILE_STORE_DIR=/var/lib/soliplex/files\nLANCEDB_DIR=/var/lib/soliplex/lancedb\n</code></pre>"},{"location":"ingester/GETTING_STARTED/#run-services","title":"Run Services","text":"<p>Server: <pre><code>si-cli serve --host 0.0.0.0 --port 8000 --workers 4\n</code></pre></p> <p>Workers: (in separate processes) <pre><code>si-cli worker  # Worker 1\nsi-cli worker  # Worker 2\nsi-cli worker  # Worker 3\n</code></pre></p> <p>Behind Nginx: <pre><code>upstream soliplex {\n    server 127.0.0.1:8000;\n}\n\nserver {\n    listen 80;\n    server_name soliplex.example.com;\n\n    location / {\n        proxy_pass http://soliplex;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#docker-deployment","title":"Docker Deployment","text":"<p>Dockerfile: <pre><code>FROM python:3.12-slim\n\nWORKDIR /app\nCOPY . .\nRUN pip install -e .\n\nCMD [\"si-cli\", \"serve\", \"--host\", \"0.0.0.0\"]\n</code></pre></p> <p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  server:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      DOC_DB_URL: postgresql+asyncpg://postgres:password@db/soliplex\n      DOCLING_SERVER_URL: http://docling:5001/v1\n    depends_on:\n      - db\n\n  worker:\n    build: .\n    command: si-cli worker\n    environment:\n      DOC_DB_URL: postgresql+asyncpg://postgres:password@db/soliplex\n      DOCLING_SERVER_URL: http://docling:5001/v1\n    depends_on:\n      - db\n    deploy:\n      replicas: 3\n\n  db:\n    image: postgres:16\n    environment:\n      POSTGRES_DB: soliplex\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: password\n    volumes:\n      - db-data:/var/lib/postgresql/data\n\nvolumes:\n  db-data:\n</code></pre></p> <p>Run: <pre><code>docker-compose up -d\n</code></pre></p>"},{"location":"ingester/GETTING_STARTED/#learning-more","title":"Learning More","text":""},{"location":"ingester/GETTING_STARTED/#documentation","title":"Documentation","text":"<ul> <li>Architecture Overview - System design and components</li> <li>API Reference - Complete REST API documentation</li> <li>Workflow System - Workflow concepts and configuration</li> <li>Database Schema - Data models and relationships</li> <li>Configuration - Environment variables and settings</li> <li>CLI Reference - Command-line interface guide</li> </ul>"},{"location":"ingester/GETTING_STARTED/#examples","title":"Examples","text":"<p>Check the <code>examples/</code> directory (if available) for: - Sample workflows - Integration scripts - Custom step handlers - Batch processing examples</p>"},{"location":"ingester/GETTING_STARTED/#community","title":"Community","text":"<ul> <li>Issues: Report bugs and request features</li> <li>Discussions: Ask questions and share ideas</li> <li>Contributing: See CONTRIBUTING.md (if available)</li> </ul>"},{"location":"ingester/GETTING_STARTED/#common-patterns","title":"Common Patterns","text":""},{"location":"ingester/GETTING_STARTED/#batch-document-ingestion","title":"Batch Document Ingestion","text":"<pre><code>import asyncio\nfrom pathlib import Path\nimport httpx\n\nasync def ingest_directory(directory: Path, batch_id: int, source: str):\n    \"\"\"Ingest all documents in a directory.\"\"\"\n    async with httpx.AsyncClient() as client:\n        for file_path in directory.glob(\"**/*.pdf\"):\n            with open(file_path, \"rb\") as f:\n                files = {\"file\": f}\n                data = {\n                    \"source_uri\": str(file_path),\n                    \"source\": source,\n                    \"batch_id\": batch_id,\n                }\n                response = await client.post(\n                    \"http://localhost:8000/api/v1/document/ingest-document\",\n                    files=files,\n                    data=data,\n                )\n                print(f\"Ingested {file_path}: {response.status_code}\")\n\n# Usage\nasyncio.run(ingest_directory(Path(\"/documents\"), batch_id=1, source=\"filesystem\"))\n</code></pre>"},{"location":"ingester/GETTING_STARTED/#monitor-batch-progress","title":"Monitor Batch Progress","text":"<pre><code>import asyncio\nimport httpx\n\nasync def wait_for_batch(batch_id: int, poll_interval: int = 5):\n    \"\"\"Wait for batch processing to complete.\"\"\"\n    async with httpx.AsyncClient() as client:\n        while True:\n            response = await client.get(\n                f\"http://localhost:8000/api/v1/batch/status\",\n                params={\"batch_id\": batch_id}\n            )\n            data = response.json()\n            counts = data[\"workflow_count\"]\n\n            print(f\"Completed: {counts.get('COMPLETED', 0)}, \"\n                  f\"Running: {counts.get('RUNNING', 0)}, \"\n                  f\"Failed: {counts.get('FAILED', 0)}\")\n\n            if counts.get(\"RUNNING\", 0) == 0 and counts.get(\"PENDING\", 0) == 0:\n                print(\"Batch complete!\")\n                break\n\n            await asyncio.sleep(poll_interval)\n\n# Usage\nasyncio.run(wait_for_batch(1))\n</code></pre>"},{"location":"ingester/GETTING_STARTED/#retry-failed-workflows","title":"Retry Failed Workflows","text":"<pre><code>#!/bin/bash\n# retry_failed.sh\n\nBATCH_ID=$1\nRUN_GROUP=$(curl -s \"http://localhost:8000/api/v1/workflow/run-groups?batch_id=${BATCH_ID}\" | jq -r '.[0].id')\n\nif [ -n \"$RUN_GROUP\" ]; then\n    curl -X POST \"http://localhost:8000/api/v1/workflow/retry\" \\\n        -d \"run_group_id=${RUN_GROUP}\"\n    echo \"Retried run group ${RUN_GROUP}\"\nelse\n    echo \"No run group found for batch ${BATCH_ID}\"\nfi\n</code></pre>"},{"location":"ingester/GETTING_STARTED/#whats-next","title":"What's Next?","text":"<p>Now that you have Soliplex Ingester running:</p> <ol> <li>Customize workflows - Create workflows for your specific needs</li> <li>Integrate services - Connect your data sources and RAG backends</li> <li>Scale processing - Add more workers and optimize configuration</li> <li>Monitor production - Set up logging, metrics, and alerting</li> <li>Build applications - Use the API to build document processing apps</li> </ol> <p>Welcome to Soliplex Ingester! \ud83d\ude80</p>"},{"location":"ingester/WORKFLOWS/","title":"Workflow System Documentation","text":""},{"location":"ingester/WORKFLOWS/#overview","title":"Overview","text":"<p>The Soliplex Ingester workflow system orchestrates multi-step document processing pipelines. Each document flows through a series of configurable steps, with automatic retry logic, status tracking, and parallel processing support.</p>"},{"location":"ingester/WORKFLOWS/#core-concepts","title":"Core Concepts","text":""},{"location":"ingester/WORKFLOWS/#workflow-definition","title":"Workflow Definition","text":"<p>A WorkflowDefinition specifies the processing pipeline for documents. It defines: - Unique ID and name - Item steps (processing stages) - Lifecycle event handlers - Retry policies</p> <p>Defined in YAML files at: <code>config/workflows/*.yaml</code></p>"},{"location":"ingester/WORKFLOWS/#workflow-run","title":"Workflow Run","text":"<p>A WorkflowRun represents a single execution of a workflow for one document. It tracks: - Status (PENDING \u2192 RUNNING \u2192 COMPLETED/FAILED) - Start and completion timestamps - Priority level - Associated document and batch</p>"},{"location":"ingester/WORKFLOWS/#run-group","title":"Run Group","text":"<p>A RunGroup aggregates multiple workflow runs that were started together (e.g., all documents in a batch). It provides: - Group-level status tracking - Aggregate statistics - Batch coordination</p>"},{"location":"ingester/WORKFLOWS/#run-step","title":"Run Step","text":"<p>A RunStep is one stage of execution within a workflow run. Each step: - Executes a specific handler method - Has its own status and retry counter - Produces artifacts stored in the file system - Updates database on completion/failure</p>"},{"location":"ingester/WORKFLOWS/#workflow-step-types","title":"Workflow Step Types","text":"<p>The system supports these predefined step types:</p>"},{"location":"ingester/WORKFLOWS/#ingest","title":"INGEST","text":"<ul> <li>Purpose: Load raw document into the system</li> <li>Input: File bytes or URI</li> <li>Output: Document stored in file system</li> <li>Artifact: <code>ArtifactType.DOC</code></li> </ul>"},{"location":"ingester/WORKFLOWS/#validate","title":"VALIDATE","text":"<ul> <li>Purpose: Check document format and readability</li> <li>Input: Raw document</li> <li>Output: Validation result</li> <li>Handler: <code>soliplex_ingester.lib.workflow.validate_document</code></li> </ul>"},{"location":"ingester/WORKFLOWS/#parse","title":"PARSE","text":"<ul> <li>Purpose: Extract text, structure, and metadata</li> <li>Input: Raw document</li> <li>Output: Markdown and JSON representations</li> <li>Artifacts: <code>ArtifactType.PARSED_MD</code>, <code>ArtifactType.PARSED_JSON</code></li> <li>Handler: <code>soliplex_ingester.lib.workflow.parse_document</code></li> <li>Service: Docling server</li> </ul>"},{"location":"ingester/WORKFLOWS/#chunk","title":"CHUNK","text":"<ul> <li>Purpose: Split document into semantic chunks</li> <li>Input: Parsed markdown</li> <li>Output: Array of text chunks</li> <li>Artifact: <code>ArtifactType.CHUNKS</code></li> <li>Handler: <code>soliplex_ingester.lib.workflow.chunk_document</code></li> </ul>"},{"location":"ingester/WORKFLOWS/#embed","title":"EMBED","text":"<ul> <li>Purpose: Generate vector embeddings for chunks</li> <li>Input: Text chunks</li> <li>Output: Embedding vectors</li> <li>Artifact: <code>ArtifactType.EMBEDDINGS</code></li> <li>Handler: <code>soliplex_ingester.lib.workflow.embed_document</code></li> </ul>"},{"location":"ingester/WORKFLOWS/#store","title":"STORE","text":"<ul> <li>Purpose: Save embeddings to RAG system</li> <li>Input: Embeddings</li> <li>Output: RAG document ID</li> <li>Artifact: <code>ArtifactType.RAG</code></li> <li>Handler: <code>soliplex_ingester.lib.workflow.save_to_rag</code></li> <li>Backend: LanceDB + HaikuRAG</li> </ul>"},{"location":"ingester/WORKFLOWS/#enrich","title":"ENRICH","text":"<ul> <li>Purpose: Add metadata or perform additional processing</li> <li>Input: Document and existing artifacts</li> <li>Output: Enhanced metadata</li> <li>Handler: Custom (user-defined)</li> </ul>"},{"location":"ingester/WORKFLOWS/#route","title":"ROUTE","text":"<ul> <li>Purpose: Conditional logic for workflow branching</li> <li>Input: Document state</li> <li>Output: Routing decision</li> <li>Handler: Custom (user-defined)</li> </ul>"},{"location":"ingester/WORKFLOWS/#workflow-configuration","title":"Workflow Configuration","text":""},{"location":"ingester/WORKFLOWS/#workflow-definition-yaml","title":"Workflow Definition YAML","text":"<p>Example: <code>config/workflows/batch.yaml</code></p> <pre><code>id: batch\nname: Batch Workflow\nmeta: {}\n\nitem_steps:\n  validate:\n    name: docling validate\n    retries: 3\n    method: soliplex_ingester.lib.workflow.validate_document\n    parameters: {}\n\n  parse:\n    name: docling parse\n    retries: 3\n    method: soliplex_ingester.lib.workflow.parse_document\n    parameters: {}\n\n  chunk:\n    name: docling chunk\n    retries: 3\n    method: soliplex_ingester.lib.workflow.chunk_document\n    parameters: {}\n\n  embed:\n    name: embeddings\n    retries: 3\n    method: soliplex_ingester.lib.workflow.embed_document\n    parameters: {}\n\n  store:\n    name: save to rag\n    retries: 3\n    method: soliplex_ingester.lib.workflow.save_to_rag\n    parameters: {}\n\nlifecycle_events:\n  group_start:\n    - name: log group start\n      method: soliplex_ingester.lib.workflow.log_event\n      retries: 1\n      parameters:\n        message: \"Starting workflow group\"\n</code></pre>"},{"location":"ingester/WORKFLOWS/#parameter-set-yaml","title":"Parameter Set YAML","text":"<p>Parameters control step behavior without changing the workflow definition.</p> <p>Example: <code>config/params/default.yaml</code></p> <pre><code>id: default\nname: Default Parameters\nmeta:\n  description: Standard processing parameters\n\nconfig:\n  parse:\n    format: markdown\n    ocr_enabled: true\n\n  chunk:\n    chunk_size: 512\n    chunk_overlap: 50\n    separator: \"\\n\\n\"\n\n  embed:\n    model: text-embedding-3-small\n    batch_size: 1000\n\n  store:\n    data_dir: lancedb\n    collection_name: documents\n</code></pre>"},{"location":"ingester/WORKFLOWS/#workflow-execution","title":"Workflow Execution","text":""},{"location":"ingester/WORKFLOWS/#creating-workflows","title":"Creating Workflows","text":"<p>For a Batch: <pre><code>curl -X POST \"http://localhost:8000/api/v1/batch/start-workflows\" \\\n  -d \"batch_id=1\" \\\n  -d \"workflow_definition_id=batch\" \\\n  -d \"param_id=default\"\n</code></pre></p> <p>For a Single Document: <pre><code>curl -X POST \"http://localhost:8000/api/v1/workflow/\" \\\n  -d \"doc_id=sha256-abc123...\" \\\n  -d \"workflow_definition_id=batch\"\n</code></pre></p>"},{"location":"ingester/WORKFLOWS/#worker-processing","title":"Worker Processing","text":"<p>Workers continuously poll for pending steps:</p> <ol> <li>Query database for PENDING steps with highest priority</li> <li>Lock step with <code>FOR UPDATE</code> to prevent duplicate processing</li> <li>Transition status: PENDING \u2192 RUNNING</li> <li>Execute handler method</li> <li>Store artifacts in file system</li> <li>Update step status: RUNNING \u2192 COMPLETED/ERROR</li> <li>Update parent run status based on step results</li> <li>Repeat</li> </ol> <p>Start a worker: <pre><code>si-cli worker\n</code></pre></p> <p>Or via server (starts worker automatically): <pre><code>si-cli serve\n</code></pre></p>"},{"location":"ingester/WORKFLOWS/#status-transitions","title":"Status Transitions","text":"<p>Valid Transitions: - PENDING \u2192 RUNNING - RUNNING \u2192 COMPLETED - RUNNING \u2192 ERROR - ERROR \u2192 RUNNING (retry) - ERROR \u2192 FAILED (after max retries)</p> <p>Invalid Transitions: - COMPLETED \u2192 RUNNING (no re-running completed steps) - FAILED \u2192 RUNNING (use retry endpoint instead)</p>"},{"location":"ingester/WORKFLOWS/#lifecycle-events","title":"Lifecycle Events","text":"<p>Lifecycle events allow custom logic at key points:</p>"},{"location":"ingester/WORKFLOWS/#event-types","title":"Event Types","text":"<ul> <li><code>GROUP_START</code> - Run group begins</li> <li><code>GROUP_END</code> - Run group completes</li> <li><code>ITEM_START</code> - Workflow run begins</li> <li><code>ITEM_END</code> - Workflow run completes</li> <li><code>ITEM_FAILED</code> - Workflow run fails</li> <li><code>STEP_START</code> - Step begins</li> <li><code>STEP_END</code> - Step completes</li> <li><code>STEP_FAILED</code> - Step fails</li> </ul>"},{"location":"ingester/WORKFLOWS/#event-handler-example","title":"Event Handler Example","text":"<pre><code>lifecycle_events:\n  item_failed:\n    - name: notify on failure\n      method: myapp.notifications.send_alert\n      retries: 3\n      parameters:\n        channel: \"#alerts\"\n        message: \"Document processing failed\"\n</code></pre>"},{"location":"ingester/WORKFLOWS/#retry-logic","title":"Retry Logic","text":""},{"location":"ingester/WORKFLOWS/#automatic-retries","title":"Automatic Retries","text":"<p>Steps automatically retry on error: - Configurable retry count per step - Exponential backoff (implementation dependent) - Status: ERROR during retries, FAILED when exhausted</p>"},{"location":"ingester/WORKFLOWS/#manual-retry","title":"Manual Retry","text":"<p>Reset failed steps for a run group: <pre><code>curl -X POST \"http://localhost:8000/api/v1/workflow/retry\" \\\n  -d \"run_group_id=5\"\n</code></pre></p> <p>This resets all FAILED steps to PENDING for re-processing.</p>"},{"location":"ingester/WORKFLOWS/#monitoring","title":"Monitoring","text":""},{"location":"ingester/WORKFLOWS/#check-run-group-status","title":"Check Run Group Status","text":"<pre><code>curl \"http://localhost:8000/api/v1/workflow/run-groups/5/stats\"\n</code></pre> <p>Returns: <pre><code>{\n  \"total_runs\": 100,\n  \"completed\": 95,\n  \"running\": 3,\n  \"pending\": 0,\n  \"failed\": 2,\n  \"average_duration\": 45.3,\n  \"group_status\": \"RUNNING\"\n}\n</code></pre></p>"},{"location":"ingester/WORKFLOWS/#check-specific-workflow-run","title":"Check Specific Workflow Run","text":"<pre><code>curl \"http://localhost:8000/api/v1/workflow/runs/42\"\n</code></pre> <p>Returns workflow run with all steps and their status.</p>"},{"location":"ingester/WORKFLOWS/#query-steps-by-status","title":"Query Steps by Status","text":"<pre><code>curl \"http://localhost:8000/api/v1/workflow/steps?status=FAILED\"\n</code></pre> <p>Lists all failed steps for investigation.</p>"},{"location":"ingester/WORKFLOWS/#custom-step-handlers","title":"Custom Step Handlers","text":""},{"location":"ingester/WORKFLOWS/#handler-signature","title":"Handler Signature","text":"<pre><code>async def custom_handler(\n    run_step: RunStep,\n    workflow_run: WorkflowRun,\n    doc: Document,\n    step_params: dict[str, Any]\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Custom workflow step handler.\n\n    Args:\n        run_step: Current step being executed\n        workflow_run: Parent workflow run\n        doc: Document being processed\n        step_params: Parameters from config\n\n    Returns:\n        Dictionary with result metadata\n\n    Raises:\n        Exception: On failure (will trigger retry)\n    \"\"\"\n    # Your processing logic here\n    result_data = await process_document(doc)\n\n    # Store artifacts if needed\n    await store_artifact(\n        doc.hash,\n        ArtifactType.CUSTOM,\n        result_data\n    )\n\n    return {\"status\": \"success\", \"items_processed\": 42}\n</code></pre>"},{"location":"ingester/WORKFLOWS/#registering-custom-handler","title":"Registering Custom Handler","text":"<ol> <li>Define the handler in your Python module</li> <li>Add to workflow YAML: <pre><code>item_steps:\n  custom_step:\n    name: My Custom Step\n    retries: 2\n    method: myapp.handlers.custom_handler\n    parameters:\n      param1: value1\n</code></pre></li> <li>Ensure module is importable by the worker process</li> </ol>"},{"location":"ingester/WORKFLOWS/#worker-configuration","title":"Worker Configuration","text":""},{"location":"ingester/WORKFLOWS/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>INGEST_WORKER_CONCURRENCY</code> - Max concurrent workflow steps (default: 10)</li> <li><code>INGEST_QUEUE_CONCURRENCY</code> - Max concurrent queue operations (default: 20)</li> <li><code>DOCLING_CONCURRENCY</code> - Max concurrent Docling requests (default: 3)</li> <li><code>WORKER_TASK_COUNT</code> - Steps to fetch per query (default: 5)</li> <li><code>WORKER_CHECKIN_INTERVAL</code> - Heartbeat interval in seconds (default: 120)</li> <li><code>WORKER_CHECKIN_TIMEOUT</code> - Worker timeout in seconds (default: 600)</li> </ul>"},{"location":"ingester/WORKFLOWS/#multiple-workers","title":"Multiple Workers","text":"<p>Run multiple workers for increased throughput:</p> <pre><code># Terminal 1\nsi-cli worker\n\n# Terminal 2\nsi-cli worker\n\n# Terminal 3\nsi-cli worker\n</code></pre> <p>Database locking ensures no duplicate processing.</p>"},{"location":"ingester/WORKFLOWS/#artifact-storage","title":"Artifact Storage","text":""},{"location":"ingester/WORKFLOWS/#storage-paths","title":"Storage Paths","text":"<p>Artifacts are stored under <code>FILE_STORE_DIR</code> with subdirectories:</p> <ul> <li><code>document_store_dir/</code> - Raw documents</li> <li><code>parsed_markdown_store_dir/</code> - Parsed markdown</li> <li><code>parsed_json_store_dir/</code> - Parsed JSON</li> <li><code>chunks_store_dir/</code> - Text chunks</li> <li><code>embeddings_store_dir/</code> - Embedding vectors</li> </ul>"},{"location":"ingester/WORKFLOWS/#file-naming","title":"File Naming","text":"<p>Files are named by document hash: <pre><code>{storage_dir}/{hash}\n</code></pre></p> <p>Example: <pre><code>file_store/markdown/sha256-abc123def456...\n</code></pre></p>"},{"location":"ingester/WORKFLOWS/#storage-backends","title":"Storage Backends","text":"<p>Configure via <code>FILE_STORE_TARGET</code>: - <code>fs</code> - Local filesystem (default) - <code>s3</code> - S3-compatible storage (via OpenDAL) - Other OpenDAL-supported backends</p>"},{"location":"ingester/WORKFLOWS/#best-practices","title":"Best Practices","text":""},{"location":"ingester/WORKFLOWS/#workflow-design","title":"Workflow Design","text":"<ol> <li>Keep steps atomic - Each step should do one thing well</li> <li>Make steps idempotent - Re-running a step should be safe</li> <li>Use appropriate retries - 3 retries for transient errors, 1 for validation</li> <li>Store intermediate results - Save artifacts for debugging and recovery</li> </ol>"},{"location":"ingester/WORKFLOWS/#error-handling","title":"Error Handling","text":"<ol> <li>Raise exceptions for retriable errors</li> <li>Log context before raising (worker ID, document hash, step)</li> <li>Use status_meta to store error details</li> <li>Monitor failed steps and investigate patterns</li> </ol>"},{"location":"ingester/WORKFLOWS/#performance","title":"Performance","text":"<ol> <li>Tune concurrency based on available resources</li> <li>Batch operations where possible (embeddings)</li> <li>Use priorities for urgent documents</li> <li>Monitor worker health via heartbeat table</li> </ol>"},{"location":"ingester/WORKFLOWS/#testing","title":"Testing","text":"<ol> <li>Test handlers independently with mock data</li> <li>Use small batches for integration testing</li> <li>Verify artifact storage after each step</li> <li>Test retry logic by simulating failures</li> </ol>"},{"location":"ingester/WORKFLOWS/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ingester/WORKFLOWS/#stuck-workflows","title":"Stuck Workflows","text":"<p>Symptom: Workflows remain in RUNNING status indefinitely</p> <p>Solution: 1. Check worker logs for exceptions 2. Query stuck steps: <code>SELECT * FROM runstep WHERE status='RUNNING' AND start_date &lt; NOW() - INTERVAL '1 hour'</code> 3. Check worker heartbeat: <code>SELECT * FROM workercheckin</code> 4. Restart workers if stale</p>"},{"location":"ingester/WORKFLOWS/#failed-steps","title":"Failed Steps","text":"<p>Symptom: Steps transition to FAILED status</p> <p>Solution: 1. Query step details: <code>GET /api/v1/workflow/steps?status=FAILED</code> 2. Check <code>status_message</code> and <code>status_meta</code> for error info 3. Fix underlying issue (service down, invalid config, etc.) 4. Retry: <code>POST /api/v1/workflow/retry</code></p>"},{"location":"ingester/WORKFLOWS/#slow-processing","title":"Slow Processing","text":"<p>Symptom: Low throughput, long durations</p> <p>Solution: 1. Check Docling server response time 2. Increase <code>INGEST_WORKER_CONCURRENCY</code> 3. Run multiple workers 4. Verify database performance (add indexes if needed) 5. Check network latency to external services</p>"},{"location":"ingester/WORKFLOWS/#duplicate-processing","title":"Duplicate Processing","text":"<p>Symptom: Same document processed multiple times</p> <p>Solution: 1. Verify database locking is working (<code>FOR UPDATE</code>) 2. Check for unique constraint violations in logs 3. Ensure workers use distinct worker IDs 4. Verify step status transitions are atomic</p>"},{"location":"soliplex/","title":"Soliplex Documentation","text":"<p>Welcome to the Soliplex documentation. This system provides AI-powered retrieval-augmented generation capabilities for intelligent document search and question answering.</p>"},{"location":"soliplex/#quick-start","title":"Quick Start","text":"<ol> <li>Overview - Learn about the system architecture and features</li> <li>RAG Database Setup - Set up the RAG search database</li> <li>Server Setup - Set up the FastAPI backend server</li> <li>Client Setup - Configure the Flutter web client</li> <li>Usage Guide - Start using the system</li> </ol>"},{"location":"soliplex/#what-is-soliplex","title":"What is Soliplex?","text":"<p>Soliplex combines the power of retrieval systems with generative AI to provide accurate, contextual responses based on your document collections. The system indexes your documents and uses them to enhance AI responses with relevant, up-to-date information.</p>"},{"location":"soliplex/client/","title":"Client Setup","text":"<p>The Soliplex client is a Flutter web application that provides the user interface for interacting with the RAG system.</p>"},{"location":"soliplex/client/#prerequisites","title":"Prerequisites","text":"<ul> <li>Dart SDK</li> <li>Flutter SDK</li> <li>Google Chrome (for web development)</li> </ul>"},{"location":"soliplex/client/#installation","title":"Installation","text":"<ol> <li> <p>Clone the client repository:    <pre><code>git clone git@github.com:soliplex/soliplex.git\ncd soliplex/src/gen_ai_client\n</code></pre></p> </li> <li> <p>Install Flutter dependencies:    <pre><code>flutter pub get\n</code></pre></p> </li> </ol>"},{"location":"soliplex/client/#running-the-client","title":"Running the Client","text":"<p>Start the Flutter web application:</p> <pre><code>flutter run -d chrome\n</code></pre> <p>This will launch the application in Chrome and provide a development server with hot reload capabilities.</p>"},{"location":"soliplex/client/#development","title":"Development","text":"<p>The client uses: - Flutter 3.35+ with Material Design - Riverpod for state management - <code>go_router</code> for navigation - WebSocket connections for real-time chat</p>"},{"location":"soliplex/overview/","title":"Soliplex Overview","text":"<p>Soliplex is an AI-powered Retrieval-Augmented Generation (RAG) system designed to provide intelligent document search and question-answering capabilities.</p>"},{"location":"soliplex/overview/#architecture","title":"Architecture","text":"<p>The system consists of three main components:</p>"},{"location":"soliplex/overview/#1-backend-server-soliplex","title":"1. Backend Server (<code>soliplex/</code>)","text":"<ul> <li>Technology: FastAPI with Python 3.13</li> <li>Purpose: Handles API requests, RAG processing, and AI model integration</li> <li>Features: </li> <li>OpenAI API integration</li> <li>Document indexing and retrieval</li> <li>Authentication and authorization</li> <li>Real-time WebSocket communication</li> </ul>"},{"location":"soliplex/overview/#2-frontend-client-gen_ai_client","title":"2. Frontend Client (<code>gen_ai_client/</code>)","text":"<ul> <li>Technology: Flutter web application</li> <li>Purpose: Provides user interface for chat and document interaction</li> <li>Features:</li> <li>Material Design UI</li> <li>Real-time chat interface</li> <li>State management with Riverpod</li> <li>Responsive web design</li> </ul>"},{"location":"soliplex/overview/#3-configuration-system","title":"3. Configuration System","text":"<ul> <li>OIDC Authentication: Keycloak integration for secure access</li> <li>Room Configuration: Chat environments and settings</li> <li>Model Configuration: LLM provider and model settings</li> </ul>"},{"location":"soliplex/overview/#key-features","title":"Key Features","text":"<ul> <li>RAG Capabilities: Combines document retrieval with AI generation</li> <li>Multiple AI Models: Support for OpenAI and local models</li> <li>Secure Authentication: OIDC-based user management  </li> <li>Real-time Chat: WebSocket-powered interactive communication</li> <li>Document Management: Upload, index, and search through documents</li> </ul>"},{"location":"soliplex/rag/","title":"Retrieval-Augmented Generation (RAG) Database","text":"<p>Soliplex depends on the <code>haiku-rag</code> library to manage its retrieval-augmented generation (RAG) searches.  That library stores its extracted documents / chunks / embeddings in LanceDB databases.</p> <p>The example installation of Soliplex uses the Soliplex documentation as its RAG corpus, and expects that database to be created at <code>db/rag/rag.lancedb</code>.</p>"},{"location":"soliplex/rag/#note-on-haiku-rag-versions","title":"Note on <code>haiku-rag</code> Versions","text":"<p>The <code>soliplex</code> code itself requires only the <code>haiku-rag-slim</code> project (https://pypi.org/project/haiku.rag-slim/), which allows for queries aganst an existing LanceDB database.</p> <p>However, this dependency is not sufficient to perform the ingestion / indexing of documents.  For that purpose, either:</p> <ul> <li> <p>Install the main <code>haiku-rag</code> project   https://pypi.org/project/haiku.rag/   wihch will pull in all the dependencies required to ingest and index   documents.</p> </li> <li> <p>Pull the <code>docling-serve</code> Docker image, and run its server, with   your <code>haiku.rag.yaml</code> file configured to use it.</p> </li> </ul> <p>See the <code>haiku.rag</code> documentation to determine:</p> <ul> <li> <p>Which installation do you need?</p> </li> <li> <p>What are the tradeoffs of local vs. remote processing?</p> </li> <li> <p>How to configure <code>haiku-rag</code> to run in \"remote processing\" mode?</p> </li> </ul>"},{"location":"soliplex/rag/#adding-a-single-document","title":"Adding a single document","text":"<pre><code>export OLLAMA_BASE_URL=&lt;your Ollama server / port&gt;\nhaiku-rag --config example/haiku.rag.yaml \\\n  add-src --db db/rag/rag.lancedb docs/index.md\n...\nDocument &lt;UUID&gt; added successfully.\n</code></pre>"},{"location":"soliplex/rag/#adding-all-documents-in-a-directory","title":"Adding all documents in a directory","text":"<pre><code>export OLLAMA_BASE_URL=&lt;your Ollama server / port&gt;\nhaiku-rag --config example/haiku.rag.yaml \\\n  add-src --db db/rag/rag.lancedb docs/\n...\n17 documents added successfully.\n</code></pre>"},{"location":"soliplex/rag/#configuration-of-haiku-rag-clients-within-soliplex","title":"Configuration of <code>haiku-rag</code> clients within Soliplex","text":"<p>Please see this page for notes on configuring the various <code>haiku-rag</code> clients used in a Soliplex installation.</p>"},{"location":"soliplex/server/","title":"Server Setup","text":"<p>The Soliplex server is a FastAPI-based backend that forwards requests to OpenAI and provides RAG functionality.</p>"},{"location":"soliplex/server/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Python 3.13+</p> </li> <li> <p>Access to LLM:</p> </li> <li> <p>OpenAI - an API key is required to use OpenAI</p> </li> <li> <p>Ollama  ([https://ollama.com/] https://ollama.com/)</p> </li> <li> <p>Logfire (optional):</p> </li> </ul> <p>A token from logfire (login here)   allows for visibility into the application. (see the   docs on FastAPI integration   for more information).</p>"},{"location":"soliplex/server/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone git@github.com:soliplex/soliplex.git\ncd soliplex/\n</code></pre></p> </li> <li> <p>Set up a Python3 virtual environment:    <pre><code>python -m venv venv\nsource venv/bin/activate\npip install --upgrade setuptools pip\n</code></pre></p> </li> <li> <p>Install <code>soliplex</code> and its dependencies:    <pre><code>pip install -e .\n</code></pre></p> </li> <li> <p>Set up environment variables:</p> </li> </ol> <p>An environment file can be used to configure secrets.    For logfire, create a <code>.env</code> file with:    <pre><code>LOGFIRE_TOKEN=&lt;your_token_here&gt;\n</code></pre></p>"},{"location":"soliplex/server/#running-the-example","title":"Running the example","text":"<p>The example configuration provides an overview of how a soliplex application is assembled.  It contains four top-level installation configurations:</p> <ul> <li> <p><code>example/minimal.yaml</code> is a minimal example using Ollama:  it requires   no secrets.</p> </li> <li> <p><code>example/installation.yaml</code> is a more fleshed-out example using Ollama:   it requires secrets for the exernal Model-Control Protocol (MCP) client   toosets for the room <code>mcptest</code>.</p> </li> <li> <p><code>example/minimal-openai.yaml</code> is a minimal example using OpenAI:    it requires no secrets beyond the <code>OPENAI_API_KEY</code>.</p> </li> <li> <p><code>example/installation.yaml</code> is a more fleshed-out example using OpenAI:   in addition tothe <code>OPENAI_API_KEY</code> secret, it requires secrets for the   exernal Model-Control Protocol (MCP) client toosets for the room <code>mcptest</code>.</p> </li> </ul> <p>Each installation configuration includes a number of rooms that </p> <ol> <li>Configure resources:</li> </ol> <p>The example needs access to a model server using either openapi    or ollama as well as access to example MCP services.</p> <p>The example uses https://smithery.ai/ but others    can be configured.</p> <p>a. OIDC configuration:    TODO</p> <ol> <li> <p>Configure the LLM (Ollama / OpenAI):</p> </li> <li> <p>For the Ollama veriants, export the URL of your model server as      <code>OLLAMA_BASE_URL</code>.  This url should not contain the <code>/v1</code> suffix.      E.g. if you are running Ollama on your own machine:</p> <pre><code>export OLLAMA_BASE_URL=http://localhost:11434\n</code></pre> </li> <li> <p>The example configuration uses the <code>gpt-oss</code> model.  If using either      Ollama variant, install that model via:      <pre><code>ollama pull gpt-oss:latest\n</code></pre></p> </li> <li> <p>Check for missing secrets / environment variables:</p> </li> </ol> <p>This command will check the server for any missing variables or    invalid configuration files.    <pre><code>soliplex-cli check-config example/&lt;installation config&gt;.yaml\n</code></pre></p> <p>The secrets used in the your chosen configuration should be exported as    environment variables, e.g.:    <pre><code>SMITHERY_AI_API_KEY=&lt;your key&gt;\nSMITHERY_AI_PROFILE=&lt;your profile&gt;\n</code></pre></p> <p>Note that the alternate installation configurations, <code>example/minimal.yaml</code>    and <code>example/minimal-openai.yaml</code>, requires no additional secrets    The <code>example/minimal.yaml</code> configuration still expects    the <code>OLLAMA_BASE_URL</code> environment variable to be set (or present in    an <code>.env</code> file):    <pre><code>soliplex-cli check-config example/minimal.yaml\n</code></pre></p> <ol> <li> <p>Configure any missing secrets, e.g. by sourcing a <code>.env</code> file, or    by exporting them directly.</p> </li> <li> <p>Configure any missing environment variables, e.g. by editing    the installation YAML file, adding them to a <code>.env</code> file in the    installation path, or exporting them directly.    <pre><code>export OLLAMA_BASE_URL=http://&lt;your-ollama-host&gt;:11434\nsoliplex-cli check-config example/\n</code></pre></p> </li> </ol>"},{"location":"soliplex/server/#running-the-server","title":"Running the Server","text":"<p>Start the FastAPI server with auto-reload:</p> <pre><code>soliplex-cli serve example/installation.yaml -r both\n</code></pre> <p>The server will be available at <code>http://localhost:8000</code> by default.</p> <p>For testing purposes, the server can be run with authentication disabled. To run without authentication: <pre><code>soliplex-cli serve example/no_auth.yaml -r both\n</code></pre></p> <p>To confirm your room configuration: <pre><code>curl -X 'GET' \\\n  'http://127.0.0.1:8000/api/v1/rooms' \\\n  -H 'accept: application/json'\n</code></pre></p>"},{"location":"soliplex/server/#api-endpoints","title":"API Endpoints","text":"<p>If the <code>soliplex-cli</code> server is running, you can browse the live OpenAPI documentation.</p>"},{"location":"soliplex/usage/","title":"Using Soliplex","text":"<p>Once both the server and client are running, you can start using the Soliplex system.</p>"},{"location":"soliplex/usage/#getting-started","title":"Getting Started","text":"<ol> <li>Open your web browser and navigate to the client application</li> <li>In the dropdown menu, select the localhost option</li> <li>Start typing your questions or prompts</li> </ol>"},{"location":"soliplex/usage/#features","title":"Features","text":"<p>The Soliplex system provides: - Chat Interface: Interactive chat with AI models - Document Retrieval: RAG-powered document search and question answering - Multiple Models: Support for various AI models through OpenAI API - Real-time Responses: WebSocket-based real-time communication</p>"},{"location":"soliplex/usage/#tips","title":"Tips","text":"<ul> <li>Use clear, specific questions for better RAG results</li> <li>The system can access and search through indexed documents</li> <li>Responses are generated using retrieval-augmented generation for   more accurate and contextual answers</li> </ul>"},{"location":"soliplex/config/agents/","title":"Agent Configurations","text":"<p>The agent configuration mapping is used to configure the Pydantic AI agent used to make the calls to the LLM.</p> <pre><code>agent:\n    model_name: \"gpt-oss:20b\"\n    system_prompt: |\n      You are an expert AI assistant specializing in information retrieval.\n\n      Your answers should be clear, concise, and ready for production use.\n\n      Always provide code or examples in Markdown blocks.\n</code></pre>"},{"location":"soliplex/config/agents/#required-agent-elements","title":"Required Agent Elements","text":"<ul> <li><code>model_name</code>: a string, should be the identifier of an LLM model for the   agent.</li> </ul> <p>NOTE: this value was previously optional, defaulting to the value             of the since-deprecated <code>DEFAULT_AGENT_MODEL</code> key in the             installation environment.</p> <ul> <li><code>system_prompt</code> is the \"instructions\" for the LLM serving the room.   If it starts with a <code>./</code>, it will be treated as a filename in the   same directory, whose contents will be read in its place.</li> </ul> <p>A minimal configuration, without an external prompt file:</p> <pre><code>agent:\n    model_name: \"gpt-oss:latest\"\n    system_prompt: |\n        You are a knowledgeable assistant that helps users find information from a document knowledge base.\n\n        Your process:\n        1. When a user asks a question, use the search_documents tool to find relevant information\n        ...\n</code></pre> <p>A minimal configuration, but with the prompt stored in external file:</p> <pre><code>agent:\n    model_name: \"gpt-oss:latest\"\n    system_prompt: \"./prompt.txt\"\n</code></pre>"},{"location":"soliplex/config/agents/#optional-agent-elements","title":"Optional Agent Elements","text":"<ul> <li> <p><code>provider_type</code>: a string, must be one of <code>\"ollama\"</code> (the default) or   <code>\"openai\"</code>.</p> </li> <li> <p><code>provider_base_url</code>: a string, defaulting to the value configured in   the installation environment as <code>OLLAMA_BASE_URL</code> is the base API URL   for the agent's LLM provider. Must be specified without the <code>/v1</code>     suffix. E.g.:</p> </li> </ul> <pre><code>provider_base_url: \"https://provider.example.com/api\"\n</code></pre> <ul> <li><code>provider_key</code> (a string, default's to None) should be the   name of the secret holding the LLM provider's API key   (not the value of the API key), prefixed with <code>secret:</code></li> </ul> <pre><code>provider_key: \"secret:FOO_PROVIDER_API_KEY\"\n</code></pre> <p><code>provider_model_settings</code>: a mapping, whose keys are determined by   the <code>provider_type</code> above (see below).</p>"},{"location":"soliplex/config/agents/#example-ollama-configuration","title":"Example Ollama Configuration","text":"<p>NOTE: the values below show types, but should not be used without           testing.</p> <pre><code>model_name: \"gpt-oss:latest\"\nprovider_type: \"ollama\"\nprovider_model_settings:\n  temperature: 0.90\n  top_k: 100\n  top_p: 0.75\n  min_p: 0.25\n  stop: \"STOP\"\n  num_ctx: 2048\n  num_predict: 2000\n</code></pre>"},{"location":"soliplex/config/agents/#example-openai-configuration","title":"Example OpenAI Configuration","text":"<p>NOTE: the values below show types, but should not be used without           testing.</p> <pre><code>model_name: \"mistral:7b\"\nprovider_type: \"openai\"\nprovider_model_settings:\n  temperature: 0.90\n  top_p: 0.70\n  frequency_penalty: 0.25\n  presence_penalty: 0.50\n  parallel_tool_calls: false\n  truncation: \"disabled\"\n  max_tokens: 2048\n  verbosity: \"high\"\n</code></pre>"},{"location":"soliplex/config/completions/","title":"Completion Configuration Filesystem Layout","text":"<p>A completion is configured via a directory, whose name is the completion ID.</p> <p>NOTE: directories whose names start with '.' are ignored.</p> <p>Within that directory should be one or two files:</p> <ul> <li> <p><code>completion_config.yaml</code> holds metadata about the completion (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the room.</p> </li> </ul> <p>Example layout without external prompt: <pre><code>simple/\n    room_config.yaml\n</code></pre></p> <p>Example layout with external prompt: <pre><code>chat/\n    prompt.txt\n    room_config.yaml\n</code></pre></p>"},{"location":"soliplex/config/completions/#completions-endpoint-configuration-file-schema","title":"Completions Endpoint Configuration File Schema","text":""},{"location":"soliplex/config/completions/#required-endpoint-elements","title":"Required endpoint elements","text":"<p>The <code>completion_config.yaml</code>  file should be a mapping, with at least the following required elements:</p> <ul> <li> <p><code>id</code> (a string) should match the name of the endpoint's directory.</p> </li> <li> <p><code>agent</code> (a mapping)</p> </li> </ul> <p>A minimal completion endpoint configuration must include the above elements, e.g.:</p> <pre><code>id: \"chat\"\nagent:\n  system_prompt: |\n      You are an..... #\n</code></pre> <p>Please see this page which documents the <code>agent</code> element schema.</p>"},{"location":"soliplex/config/environment/","title":"Installation Environment","text":"<p>The <code>environment</code> section configures non-secret values used by various portions of the Soliplex application.  Application code should use the <code>Installation.get_environment</code> API to fetch configured values, rather than using <code>os.environ</code>.</p>"},{"location":"soliplex/config/environment/#environment-entries","title":"Environment Entries","text":"<p>The section consists of a list of mappings, each with keys <code>name</code> and <code>value</code>.</p> <pre><code>environment:\n  - name: \"ENV_VAR_NAME\"\n    value: \"ENV_VAR_VALUE\"\n</code></pre>"},{"location":"soliplex/config/environment/#unconfigured-environment-entries","title":"Unconfigured Environment Entries","text":"<p>If the <code>value</code> key is missing, the Soliplex application will attempt to resolve it using <code>os.environ</code> during startup.</p>"},{"location":"soliplex/config/environment/#bare-string-environment-entries","title":"Bare-String Environment Entries","text":"<p>As an alternative, an item in the list can be a bare string:  such an entry corresponds exactly to a mapping with <code>name: \"&lt;bare string</code> and no <code>value</code>.</p> <p>This configuration: <pre><code>environment:\n  - \"ENV_VAR_NAME\"\n</code></pre> is exactly equivalent to this one: <pre><code>environment:\n  - name: \"ENV_VAR_NAME\"\n</code></pre></p>"},{"location":"soliplex/config/environment/#checking-configured-environment-values","title":"Checking Configured Environment Values","text":"<p>The <code>soliplex-cli</code> application has a sub-command, <code>list-environment</code>. It loads the configuration, attempts to resolve any values not found, and reports them:</p> <pre><code>$ soliplex-cli list-environment example/installation.yaml \n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Configured environment variables \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n- OLLAMA_BASE_URL          : MISSING\n- INSTALLATION_PATH        : file:.\n- RAG_LANCE_DB_PATH        : file:../db/rag\n- LOGFIRE_ENVIRONMENT      : container\n- LOGFIRE_SERVICE_NAME     : soliplex\n</code></pre>"},{"location":"soliplex/config/filesystem_layout/","title":"Installation Filesystem Layout","text":"<p>An \"installation\" is a set of filesystem-based configuration files, organized as a directory tree.</p> <p>At the root of an installation directory is a file, <code>installation.yaml</code>, which is used to configure environment variables and secrets used by the installation.  There may be alternative configurations available, e.g. to configure how the installation runs inside a container.</p> <p>See this page for documentation on the schema of one of these configurations.</p> <p>An installation directory typically contains subdirectories, each holding configurations for a given type of entity.</p> <p>Example layout:</p> <pre><code>/\n  installation.yaml\n  completions/\n    chat-bot/\n      completion_config.yaml\n      prompt.txt\n    ...\n  oidc/\n    cacert.pem\n    config.yaml\n  quizzes/\n    quiz_name.json\n    ...\n  rooms/\n    quiztest/\n      prompt.txt\n      room_config.yaml\n    ...\n</code></pre>"},{"location":"soliplex/config/filesystem_layout/#room-configuration","title":"Room Configuration","text":"<p>Within a \"rooms\" directory, each room is represented by a subdirectory, whose name is the room ID.</p> <p>Within that subdirectory should be one or two files:</p> <ul> <li> <p><code>room_config.yaml</code> holds metadata about the room (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the room.</p> </li> <li> <p>A logo image file (optional)</p> </li> </ul> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"soliplex/config/filesystem_layout/#completions-endpoint-configuration","title":"Completions Endpoint Configuration","text":"<p>Within a \"completions\" directory, each endpoint is represented by a subdirectory, whose name is the endpoint ID.</p> <p>Within that subdirectory should be one or two files:</p> <ul> <li> <p><code>completion_config.yaml</code> holds metadata about the endpoint (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the endpoint.</p> </li> </ul> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"soliplex/config/filesystem_layout/#quiz-configuration","title":"Quiz Configuration","text":"<p>This directory contains question sets as individual JSON files, derived from the evaluation dataset entries.</p> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"soliplex/config/filesystem_layout/#oidc-provider-configuration","title":"OIDC Provider Configuration","text":"<p>This directory contains configuration files defining the OIDC identity providers configured for use in this installation.</p> <p>See this page for documentation on the contents and schema of these files.</p>"},{"location":"soliplex/config/installation/","title":"Installation Configuration","text":""},{"location":"soliplex/config/installation/#installation-id","title":"Installation ID","text":"<p>A required field, to allow quick disambiguation between alternative configurations.</p> <pre><code>id: \"soliplex-example\"\n</code></pre>"},{"location":"soliplex/config/installation/#installation-metaconfiguration","title":"Installation Metaconfiguration","text":"<p>The <code>meta</code> section allows you to register custom \"kinds\" of entities (tool configurations, MCP client toolset configurations, etc.), such that you can use them within your own configurations (e.g., to register a configuration class for use with a custom tool in a given room).</p> <pre><code>meta:\n</code></pre> <p>See this page for documentation on the meta-configuration schema.</p>"},{"location":"soliplex/config/installation/#secrets","title":"Secrets","text":"<pre><code>secrets:\n</code></pre> <p>Secrets are values used to authenticate access to different resources or APIs.</p> <p>The may be kept in an external store, such as:</p> <ul> <li>ASW secret store</li> <li>GitHub secrets</li> <li>Docker Compose secrets files</li> <li>The user keyring</li> </ul> <p>See this page for documentation on configuring installation secrets.</p>"},{"location":"soliplex/config/installation/#environment","title":"Environment","text":"<p>The <code>environment</code> section configures non-secret values used by various portions of the Soliplex application.  Application code should use the <code>Installation.get_environment</code> API to fetch configured values, rather than using <code>os.environ</code>.</p> <pre><code>environment:\n</code></pre> <p>See this page for documentation on configuring the installation environment.</p>"},{"location":"soliplex/config/installation/#haikurag-configuration-file","title":"<code>haiku.rag</code> Configuration File","text":"<p>The <code>haiku_rag_config_file</code> entry points to a YAML file containing configuration values for the <code>haiku.rag</code> client</p> <p>If not configured explicitly, the installation configuration expects to find this file in the same directory, with the default name <code>haiku.rag.yaml</code>.</p> <p>Pleas see the <code>haiku.rag</code> configuration docs for details on how to configure the <code>haiku.rag</code> client used by Soliplex.</p>"},{"location":"soliplex/config/installation/#agent-configurations","title":"Agent Configurations","text":"<p>An installation can declare agent configurations (which are normally bound to rooms / completions) at the top-level, such that they can be looked up by ID from Python code using <code>the_installation.get_agent_by_id</code>.</p> <p><pre><code>agent_configs:\n\n  - id: \"ollama_gpt_oss\"\n    model_name: \"gpt-oss:20b\"\n    system_prompt: |\n      You are an expert AI assistant specializing in information retrieval.\n      ...\n</code></pre> Please see this page for details on configuring agents. In addition to the values described there, note that the <code>id</code> element is required here.</p>"},{"location":"soliplex/config/installation/#thread-persistence-dburi","title":"Thread Persistence DBURI","text":"<p>An installation can define two DBURIs for the database used to store AG-UI threads, runs, events, etc.</p>"},{"location":"soliplex/config/installation/#synchronous-dburi","title":"Synchronous DBURI","text":"<p>One DBURI is for sync usage, e.g.  within console scripts.  Examples:</p> <ul> <li><code>sqlite://</code></li> <li><code>postgresql+psycopg2://user:&lt;password&gt;@dbhost/dbname</code></li> </ul>"},{"location":"soliplex/config/installation/#asynchronous-dburi","title":"Asynchronous DBURI","text":"<p>The other DBURI is for async usage, e.g. within the Soliplex server process.  Examples:</p> <ul> <li><code>sqlite+aiosqlite://</code></li> <li><code>postgresql+asyncpg://user:&lt;password&gt;@dbhost/dbname</code></li> </ul> <p>This DBURI must be compatible with SQLAlchemy's asyncio extension. Dialects known to work include:</p> <ul> <li><code>aiosqlite</code></li> <li><code>asyncpg</code></li> </ul>"},{"location":"soliplex/config/installation/#default-configuration","title":"Default configuration","text":"<p>By default, Soliplex configures thread persistence using in-memory DBURIS:</p> <ul> <li>For sync use, <code>sqlite</code> (DBURI <code>sqlite://</code>)</li> <li>For async use, <code>aiosqlite</code> (DBURI <code>sqlite+aiosqlite://</code>)</li> </ul> <p>The default configuration is equivalent to this explicit YAML:</p> <pre><code>thread_persistence_dburi:\n  sync: \"sqlite://\"\n  async: \"sqlite+aiosqlite://\"\n</code></pre>"},{"location":"soliplex/config/installation/#database-passwords-as-secrets","title":"Database passwords as secrets","text":"<p>For DBURIs requiring authentication, we would rather not expose the password in plain-text configuration.  In this case, we can define a Soliplex secret (read here), and use that secret in the DBURI.</p> <pre><code>secrets:\n    - secret_name: MY_DBURI_SECRET\n      # Configure sources here\n...\n\nthread_persistence_dburi:\n  sync: \"postgresql+psycopg2://user:secret:MY_DBURI_SECRET@dbhost/dbname\"\n  async: \"postgresql+asyncpg://user:secret:MY_DBURI_SECRET@dbhost/dbname\"\n</code></pre>"},{"location":"soliplex/config/installation/#oidc-auth-provider-paths","title":"OIDC Auth Provider Paths","text":"<p>The <code>oidc_paths</code> element specifies one or more filesystem paths to be searched for OIDC provider configs.</p> <p>Please see this page for details on how to configure these providers.</p> <pre><code>oidc_paths:\n  - \"/path/to/oidc/config/dir\"\n</code></pre> <p>Non-absolute paths will be evaluated relative to the installation directory.</p> <p>By default, Soliplex loads provider configurations found under the path './oicd', just as though we had configured:</p> <pre><code>oidc_paths:\n  - \"./oidc\"\n</code></pre> <p>To disable authentication, list a single, \"null\" path, e.g.: <pre><code>oidc_paths:\n  -\n</code></pre> Or else run 'soliplex-cli serve --no-auth-mode'</p>"},{"location":"soliplex/config/installation/#room-configuration-paths","title":"Room Configuration Paths","text":"<p>The <code>room_paths</code> element specify one or more filesystem paths to search for room configs.</p> <p>Please see this page for details on how to configure these providers.</p> <p>Each path can be either:</p> <ul> <li> <p>a directory containing its own <code>room_config.yaml</code> file:  this directory   will be mapped as a single room.</p> </li> <li> <p>a directory whose immediate subdirectories will be treated as rooms   IFF they contain a <code>room_config.yaml</code> file.</p> </li> </ul> <p>Non-absolute paths are evaluated relative to the installation directory.</p> <p>The order of <code>room_paths</code> in this list controls which room configuration is used for any conflict on room ID:  rooms found earlier in the list \"win\" over later ones with the same ID.</p> <p>By default, Soliplex loads room configurations found under the path './rooms', just as though we had configured:</p> <p><pre><code>room_paths:\n  - \"./rooms\"\n</code></pre> To disable all rooms, list a single, \"null\" path, e.g.:</p> <pre><code>room_paths:\n   -\n</code></pre>"},{"location":"soliplex/config/installation/#completion-configuration-paths","title":"Completion Configuration Paths","text":"<p>The <code>completion_paths</code> entry specifies one or more filesystem paths to search for completion configs.</p> <p>Please see this page for details on how to configure these providers.</p> <p>Each path can be either:</p> <ul> <li> <p>a directory containing its own <code>completion_config.yaml</code> file:  this   directory will be mapped as a single completion.</p> </li> <li> <p>a directory whose immediate subdirectories will be treated as rooms   IFF they contain a <code>room_config.yaml</code> file.</p> </li> </ul> <p>Non-absolute paths will be evaluated relative to the installation directory.</p> <p>The order of entries in the <code>completion_paths</code> list controls which completion configuration is used for any conflict on completion ID:  completions found earlier in the list \"win\" over later ones with the same ID.</p> <p>By default, Soliplex loads completion configurations found under the path './completions', just as though we had configured:</p> <pre><code>completion_paths:\n  - \"./completions\"\n</code></pre> <p>To disable all completions, list a single, \"null\" path, e.g.: <pre><code>completion_paths:\n  -\n</code></pre></p>"},{"location":"soliplex/config/meta/","title":"Installation Metaconfiguration","text":"<p>The <code>meta</code> section of an installation configuration enables registration of custom \"kinds\" of entities (tool configurations, MCP client toolset configurations, etc.), so that they can be used within the rest of the installation.</p> <p>E.g., registering a new tool configuration class in the <code>meta.tool_configs</code> section allows use of that class when configuring a custom tool in a given room.</p>"},{"location":"soliplex/config/meta/#registering-ag-ui-feature-classes","title":"Registering AG-UI Feature Classes","text":"<p>The <code>meta.agui_features</code> section registers AG-UI feature types so that they can be referenced by their <code>name</code>.  Each feature is a contract between the client application and the server, defining the schema for a named field in the AG-UI state, and which parties are expected to write to that field.</p> <p>The section contains a list of mappings, each of which include:</p> <ul> <li> <p><code>name</code>, a string identifying the field in the AG-UI state.</p> </li> <li> <p><code>model_klass</code>, a Python \"dotted name\" which can be used to import the    model class which defines the field's schema.</p> </li> <li> <p><code>source</code> (optional), a  key indicating which party is allowed to set   the feature's field in the AG-UI state. Allowed values are \"client\",   \"server\", and \"either\";  the default is \"either\".</p> </li> </ul> <p>By default, Soliplex registers its own AG-UI feature classes, just as though we configured explicitly:</p> <pre><code>meta:\n  agui_features:\n\n  - name: \"filter_documents\"\n    model_klass: \"soliplex.agui.features.FilterDocuments\"\n    source: \"client\"\n\n  - name: \"ask_history\"\n    model_klass: \"soliplex.agui.features.AskedAndAnswered\"\n    source: \"server\"\n</code></pre>"},{"location":"soliplex/config/meta/#registering-tool-configuration-classes","title":"Registering Tool Configuration Classes","text":"<p>The <code>meta.tool_configs</code> section enumerates tool configuration types so that they can be referenced by their <code>tool_name</code>.</p> <p>The section contains a list of Python \"dotted names\", i.e. strings which can be used to import the configuration class.</p> <p>By default, Soliplex registers its own tool config classes, just as though we configured explicitly:</p> <pre><code>meta:\n  tool_configs:\n  - \"soliplex.config.SearchDocumentsToolConfig\"\n</code></pre>"},{"location":"soliplex/config/meta/#registering-mcp-client-toolset-configuration-classes","title":"Registering MCP Client Toolset Configuration Classes","text":"<p>The <code>meta.mcp_toolset_configs</code> section enumerates MCP client toolset configuration types so that they can be referenced by their 'kind'.</p> <p>The section contains a list of Python \"dotted names\", i.e. strings which can be used to import the configuration class.</p> <p>By default, Soliplex registers its own tool config classes, just as though we configured explicitly:</p> <pre><code>meta:\n  mcp_toolset_configs:\n  - \"soliplex.config.Stdio_MCP_ClientToolsetConfig\"\n  - \"soliplex.config.HTTP_MCP_ClientToolsetConfig\"\n</code></pre>"},{"location":"soliplex/config/meta/#registering-mcp-server-tool-wrapper-types","title":"Registering MCP Server Tool Wrapper Types","text":"<p>The <code>meta.mcp_server_tool_wrappers</code> section maps tool configuration classes to the equivalent wrapper class, used then offering the tool to external MCP clients.</p> <p>The section contains a list of mappings with keys <code>config_klass</code> and <code>wrapper_klass</code>.  Values for both keys Python \"dotted names\", i.e. strings which can be used to import the corresponding class.</p> <p>By default, Soliplex configures its 'soliplex.config.WithQueryMCPWrapper' as the wrapper for 'soliplex.config.SearchDocumentsToolConfig', just as if we configured here:</p> <pre><code>meta:\n  mcp_server_tool_wrappers:\n  - config_klass: \"soliplex.config.SearchDocumentsToolConfig\"\n    wrapper_klass: \"soliplex.config.WithQueryMCPWrapper\"\n</code></pre>"},{"location":"soliplex/config/meta/#registering-agent-configuration-classes","title":"Registering Agent Configuration Classes","text":"<p>The <code>meta.agent_configs</code> section enumerates agent configuration types so that they can be referenced by their <code>kind</code>.</p> <p>The section contains a list of Python \"dotted names\", i.e. strings which can be used to import the configuration class.</p> <p>By default, Soliplex registers its own agent config class, just as though we configured explicitly:</p> <pre><code>meta:\n  tool_configs:\n  - \"soliplex.config.AgentConfig\"\n</code></pre>"},{"location":"soliplex/config/meta/#registering-secret-source-configurations","title":"Registering Secret Source Configurations","text":"<p>Each installation secret can be configured with multiple \"sources\" of different kinds. Each source configuration kind corresponds to a Python function which is used to retrieve the secret value.</p> <p>The <code>meta.secret_sources</code> section allows configuring new secret source configurations and their corresponding functions.</p> <p>By default, these classes are configured to use the corresponding functions in 'soliplex.secrets', just as if we configured here:</p> <pre><code>meta:\n  secret_sources:\n  - config_klass: \"soliplex.config.EnvVarSecretSource\"\n    registered_func: \"soliplex.secrets.get_env_var_secret\"\n  - config_klass: \"soliplex.config.FilePathSecretSource\"\n    registered_func: \"soliplex.secrets.get_file_path_secret\"\n  - config_klass: \"soliplex.config.SubprocessSecretSource\"\n    registered_func: \"soliplex.secrets.get_subprocess_secret\"\n  - config_klass: \"soliplex.config.RandomCharsSecretSource\"\n    registered_func: \"soliplex.secrets.get_random_chars_secret\"\n</code></pre>"},{"location":"soliplex/config/oidc_providers/","title":"OIDC Provider Configuration","text":"<p>The <code>config.yaml</code> file in an OIDC provider configuration directory specifies one or more authentication systems, sharing a common CA certificate store:</p> <pre><code>oidc_client_pem_path: \"./cacert.pem\"\n\nauth_systems:\n\n  - id: \"myprovder\"\n    title: \"Authenticate with MyProovider\"\n    server_url: \"https://oidc.excample.com/\"\n    client_id: \"myprovider-token-service\"\n    client_secret: \"\"  # \"secret:{MYPROVIDER_CLIENT_SECRET}\"\n    scope: \"openid email profile\"\n    token_validation_pem: |\n        -----BEGIN PUBLIC KEY-----\n        MII..AQAB\n        -----END PUBLIC KEY-----\n</code></pre>"},{"location":"soliplex/config/oidc_providers/#required-configuration-elements","title":"Required Configuration Elements","text":"<ul> <li><code>authsystems</code> is a list of one or more OIDC provider configurations   (see below).</li> </ul>"},{"location":"soliplex/config/oidc_providers/#optional-configuration-elements","title":"Optional Configuration Elements","text":"<ul> <li><code>oidc_client_pem_path</code> points to a file on the filesystem containing   the shared CA certificate store.  If not configured, the Soliplex   application will use systemwide default CA certificates.</li> </ul>"},{"location":"soliplex/config/oidc_providers/#required-oidc-provider-elements","title":"Required OIDC Provider Elements","text":"<ul> <li> <p><code>id</code>: a string, should be unique across all configured providers</p> </li> <li> <p><code>title</code>: a string, might be displayed by a client</p> </li> <li> <p><code>server_url</code>: URL for initiating the token auth flow.</p> </li> <li> <p><code>token_validation_pem</code>: a string, the public key used to verify    the providers tokens.</p> </li> <li> <p><code>client_id</code>: a string identifying the client to the provider.</p> </li> </ul>"},{"location":"soliplex/config/oidc_providers/#optional-oidc-provider-elements","title":"Optional OIDC Provider Elements","text":"<ul> <li> <p><code>client_secret</code>: a string;  if not empty, should be in the form   <code>\"secret:MYPROVIDER_CLIENT_SECRET\"</code>, where the name following the   <code>secret:</code> prefix is the name of a configured installation secret   (see this page for details).</p> </li> <li> <p><code>scope</code>: string, an OAuth scope specifier.</p> </li> </ul>"},{"location":"soliplex/config/quizzes/","title":"Quiz Datasets","text":"<p>Quizzes use the evaluation dataset entries (see the schema).</p>"},{"location":"soliplex/config/quizzes/#room-configuration","title":"Room Configuration","text":"<ul> <li>Room configurations get a new key, <code>quizzes</code>, with a value which   is a mapping defining quizzes which can be run in the room   (see <code>rooms/README.md</code>).</li> </ul>"},{"location":"soliplex/config/quizzes/#api","title":"API","text":""},{"location":"soliplex/config/quizzes/#get-apiv1rooms","title":"<code>GET /api/v1/rooms</code>","text":"<p>Room config entries in the response include the value of <code>quizzes</code> (a list of mappings).</p>"},{"location":"soliplex/config/quizzes/#get-apiv1roomsroom_id","title":"<code>GET /api/v1/rooms/{room_id}</code>","text":"<p>Response includes  the value of <code>quizzes</code> (a list of mappings).</p>"},{"location":"soliplex/config/quizzes/#get-apiv1roomsroom_idquizquiz_id","title":"<code>GET /api/v1/rooms/{room_id}/quiz/{quiz_id}</code>","text":"<p>Fetch the quiz.  Returns a mapping for the quiz with a list of questions:</p> <pre><code>{\n    \"id\": \"&lt;quiz_id&gt;\",\n    \"questions\": [\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"What color is the sky? (QA)\",\n            \"metadata\": {\n                \"type\": \"qa\"\n            }\n        },\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"The color of the sky is _____\",\n            \"metadata\": {\n                \"type\": \"fill-blank\"\n            }\n        },\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"Is the sky blue?\",\n            \"metadata\": {\n                \"type\": \"multiple-choice\",\n                \"options\": {\n                    \"true\",\n                    \"false\"\n                }\n            }\n        },\n        {\n            \"uuid\": \"&lt;question_uuid&gt;\",\n            \"inputs\": \"What color is the sky? (MC)\",\n            \"metadata\": {\n                \"type\": \"multiple-choice\",\n                \"options\": {\n                    \"red\",\n                    \"green\",\n                    \"blue\"\n                }\n            }\n        },\n    ...\n    ]\n}\n</code></pre> <ul> <li> <p><code>question-type</code> is one of <code>\"qa\"</code>, <code>\"fill-blank\"</code>, or <code>\"multiple-choice\"</code></p> </li> <li> <p>Questions of type <code>\"multiple-choice\"</code> contain an additional entry,   <code>\"options\"</code> in their metadata, whose value is a list of strings.</p> </li> </ul>"},{"location":"soliplex/config/quizzes/#post-apiv1roomsroom_idquizquiz_idquestion_uuid","title":"<code>POST /api/v1/rooms/{room_id}/quiz/{quiz_id}/{question_uuid}</code>","text":"<p>Check an answer.  Client should send the answer entered / selected by the user as a <code>text/plain</code> body.  For a correct answer, returns:</p> <pre><code>{\n    \"correct\": \"true\"\n}\n</code></pre> <p>For an incorrect answer, returns: <pre><code>{\n    \"correct\": \"false\"\n    \"expected_output\": \"&lt;expected_output&gt;\"\n}\n</code></pre></p> <p>(Later, this response might include more information, such as a citation).</p>"},{"location":"soliplex/config/rag/","title":"<code>haiku-rag</code> Client Configuration","text":"<p>In order to use its RAG database(s) (see this page for how to create them), Soliplex installation uses <code>haiku.rag</code> as a library, creating instances of <code>haiku.rag.client.HaikuRag</code> client class as needed.</p> <p>NOTE:  the <code>embeddings</code> configuration used to create the RAG database            must match the client configuration used to read the database.</p> <p>The configuration used to create these client instances can be defined in two places:</p>"},{"location":"soliplex/config/rag/#global-configuration","title":"Global Configuration","text":"<p>The default <code>haiku-rag</code> configuration for an installation lives in a seprate file, <code>haiku.rag.yaml</code>, which is located by default in the installation directory (next to the main installation config file).</p> <p>See the <code>haiku-rag</code> docs for the format and semantics of this file.</p>"},{"location":"soliplex/config/rag/#room-level-and-completion-level-configuration","title":"Room-level and Completion-level Configuration","text":"<p>Rooms and completions which use the <code>soliplex.tools.search_documents</code> tool can also define a <code>haiku.rag.yaml</code> file, next to their own config files.  Soliplex overlays any configuration defined in such files on top of the global configuration when using the tool.</p> <p>E.g., to override only the reranking used by <code>haiku-rag</code> in a given room:</p> <pre><code>reranking:\n  model:\n    name: \"gpt-oss:20b\"\n    provider: \"ollama\"\n</code></pre>"},{"location":"soliplex/config/rooms/","title":"Room Configuration Filesystem Layout","text":"<p>A room is configured via a directory, whose name is the room ID.</p> <p>NOTE: directories whose names start with '.' are ignored.</p> <p>Within that directory should be one or two files:</p> <ul> <li> <p><code>room_config.yaml</code> holds metadata about the room (see below)</p> </li> <li> <p><code>prompt.txt</code> (if present) holds the system prompt for conversations   which are initiated from the room.</p> </li> </ul> <p>Example layout without external prompt file: <pre><code>simple/\n    room_config.yaml\n</code></pre></p> <pre><code>chat/\n    prompt.txt\n    room_config.yaml\n</code></pre>"},{"location":"soliplex/config/rooms/#room-configuration-file-schema","title":"Room Configuration File Schema","text":""},{"location":"soliplex/config/rooms/#required-room-elements","title":"Required room elements","text":"<p>The <code>room_config.yaml</code>  file should be a mapping, with at least the following required elements:</p> <ul> <li> <p><code>id</code> (a string) should match the name of the room's directory.</p> </li> <li> <p><code>name</code> (a string) is the \"title\" of the room, as would be shown in a list.</p> </li> <li> <p><code>description</code> (a string) tells the purpose of the room:  it might show up   as the \"lede\" graph (below the <code>name</code>) in a list of rooms.</p> </li> <li> <p><code>agent</code> (a mapping, see next section)</p> </li> </ul> <p>A minimal room configuration must include the above elements, e.g.:</p> <pre><code>id: \"chat\"\nname: \"Chatting Darkly\"\ndescription: \"Scanning for conversations\"\nagent:\n  system_prompt: |\n      You are an..... #\n</code></pre>"},{"location":"soliplex/config/rooms/#optional-room-elements-ui-related","title":"Optional room elements (UI-related):","text":"<ul> <li><code>welcome_message</code> (a string), for the UI to display when the user   enters a room.  E.g.:</li> </ul> <pre><code>welcome_message: &gt;\n    Welcome to the room.  We hope you find it useful\n\n    Please review the suggestions below for ideas on the kinds\n    of questions for which this room is intended.\n</code></pre> <ul> <li><code>suggestions</code> (a list of strings) contains possible \"starter questions\"   for the room, which the UI might display as shortcuts when the user   enters the room.  E.g.:</li> </ul> <pre><code>suggestions:\n  - \"How high is up?\"\n  - \"Why is the sky blue?\"\n</code></pre> <ul> <li><code>enable_attachments</code> (a boolean, default <code>False</code>), which, if true,    tells the UI to allow the user to attach files to a prompt. E.g.:</li> </ul> <pre><code>enable_attachments: true\n</code></pre>"},{"location":"soliplex/config/rooms/#agent-configuration","title":"Agent configuration","text":"<p>The <code>agent</code> mapping is used to configure the Pydantic AI agent used to make the room's calls to the LLM.</p> <pre><code>agent:\n    model_name: \"gpt-oss:latest\"\n    system_prompt: \"./prompt.txt\"\n</code></pre> <p>Please see this page for a full description of the options for configuring an agent.</p>"},{"location":"soliplex/config/rooms/#tool-configurations","title":"Tool Configurations","text":"<ul> <li><code>tools</code> should be a list of mappings, with at least the key   <code>tool_name</code>, whose value is a dotted name identifying a Python function    (or callable) which can serve as a \"tool\" for the LLM.  E.g.:</li> </ul> <p><pre><code>tools:\n    - tool_name: \"soliplex.tools.get_current_datetime\"\n    - tool_name: \"soliplex.tools.get_current_user\"\n</code></pre>   Each tool mapping can contain additional elements, which are used to    configure the tool's behavior.</p>"},{"location":"soliplex/config/rooms/#rag-search-related","title":"RAG / search-related","text":"<p>The <code>soliplex.tools.search_documents</code> tool takes a number of configuration values.  Exactly one of the following two elements is required:</p> <ul> <li><code>rag_lancedb_stem</code> is a string:  it should be the \"base name\" (without   path or <code>.lancedb</code> suffix) of the LanceDB file containing the RAG document   data for the tool. This file must exist in the \"standard\" location   (typically under the <code>db/rag/</code> directory;  see below).</li> </ul> <pre><code>rag_lancedb_stem: \"&lt;room_id&gt;\"\n</code></pre> <ul> <li><code>rag_lancedb_override_path</code> is a string:  it should be a fully-qualified   pathname, including the suffix, of the LanceDB directory containing the RAG   document data for the tool. </li> </ul> <pre><code>rag_lancedb_override_path: \"/&lt;path-to-rag-databases&gt;/&lt;room_id&gt;.&lt;extension&gt;\"\n</code></pre> <p>Other, optional elements for the <code>search_documents</code> tool:</p> <ul> <li><code>search_documents_limit</code> is a positive integer (default <code>5</code>), used to   control the number of results returned by the <code>search_documents</code> tool. E.g.:</li> </ul> <pre><code>search_documents_limit: 8\n</code></pre> <p>Minimal <code>search_documents</code> configuration, with RAG database file found in the standard location:</p> <pre><code>agent:\n  tools:\n    - tool_name: \"soliplex.tools.search_documents\"\n      rag_lancedb_stem: \"chat\"\n</code></pre> <p>Minimal <code>search_documents</code> configuration, with RAG database file found in an overridden location:</p> <pre><code>agent:\n  tools:\n    - tool_name: \"soliplex.tools.search_documents\"\n      rag_lancedb_override_path: \"/path/to/rag/db/filename.lancedb\"\n</code></pre> <p>Maximal <code>search_documents</code> configuration</p> <pre><code>agent:\n  tools:\n    - tool_name: \"soliplex.tools.search_documents\"\n      rag_lancedb_stem: \"chat\"\n      search_documents_limit: 8\n</code></pre>"},{"location":"soliplex/config/rooms/#quiz-related-elements","title":"Quiz-related elements","text":"<ul> <li><code>quizzes</code> is a list of mappings (default <code>()</code>):  each mapping defines a   quiz which can be run in the room (see this page for   details of the quiz dataset).</li> </ul> <pre><code>quizzes:\n  - id: \"test_quiz\"\n    title: \"Test Quiz\"\n    question_file: \"/path/to/questions.json\"\n    randomize: false\n    max_questions: 100\n</code></pre>"},{"location":"soliplex/config/rooms/#location-of-rag-database-files","title":"Location of RAG database files","text":"<p>Rooms using the <code>search_documents</code> tool need to be able to find the LanceDB database containing the chunks and embeddings extracted by Haiku-RAG.  At present, there should be a single database per room, named by convention <code>&lt;stem&gt;.lancedb</code>, and stored in the <code>db/rag/</code> subdirectory of the project root.</p>"},{"location":"soliplex/config/secrets/","title":"Configuring Installation Secrets","text":"<p>The <code>secrets</code> section of an installation configuration contains a list of secret names, and optionally their configured sources.</p> <p>The default configuration knows of four types of sources:</p> <ul> <li>Environment variables</li> <li>File paths</li> <li>Subprocess commands</li> <li>Randomly-generated strings</li> </ul>"},{"location":"soliplex/config/secrets/#secret-source-environment-variable","title":"Secret Source: Environment Variable","text":"<p>A secret source which uses an environment variable can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"env_var\"\n       env_var_name: \"MY_SECRET_ENV_VAR_NAME\"\n</code></pre>"},{"location":"soliplex/config/secrets/#secret-source-filesystem-path","title":"Secret Source: Filesystem Path","text":"<p>A secret source which uses a file system path can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"file_path\"\n       file_path: \"/run/secret/my_secret\"\n</code></pre>"},{"location":"soliplex/config/secrets/#secret-source-subprocess-command","title":"Secret Source: Subprocess Command","text":"<p>A secret source which uses a subprocess command can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"subprocess\"\n       command: \"/usr/bin/fetch_secret\"\n       args:\n       - \"--secret-name=MY_SECRET\"\n</code></pre>"},{"location":"soliplex/config/secrets/#secret-source-randomly-generated-string","title":"Secret Source: Randomly-Generated String","text":"<p>A secret source which uses generates a random string at process startup can be configured so:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"random_chars\"\n       n_chars: 32\n</code></pre>"},{"location":"soliplex/config/secrets/#layering-secret-sources","title":"Layering Secret Sources","text":"<p>Sources are resolved in the order they are listed, with the first one returning a value winning.  This example layers an environment variable source with a random string source:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"env_var\"\n       env_var_name: \"MY_SECRET_ENV_VAR_NAME\"\n     - kind: \"random_chars\"\n       n_chars: 32\n</code></pre>"},{"location":"soliplex/config/secrets/#secrets-without-sources","title":"Secrets without Sources","text":"<p>Secrets which list no sources are treated as though they were configured using an environment variable source with the same name.</p> <p>This configuration:</p> <pre><code>secrets:\n    - secret_name: MY_SECRET\n</code></pre> <p>is equivalent to:</p> <pre><code>secrets:\n   - secret_name: MY_SECRET\n     sources:\n     - kind: \"env_var\"\n       env_var_name: \"MY_SECRET\"\n</code></pre>"},{"location":"soliplex/config/secrets/#secrets-as-bare-strings","title":"Secrets as Bare Strings","text":"<p>An even shorter way to spell the previous configuration:</p> <pre><code>secrets:\n   - \"MY_SECRET\"\n</code></pre>"},{"location":"soliplex/config/secrets/#checking-configured-secrets","title":"Checking Configured Secrets","text":"<p>The <code>soliplex-cli</code> application has a sub-command, <code>list-secrets</code>. It loads the configuration, attempts to resolve all the secrets, and reports those not found.  E.g.:</p> <pre><code>$ soliplex-cli list-secrets example/installation.yaml \n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Configured secrets \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n- LOGFIRE_TOKEN             MISSING\n- SMITHERY_AI_API_KEY       MISSING\n- SMITHERY_AI_PROFILE       MISSING\n- URL_SAFE_TOKEN_SECRET     OK\n</code></pre>"}]}